[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "",
    "text": "Preface\nWelcome to the online notes for MAS3919 — Foundations of Machine Learning.\nThis course is co-taught for MAS3919 and MAS8607.\nStudents taking MAS8607 can expect to be examined on at least one of the Advanced Topics, indicated with a (\\star) in the table of contents, while these are non-examinable for MAS3919. There will be four Exercise Sheets in total, with solutions presented one week later at Problem Classes.\nThere will be one formative assignment [details] and one summative assignment[details] worth 20% of your overall mark. A written exam forms the remaining 80%.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "Course Overview",
    "text": "Course Overview\nThe first section 1  Overview of Machine Learning of these notes aims to provide an overview of the module, and to recap important prerequisites from Stage 2. In many cases we will indicate precisely where concepts can be found (up to minor presentational variation) in the lecture notes from Stage 2. These notes represent the definitive version of MAS3919 and MAS8607; in-person lectures are an opportunity to review a subset of the material in real-time, but are not a substitute for studying these lecture notes in detail. Students are recommended to read through the lecture notes in advance of the lecture, in a flipped classroom format.\nDistinct from most other modules, we will tend to emphasise understanding of concepts as opposed to detailed calculations, and your examination will test your ability both to recall these concepts and to give a coherent written explanation of their relevance in a given context. After taking this module you should feel equipped with a broad knowledge of machine learning, enabling you to coherently communicate at a technical level in (e.g.) a job interview for a machine learning engineer post. In addition, we will provide practical demonstrations of machine learning in Python; you are strongly encouraged to try these out as homework, as experience of implementing machine learning in Python is a valuable addition to any CV.\nThese lecture notes are new for 2026 and are therefore bound to contain small errors; we would appreciate these being brought to our attention by emailing chris.oates@ncl.ac.uk or matthew.fisher@ncl.ac.uk.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html",
    "href": "content/main/1-overview-of-machine-learning.html",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "1.1 What is Machine Learning?\nYou might be surprised to learn that machine learning is not just a buzzword; it is a rich collection of mathematical concepts that can be rigorously studied.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#sec-what-is-ml",
    "href": "content/main/1-overview-of-machine-learning.html#sec-what-is-ml",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "1.1.1 Tasks\n\n\n\n\n\n\n\nDefinition 1.1 (Supervised Learning Task) Fix sets \\mathcal{X}, \\mathcal{Y}, and \\mathcal{Z}, a probability distribution P on \\mathcal{X} \\times \\mathcal{Y}, and a loss function L : \\mathcal{Y} \\times \\mathcal{Z} \\rightarrow \\mathbb{R}.\nGiven a training dataset \\{(\\mathbf{x}_i,\\mathbf{y}_i)\\}_{i=1}^n consisting of n independent samples from P, try to find a function f : \\mathcal{X} \\rightarrow \\mathcal{Z} for which \n\\mathbb{E}_{(\\mathbf{X},\\mathbf{Y}) \\sim P} [ L(\\mathbf{Y},f(\\mathbf{X})) ]\n is minimal.\n\n\n\n\nTo unpack this definition we are going to recap some of the prerequisite mathematical concepts, which you should have already studied:\n\n\n1.1.1.0.0.1 Set Notation I\nA set is a collection of objects, e.g. \\mathbb{N} is the set of natural numbers, \\mathbb{N}_0 = \\{0\\} \\cup \\mathbb{N} is the set of non-negative integers, and \\mathbb{R} is the set of real numbers.\nGiven a pair of sets, say \\mathcal{X} and \\mathcal{Y}, the Cartesian product of \\mathcal{X} and \\mathcal{Y} consists of all (ordered) pairs (x,y) where x is an element of \\mathcal{X} and y is an element of \\mathcal{Y}.\nAs a shorthand for set membership we can write x \\in \\mathcal{X} and y \\in \\mathcal{Y}. The Cartesian product of \\mathcal{X} and \\mathcal{Y} is denoted \\mathcal{X} \\times \\mathcal{Y}. For example, \\mathbb{R} \\times \\mathbb{R} is the two-dimensional Euclidean plane; we often abbreviate this to \\mathbb{R}^2.\nMore generally we could consider d-fold Cartesian products such as \\mathbb{R}^d.\n\n\n\n\n1.1.1.0.0.2 Probability mass functions; Definition 7 in MAS2909\nLet P be a probability distribution on a countable set \\mathcal{X} = \\{x_1, x_2, \\dots \\}.\nThen P is characterised by its probability mass function \np : \\mathcal{X} \\rightarrow [0,\\infty).\n Indeed, P assigns an amount of probability P(S) = \\sum_{x \\in S} p(x) to each S \\subset \\mathcal{X}.\nFrom the definition of a probability measure it must hold that p(\\mathcal{X}) = \\sum_{x \\in \\mathcal{X}} p(x) = 1.\n\n\n\n\n\n\n\n\n\nExample 1.1 (Binomial Distribution) The Binomial Distribution 1.2, with n trials and success parameter \\rho \\in [0,1], is a probability distribution on \\mathcal{X} = \\{0,1,2, \\dots , n \\} with probability mass function \np(x) = \\binom{n}{x} \\rho^x (1-\\rho)^{n-x}.\n In shorthand this is denoted \\mathrm{Binom}(n,\\rho).\n\n\nShow Visualisation\n\n{\n  const n = binom_n, p = binom_p;\n  const data = Array.from({ length: n + 1 }, (_, k) =&gt; ({ x: k, y: binomPMF(n, p, k) }));\n  const xDomain = Array.from({ length: n + 1 }, (_, k) =&gt; k);  // &lt;-- 0..n categories\n\n  const stats = md`**Mean** ${tex`= n\\rho`} = ${(n * p).toFixed(2)}; \n  **Variance** ${tex`= n\\rho(1-\\rho)`} = ${(n * p * (1 - p)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n    y: { label: \"PMF\" },\n    x: { label: \"x\", type: \"band\", domain: xDomain, padding: 0.05 },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof binom_n = Inputs.range([1, 200], { value: 20, step: 1,  label: md`${tex`n`}` })\nviewof binom_p = Inputs.range([0.01, 0.99], { value: 0.3, step: 0.01, label: md`${tex`\\rho`}` })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.2 (Poisson Distribution) The Poisson Distribution 1.4, with rate parameter \\lambda &gt;0, is a probability distribution on \\mathcal{X} = \\{0,1,2, \\dots  \\} with probability mass function \np(x) = \\frac{ e^{-\\lambda} \\lambda^x }{ x! } .\n In shorthand this is denoted \\mathrm{Pois}(\\lambda).\n\n\nShow Visualisation\n\n{\n  // compute locally (no exported names)\n  const L     = pois_lambda;\n  const kmax  = Math.max(15, Math.ceil(L + 6*Math.sqrt(L)));\n  const pois_data = Array.from({length: kmax + 1}, (_, k) =&gt; ({ x: k, y: poisPMF(L, k) }));\n\n  // build the UI bits\n  const stats = md`**Mean** ${tex`= \\lambda`} = ${L.toFixed(2)}; \n  **Variance** ${tex`= \\lambda`} = ${L.toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(pois_data, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\" }),\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return both in a single wrapper\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof pois_lambda = Inputs.range([0.2, 30], {\n  value: 6, step: 0.2, label: md`${tex`\\lambda`}`\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.1.0.0.3 Set Notation II\nIf a set \\mathcal{X} is contained in another set \\mathcal{Y} we write \\mathcal{X} \\subset \\mathcal{Y}.\nIn this case, the indicator function of the set \\mathcal{X} is the function 1_{\\mathcal{X}} : \\mathcal{Y} \\rightarrow \\{0,1\\} for which f_{\\mathcal{X}}(y) = 1 if and only if y \\in \\mathcal{X}.\nFor example, 1_{[0,1]}(x) is equal to 1 when 0 \\leq x \\leq 1 and equal to 0 if x lies outside this interval.\n\n\n\n\n1.1.1.0.0.4 Probability Density Function\nLet P be a sufficiently regular1 probability distribution on \\mathbb{R}^d.\nThen P is characterised by its probability density function \np : \\mathbb{R}^d \\rightarrow [0,\\infty).\n Indeed, P assigns an amount of probability P(S) = \\int 1_S(\\mathbf{x}) p(\\mathbf{x}) \\; \\mathrm{d}\\mathbf{x} to each set S \\subset \\mathbb{R}^d.\nFrom the definition of a probability measure it must hold that \\int p(\\mathbf{x}) \\; \\mathrm{d}\\mathbf{x} = 1.\n\n\n\n\n\n\n\n\n\nExample 1.3 (Uniform Distribution; Section 1.4 in MAS2909) The Uniform Distribution 2.1 on an interval [a,b] with a &lt; b has probability density function \np(x) = \\frac{1}{b-a} 1_{[a,b]}(x).\n In shorthand this is denoted \\mathcal{U}(a,b).\n\n\nShow Visualisation\n\n{\n  const a = unif_a, b = unif_b;\n  const data = linspace(a - 1, b + 1, 401).map(x =&gt; ({ x, y: unifPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= (a+b)/2`} = ${(((a+b)/2)).toFixed(2)}; \n  **Variance** ${tex`= (b-a)^2/12`} = ${(((b-a)**2)/12).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof unif_a = Inputs.range([-5, 5], {value: -2, step: 0.1, label: md`${tex`a`}`})\nviewof unif_b = Inputs.range([unif_a + 0.2, unif_a + 10], {value: 3, step: 0.1, label: md`${tex`b`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.4 (Normal Distribution on \\mathbb{R}; Section 1.4 in MAS2909) The Normal Distribution 2.5, with mean parameter \\mu \\in \\mathbb{R} and variance parameter \\sigma^2 &gt; 0, has probability density function \np(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( - \\frac{1}{2 \\sigma^2} (x-\\mu)^2 \\right).\n In shorthand this is denoted \\mathcal{N}(\\mu,\\sigma^2).\n\n\nShow Visualisation\n\n{\n  const μ = norm_mu, σ = norm_sig;\n  const [lo, hi] = domainNormal(μ, σ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: normPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= \\mu`} = ${μ.toFixed(2)}; \n  **Variance** ${tex`= \\sigma^2`} = ${(σ**2).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n    width, height: 260,\n    style: { background: \"var(--plot-panel-bg)\", color: \"var(--brand-fg)\" },\n    x: { label: \"x\" }, y: { label: \"PDF\" },\n    marks: [\n      // shaded area under the PDF:\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n\n      // PDF outline:\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof norm_mu  = Inputs.range([-3, 3], {value: 0, step: 0.05, label: md`${tex`\\mu`}`})\nviewof norm_sig = Inputs.range([0.05, 3], {value: 1, step: 0.05, label: md`${tex`\\sigma`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom variables were formally defined in MAS2909. Following standard convention, we will use upper-case Roman letters (e.g. X) for random variables and lower-case Roman letters (e.g. x) for specific values that could be taken by X.\n\n\n1.1.1.0.0.5 Distribution of a Random Variable\nLet X be a random variable taking values in a set \\mathcal{X}.\nThe distribution of X is the probability distribution P for which P(S) = \\mathrm{Prob}(X \\in S) for each S \\subset \\mathcal{X}.\n\n\nIt is common to write X \\sim P as shorthand for “X has distribution P”. Another reasonably common notation, which will be used in this module, is \\mathcal{P}(\\mathcal{X}) to denote the set of probability distributions on a set \\mathcal{X}.\n\n\n\n\n\n\n\nExercise 1.1 (Coin Tossing) A biased coin, which with probability 0.6 lands on heads, is tossed 10 times in total.\nWhat is the probability of observing at least 8 heads?\n\nSolution\nLet X denote the number of heads.\nThen X is a random variable with distribution P = \\mathrm{Binom}(10,0.6). We have P(\\{8,9,10\\}) = p(8) + p(9) + p(10) = \\binom{10}{8} 0.6^8 (1-0.6)^{2} + \\binom{10}{9} 0.6^9 (1-0.6)^1 + \\binom{10}{10} 0.6^{10} (1-0.6)^0 = 0.1673 (4 s.f.)\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 1.2 (Sums of random variables) Let X_1 \\sim \\mathcal{U}(0,1) and X_2 \\sim \\mathcal{U}(0,1) be independent.\nLet Z = X_1 + X_2.\nFind a probability density function for Z.\n(Hint: Recall Proposition 1 in MAS2909.)\n\nSolution\nFrom Proposition 1 in MAS2909 we have \np(z) = \\int 1_{[0,1]}(x) 1_{[0,1]}(z-x) \\; \\mathrm{d}x\n and we can evaluate this integral: \\begin{align*}\np(z)   &= \\int 1_{[\\max\\{0 , z-1 \\},\\min\\{1,z\\}]}(x) \\; \\mathrm{d}x \\\\\n    &= \\max\\{ \\min\\{1,z\\} - \\max\\{0 , z-1 \\} , 0 \\} \\\\\n    &= \\left\\{ \\begin{array}{ll} z & 0 &lt; z \\leq 1 \\\\ 2 - z & 1 &lt; z &lt; 2 \\\\ 0 & \\text{otherwise} \\end{array} \\right.\n\\end{align*} This is called the triangular distribution.\n\n\n\n\n\n\n\n1.1.1.0.0.6 Probabilistic calculus\nWhich of the following equivalent statements do you think is most natural?\n\nZ = X_1 + X_2 where X_1 \\sim \\mathcal{U}(a,b) and X_2 \\sim \\mathcal{N}(\\mu,\\sigma^2) are independent\nZ has probability density function \n\\frac{1}{b-a} \\int 1_{[a,b]}(x) \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (z - x - \\mu)^2 \\right) \\; \\mathrm{d}x\n\n\nIt of course depends on what we are trying to do - a good rule of thumb is to “use random variables for intuition, and use densities for computation”.\n\n\n\n\n1.1.1.0.0.7 Joint Distribution\nGiven random variables X_1 and X_2, we can define a new random variable as \\mathbf{X} = (X_1,X_2).\nThe distribution of \\mathbf{X} is called the joint distribution of X_1 and X_2.\nThe concept naturally extends to more than two random variables as well.\n\n\n\n\n1.1.1.0.0.8 Marginal Distribution; Section 2.3 of MAS2909\nGiven a random variable \\mathbf{X} = (X_1,X_2) with probability (mass or) density function p.\nThe distribution of X_1 is called the marginal distribution of X_1; i.e. the probability distribution whose probability (mass or) density function is \np_1(x_1) = \\int p(\\mathbf{x}) \\; \\mathrm{d}x_2,\n where \\mathbf{x} = (x_1,x_2).\n(For probability mass functions this integral should be replaced by a sum.)\nIntuitively, the marginal distribution of X_1 is just the distribution of X_1 if we have not observed X_2.\n\n\n\n\n1.1.1.0.0.9 Conditional Distribution; Section 2.4 of MAS2909\nGiven a random variable \\mathbf{X} = (X_1,X_2) with probability (mass or) density function p, let p_1 and p_2 denote probability (mass or) density functions for the marginal distributions of X_1 and X_2.\nThe conditional distribution of X_1 given X_2 = x_2 is the probability distribution whose probability (mass or) density function is \np(\\mathbf{x}) / p_2(x_2),\n where \\mathbf{x} = (x_1,x_2). The associated random variable is usually denoted X_1 | X_2 = x_2.\nIntuitively, the conditional distribution of X_1 given X_2 represents our understanding of X_1 if we had observed the value of X_2 (e.g. our understanding of the weather given we had observed someone putting on a coat).\n\n\n\n\n1.1.1.0.0.10 Independence; Section 2.5 of MAS2909\nTwo random variables X_1 and X_2 are independent if their joint distribution admits a probability (mass or) density function of the form p(\\mathbf{x}) = p_1(x_1) p_2(x_2) where p_i is a probability density function for X_i and \\mathbf{x} = (x_1,x_2).\nIntuitively, if X_1 and X_2 are independent, then observing X_2 tells us nothing about X_1 (and vice versa).\nThe concept naturally extends to multiple random variables; we say X_1,\\dots,X_n are independent if \np(\\mathbf{x}) = p_1(x_1) p_2(x_2) \\cdots p_n(x_n)\n where \\mathbf{x} = (x_1,\\dots,x_n).\n\n\n\n\n\n\n\n\n\nExercise 1.3 (Normal distribution on \\mathbb{R}^d) Let X_1 , \\dots X_d be independent with X_i \\sim \\mathcal{N}(\\mu_i , \\sigma_i^2) for each i \\in \\{1,\\dots,d\\}. Let \\mathbf{X} = (X_1, \\dots , X_d).\nShow that \\mathbf{X} \\sim \\mathcal{N}(\\bm{\\mu},\\bm{\\Sigma}) where \\bm{\\mu} = (\\mu_1,\\dots,\\mu_d)^\\top and \\bm{\\Sigma} = \\mathrm{diag}(\\sigma_1^2 , \\dots , \\sigma_d^2).\n\nSolution\nFrom independence we know that \\mathbf{X} has distribution p(\\mathbf{x}) = p_1(x_1) \\cdots p_d(x_d) where p_i(x_i) = \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp( - \\frac{1}{2 \\sigma_i^2} (x_i-\\mu_i)^2 ).\nAlgebra gives the result.\n\n\n\n\n\n\n\n1.1.1.0.0.11 Notation for Expectations\nLet P be a probability distribution on a set \\mathcal{X} and let f : \\mathcal{X} \\rightarrow \\mathbb{R} be a function of interest.\nThe following notations are all equivalent and widely-used:\n\n\\mathbb{E}_{X \\sim P}[f(X)]\n\\mathbb{E}[f(X)] where X \\sim P\nP(f)\n\\int f \\; \\mathrm{d}P\n\\int f(x) p(x) \\; \\mathrm{d}x (if P has a probability density function p)\n\\sum_{x \\in \\mathcal{X}} f(x) p(x) (if P has a probability mass function p)\n\n\n\n\n\n\n\n\n\nTipRemark (Disclaimer: MAS3716 Prequisite)\n\n\n\n\n\n\nRemark 1.2 (Disclaimer: MAS3716 Prequisite). This course does not require MAS3716 and so we will not work rigorously with measure theory; any expectations that we write down will always be assumed to exist.\n\n\n\n\n\n\n\n\n\n\n\nExample 1.5 (Expected Loss 1)  \n\n\n\n\n\n\n\n\n\n\n\nExample 1.6 (Expected Loss 2)  \n\n\n\n\n\n\n\n\n\n\n\nExample 1.7 (Expected Loss 3)  \n\n\n\n\nNow we are ready to unpack Definition 1.1. The easiest way is to see some examples of supervised learning tasks:\n\n\n\n\n\n\n\nExample 1.8 (Regression) Regression models are powerful statistical tools used to understand the relationship between variables and make predictions. At their core, these models aim to identify how one or more independent variables (also often called covariates or predictors), influence a dependent variable (also often called a response variable) of interest.\nFor example, suppose we are interested in the (statistical) relationship between the frequency of pedestrians walking up the Queen Victoria Road next to campus and the time of day.\n\n\n\n\n\n\nFigure 1.1: Map of the main university campus, with the location of the measurements on the Queen Victoria Road highlighted.\n\n\n\nThe independent variable here is the time of day, which we denote X, and the dependent variable is the frequency of pedestrians (i.e. the number of pedestrians per unit time), which we denote Y. It is reasonable to suppose X \\in \\mathbb{R} and Y \\in [0,\\infty).\nOne can freely access such data via the university’s Urban Observatory; the data shown below are from September 2025:\n\n\n\n\n\n\nFigure 1.2: Footfall data for the Queen Victoria Road in September 2025. The vertical axis represents the frequency of pedestrians.\n\n\n\nPredicting pedestrian footfall has important applications in transport, retail, and public safety; other independent variables that could be of interest in this context include the weather and whether or not large public events (e.g. the freshers’ fair) are being held. The goal in regression is to directly predict the dependent variable, so that \\mathcal{Z} = \\mathcal{Y} in the notation of Definition 1.1.\nSimple examples of loss functions, which measure the loss incurred when a true response y is predicted as y', include L(y,y') = |y-y'| and L(y,y') = (y-y')^2.\nRegression models are widely used in various fields, including economics for forecasting financial trends, in medicine for assessing treatment effects, and in social sciences for understanding behavioral patterns. They provide insights that are crucial for making informed decisions and formulating strategies.\n\n\n\n\n\n\n\n\n\n\n\nExample 1.9 (Classification) Continuing on from Example 1.8, how do you think these footfall data on the Queen Victoria Road were collected?\nIt will not be a surprise to you that CCTV cameras are abundant in large cities such as Newcastle; take a look at the latest feeds for yourself:\nhttps://api.newcastle.urbanobservatory.ac.uk/camera/\nCounting the number of people in an image obtained from CCTV is an example of a classification task. Classification is a fundamental concept in machine learning that involves categorising data into predefined groups or classes.\nHere \\mathbf{X} is the CCTV image, which we can consider as an element of \\mathbb{R}^{w \\times h \\times 3}, where the image is w pixels wide, h pixels high, and contains information for each of the red, green and blue colour channels, and Y is the number of pedestrians in the image, which is an element of \\mathbb{N}_0 (here the “classes”).\nThe goal in classification is to directly predict the class, so that \\mathcal{Z} = \\mathcal{Y} in the notation of Definition 1.1.\nThe most common loss function used in classification applications is L(y,y') = 1 if y = y', and otherwise L(y,y') = 0; in fact, this is sometimes called the classification loss, or the 0-1 loss.\nFor this footfall application it might also be reasonable to use a loss function such as L(y,y') = |y-y'|, which is more tolerant to small counting errors than the 0-1 loss.\n(Note that the scale of the loss is irrelevant; the supervised learning task is invariant to whether we use the loss function L(y,y') of the loss function cL(y,y') for any constant c &gt; 0, since we only care about the function f for which the expected loss is minimised; cf. Definition 1.1.)\n\n\n\n\n\n\nFigure 1.3: Several companies have emerged to sell “people counters” as a product. This image is taken from one such company.}.\n\n\n\nThe independent variable here is the time of day, which we denote X, and the dependent variable is the frequency of pedestrians (i.e. the number of pedestrians per unit time), which we denote Y. It is reasonable to suppose X \\in \\mathbb{R} and Y \\in [0,\\infty).\nOne can freely access such data via the university’s Urban Observatory; the data shown below are from September 2025:\n\n\n\n\n\n\nFigure 1.4: Footfall data for the Queen Victoria Road in September 2025. The vertical axis represents the frequency of pedestrians.\n\n\n\nClassification is widely used in various fields, from spam detection in emails to diagnosing diseases in the medical field.\nClassifiers are trained on a dataset where the categories, or labels, are already known; training helps the system learn the patterns and characteristics that differentiate one class from another (cf. Section 1.2).\n\n\n\n\n\n\n\n\n\n\n\nExample 1.10 (Probabilistic Forecasting) Probabilistic forecasting refers to predicting future events or outcomes along with an associated probability distribution.\nUnlike regression, which provides a single outcome prediction, probabilistic forecasting provides a range of potential outcomes and the likelihood of each occurring, offering a more comprehensive view of future uncertainties.\nOne of the key advantages of probabilistic forecasting is its ability to provide decision-makers with a range of possible scenarios, along with their associated probabilities. This allows organisations to plan for various contingencies and make informed decisions based on the level of risk they are willing to accept.\nSuppose, at time t, we want to predict footfall on the Queen Victoria Road at a future time t + 1. Our input X represents all data available to us at time t, and our task is to select a probability distribution that represents a probabilistic prediction of the actual footfall Y. In the setting of Definition 1.1, we have \\mathcal{Y} = \\mathbb{N}_0 and \\mathcal{Z} = \\mathcal{P}(\\mathbb{N}_0).\n\n\n\n\n\n\n\n\n\n\n\nExample 1.11 (Text-to-Video) Text-to-video technology represents a groundbreaking development in the field of artificial intelligence and multimedia content generation.\nBy employing advanced algorithms, this technology can transform textual descriptions X into dynamic video content f(X), offering a novel way to create visual media without the traditional constraints of video production.\nIn the setting of Definition 1.1, \\mathcal{X} is the set of text strings and \\mathcal{Z} is the set of all possible video content.\nFor coherence we can define Y equal to X, so that the loss function L(Y,f(X)) can be interpreted as a critical assessment of whether the video content f(X) is an accurate instantiation of the text string X.\n\n\n\n\n\n\n1.1.2 Models\nNow that we have seen several examples of supervised learning tasks, a natural question is how to solve them? That is, in the notation of Definition 1.1, how do we find a suitable function f : \\mathcal{X} \\rightarrow \\mathcal{Z}?\nThe answer to this question will be broken down into two parts:\n\nFirst we will talk about how to identify a set \\mathcal{F} whose elements are candidates for the function f in a given learning task; this set \\mathcal{F} is called the machine learning model.\nThen we will see how to identify a suitable element f \\in \\mathcal{F}; this second step is called training the machine learning model, and we will defer this discussion to Section 1.2.\n\n\n\n\n\n\n\n\nDefinition 1.2 (Machine Learning Model) A machine learning model (or simply model) for a supervised learning task as in Definition 1.1 is a collection \\mathcal{F} of maps \nf : \\mathcal{X} \\rightarrow \\mathcal{Y}.\n\n\n\n\n\nIn practice the elements of \\mathcal{F} are usually parametrised, denoted f_\\theta : \\mathcal{X} \\rightarrow \\mathcal{Y} for some parameters \\theta from a suitable index set \\Theta. It is then equivalent to specify either the set \\mathcal{F} or the form of the parametric function f_\\theta together with the set of allowed parameters \\Theta.\n\n\n\n\n\n\n\nExample 1.12 (Linear Regression) Linear models are one of the simplest examples of a machine learning model for a regression task (cf. Example 1.8).\nRecall that linear regression refers to using a linear function \nf_{\\bm{\\theta}}(\\mathbf{x}) = \\theta_1 x_1 + \\dots + \\theta_d x_d\n\\tag{1.1}\nto predict the value of the dependent variable Y \\in \\mathbb{R} based on the values of the independent variables \\mathbf{X} \\in \\mathbb{R}^d.\nDespite their simplicity, linear models are widely used in applications where scientific interpretation of the parameters \\bm{\\theta} is required.\nIndeed, \\theta_i carries the interpretation of how the prediction for the dependent variable Y changes per unit change in the associated independent variable X_i in Equation 1.1.\nIn fact, linear regression models can be quite sophisticated, e.g. \nf_{\\bm{\\theta}}(\\mathbf{x}) = \\theta_1 \\phi_1(\\mathbf{x}) + \\dots + \\theta_p \\phi_p(\\mathbf{x})\n\\tag{1.2}\nfor a fixed collection of \\bm{\\theta}-independent functions \\phi_i, i = 1 , \\dots , p, called features (cf. Section 2.1.2) which could include an intercept (\\phi_i(\\mathbf{x}) = 1), nonlinearities (e.g. \\phi_i(\\mathbf{x}) = x_1^2), and interactions (e.g. \\phi_i(\\mathbf{x}) = x_1 x_2).\nIn this module a linear regression model refers to a machine learning model f_{\\bm{\\theta}} that is linear in the parameters \\bm{\\theta}; the map f_{\\bm{\\theta}}(\\mathbf{x}) need not be linear in \\mathbf{x}, as Equation 1.2 demonstrated.\nNote also that no concepts from probability appear in our definition of a linear regression model (though sometimes concepts from probability are used to train such a model; see Section 1.2).\n\n\n\n\n\n\n\n\n\n\n\nExample 1.13 (Logistic Classifier) A logistic classifier is a machine learning model used for binary classification tasks, i.e. where the classes can be represented using the binary labels \\mathcal{Y} = \\{0,1\\}. The model has the form \\begin{align*}\n    f_{\\bm{\\theta}}(\\mathbf{x}) = \\left\\{ \\begin{array}{ll} 1 & \\text{if} \\quad \\sigma( g_{\\bm{\\theta}}(\\textbf{x}) ) &gt; \\tau \\\\ 0 & \\text{if} \\quad \\sigma( g_{\\bm{\\theta}}(\\mathbf{x}) ) \\leq \\tau \\end{array} \\right.\n\\end{align*} where g_{\\bm{\\theta}} : \\mathcal{X} \\rightarrow \\mathbb{R} is a linear regression model of the form Equation 1.1 parametrised by \\bm{\\theta}, \\sigma(\\cdot) is the logistic function \n\\sigma(z) = \\frac{1}{1 + e^{-z}} ,\n\\tag{1.3}\nalso known as the sigmoid function, which converts the output g_{\\bm{\\theta}}(\\mathbf{x}) from the linear regression model into a score that ranges from 0 to 1, and \\tau \\in (0,1) is a fixed threshold, which is commonly \\tau = \\frac{1}{2}.\nAs with the linear regression model, no concepts from probability are required to define a logistic classifier (though sometimes concepts from probability are used to train such a model; see Section 1.2).\nLogistic classifiers are widely used in various fields, including finance for credit scoring, healthcare for disease prediction, and marketing for customer segmentation.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#sec-training",
    "href": "content/main/1-overview-of-machine-learning.html#sec-training",
    "title": "1  Overview of Machine Learning",
    "section": "1.2 Training",
    "text": "1.2 Training",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#footnotes",
    "href": "content/main/1-overview-of-machine-learning.html#footnotes",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "Students who have taken MAS3716 will understand that we require P to be absolutely continuous with respect to the Lebesgue measure on \\mathbb{R}^d in order for a density to exist. An example of a probability distribution which fails this requirement is the distribution that places all mass at a single point. Such issues will not be the focus of this module; cf. Remark 1.2.↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/2-machine-learning-models.html",
    "href": "content/main/2-machine-learning-models.html",
    "title": "2  Machine Learning Models",
    "section": "",
    "text": "2.1 Linear Model\nThis section takes a deep dive into the two main classes of machine learning model, the linear model 2.1 and neural networks 2.2\nAlong the way we will learn about the key (related) concepts of regularisation 2.1.1, featurisation 2.1.2, and dimensionality reduction 2.1.2.2.\nAlthough we already encountered examples of linear models in the regression context (cf. Example 1.12), here we precisely define it:\nIt is worth re-emphasising that this definition does not require the relationship between \\mathbf{x} and f_{\\bm{\\theta}}(\\mathbf{x}) to be linear as in Equation 1.1. The “linearity” refers to linearity of f_{\\bm{\\theta}}(\\mathbf{x}) with respect to the parameters \\bm{\\theta} \\in \\mathbb{R}^p.\nFor the moment we will suppose we are provided with appropriate feature functions \\phi_i : \\mathcal{X} \\rightarrow \\mathbb{R}; the issue of selecting an appropriate featurisation is discussed in detail in Section 2.1.2. The vector-valued function \\phi : \\mathcal{X} \\rightarrow \\mathbb{R}^p whose coordiate functions are the \\phi_i is called the feature map associated to the linear regression model.\nTo get started, let us see how to recover standard least squares from the empirical risk minimisation framework:\nIt is reassuring that least squares falls under the umbrella of empirical risk minimisation, but the value of having a general framework for supervised learning is that we can consider alternative loss functions as well.\nOne motivation for this is to consider the robustneess of a linear regression model against an ?def-adversarial-attack targetting one entry in the dataset.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Machine Learning Models</span>"
    ]
  },
  {
    "objectID": "content/main/2-machine-learning-models.html#sec-linear-model",
    "href": "content/main/2-machine-learning-models.html#sec-linear-model",
    "title": "2  Machine Learning Models",
    "section": "",
    "text": "Definition 2.1 (Linear Model) Let \\mathcal{X} = \\mathbb{R}^d and \\mathcal{Z} = \\mathbb{R}. A linear model is a model of the form \nf_{\\bm{\\theta}}(\\mathbf{x}) = \\theta_1 \\phi_1(\\mathbf{x}) + \\dots + \\theta_p \\phi_p(\\mathbf{x})\n for some \\bm{\\theta} = (\\theta_1 , \\cdots , \\theta_p)^\\top \\in \\mathbb{R}^p and some feature functions \\phi_i : \\mathcal{X} \\rightarrow \\mathbb{R}, i \\in \\{1,\\dots,p\\}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.1 (Least squares as empirical risk minimisation) Consider training a linear regression model using empirical risk minimisation with squared error loss L(y,z) = (y - z)^2. Let \\bm{\\Phi} be the n \\times p whose (i,j)th entry is \\phi_j(\\mathbf{x}_i), and assume that \\bm{\\Phi} has full column rank. Then, \\begin{align*}\n\\mathcal{R}_n(f_{\\bm{\\theta}}) & = \\frac{1}{n} \\sum_{i=1}^n L(y_i , f_{\\bm{\\theta}}(\\mathbf{x}_i)) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\phi(\\mathbf{x}_i)^\\top \\bm{\\theta} )^2 \\\\\n& = \\frac{1}{n} \\| \\mathbf{y} - \\bm{\\Phi} \\bm{\\theta} \\|^2\n\\end{align*} so that \\begin{align*}\n\\nabla_{\\bm{\\theta}} \\mathcal{R}_n(f_{\\bm{\\theta}}) & = \\frac{2}{n} [ - 2 \\bm{\\Phi}^\\top \\mathbf{y} + 2 \\bm{\\Phi}^\\top \\bm{\\Phi} \\bm{\\theta} ] .\n\\end{align*} Since \\bm{\\Phi} has full column rank it follows that \\bm{\\Phi}^\\top \\bm{\\Phi} is a positive definite (and thus invertible) matrix. Thus the stationarity equation \\nabla_{\\bm{\\theta}} \\mathcal{R}_n(f_{\\bm{\\theta}}) = \\mathbf{0} has a unique solution \n\\hat{\\bm{\\theta}} = (\\bm{\\Phi}^\\top \\bm{\\Phi})^{-1} \\bm{\\Phi}^\\top \\mathbf{y}\n\\tag{2.1}\nwhich we recognise as the usual least-squares formula for regression coefficients that you learned in school.\nNote that the Hessian matrix \\nabla_{\\bm{\\theta}}^2 \\mathcal{R}_n(f_{\\bm{\\theta}}) = \\frac{4}{n} \\bm{\\Phi}^\\top \\bm{\\Phi} is positive definite, so although \\hat{\\bm{\\theta}} was obtained as a solution of the stationary point equation it is indeed a global minimiser of the empirical risk.\n\n\n\n\n\n\n\n2.1.1 Regularisation\n\n2.1.1.1 Ridge Regression\n\n\n2.1.1.2 Other Convex Regularisers\n\n\n\n2.1.2 Featurisation\n\n2.1.2.1 Variable Selection\n\n\n2.1.2.2 Dimensionality Reduction\n\n\n2.1.2.3 Kernel Methods (\\star)",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Machine Learning Models</span>"
    ]
  },
  {
    "objectID": "content/main/2-machine-learning-models.html#sec-nn",
    "href": "content/main/2-machine-learning-models.html#sec-nn",
    "title": "2  Machine Learning Models",
    "section": "2.2 Neural Networks",
    "text": "2.2 Neural Networks\n\n2.2.1 Activation Functions",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Machine Learning Models</span>"
    ]
  },
  {
    "objectID": "content/main/3-stochastic-optimisation.html",
    "href": "content/main/3-stochastic-optimisation.html",
    "title": "3  Stochastic Optimisation",
    "section": "",
    "text": "3.1 Gradient Descent",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochastic Optimisation</span>"
    ]
  },
  {
    "objectID": "content/main/3-stochastic-optimisation.html#stochastic-gradient-descent",
    "href": "content/main/3-stochastic-optimisation.html#stochastic-gradient-descent",
    "title": "3  Stochastic Optimisation",
    "section": "3.2 Stochastic Gradient Descent",
    "text": "3.2 Stochastic Gradient Descent",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochastic Optimisation</span>"
    ]
  },
  {
    "objectID": "content/main/4-generalisation-error.html",
    "href": "content/main/4-generalisation-error.html",
    "title": "4  Generalisation Error",
    "section": "",
    "text": "4.1 Generalisation Error Bounds (\\star)",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Generalisation Error</span>"
    ]
  },
  {
    "objectID": "content/main/4-generalisation-error.html#domain-shift",
    "href": "content/main/4-generalisation-error.html#domain-shift",
    "title": "4  Generalisation Error",
    "section": "4.2 Domain Shift",
    "text": "4.2 Domain Shift",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Generalisation Error</span>"
    ]
  },
  {
    "objectID": "content/main/5-online-supervised-learning.html",
    "href": "content/main/5-online-supervised-learning.html",
    "title": "5  Online Supervised Learning",
    "section": "",
    "text": "5.1 Continual Learning",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Online Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/5-online-supervised-learning.html#bandits",
    "href": "content/main/5-online-supervised-learning.html#bandits",
    "title": "5  Online Supervised Learning",
    "section": "5.2 Bandits",
    "text": "5.2 Bandits",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Online Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/5-online-supervised-learning.html#reinforcement-learning",
    "href": "content/main/5-online-supervised-learning.html#reinforcement-learning",
    "title": "5  Online Supervised Learning",
    "section": "5.3 Reinforcement Learning",
    "text": "5.3 Reinforcement Learning",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Online Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/6-beyond-supervised-learning.html",
    "href": "content/main/6-beyond-supervised-learning.html",
    "title": "6  Beyond Supervised Learning",
    "section": "",
    "text": "6.1 Unsupervised Learning",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Beyond Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/6-beyond-supervised-learning.html#semi-supervised-learning",
    "href": "content/main/6-beyond-supervised-learning.html#semi-supervised-learning",
    "title": "6  Beyond Supervised Learning",
    "section": "6.2 Semi-supervised Learning",
    "text": "6.2 Semi-supervised Learning",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Beyond Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/6-beyond-supervised-learning.html#generative-modelling-star",
    "href": "content/main/6-beyond-supervised-learning.html#generative-modelling-star",
    "title": "6  Beyond Supervised Learning",
    "section": "6.3 Generative Modelling (\\star)",
    "text": "6.3 Generative Modelling (\\star)\n\n6.3.1 Generative Models (\\star)\n\n\n6.3.2 Training Generative Models (\\star)",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Beyond Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/7-ethics-of-ml.html",
    "href": "content/main/7-ethics-of-ml.html",
    "title": "7  Ethics of Machine Learning",
    "section": "",
    "text": "Definition 7.1 (Adversarial Attacks) Adversarial attacks in machine learning refer to techniques used to deceive models by introducing small, intentional perturbations to the input data. This area of study has gained significant attention due to the vulnerabilities it exposes in machine learning systems, particularly in computer vision, natural language processing, and other applications where AI models are deployed.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/appendix/formula-sheet.html#discrete-distributions",
    "href": "content/appendix/formula-sheet.html#discrete-distributions",
    "title": "Formula Sheet",
    "section": "Discrete distributions",
    "text": "Discrete distributions\n\nBernoulli\nModel. X \\sim \\operatorname{Bernoulli}(p) with 0&lt;p&lt;1.\nSupport. x \\in \\{0,1\\}.\nPMF. \n\\operatorname{Pr}(X=x) = p^{\\,x}(1-p)^{1-x}, \\quad x\\in\\{0,1\\}.\n Mean/Var. \\mathbb{E}[X]=p,\\quad \\operatorname{Var}(X)=p(1-p).\n\n\n\nBinomial\nModel. X \\sim \\operatorname{Binom}(n,p), n\\in \\mathbb{N}, 0&lt;p&lt;1.\nSupport. x=0,1,\\ldots,n.\nPMF. \n\\operatorname{Pr}(X=x) = \\binom{n}{x} p^x (1-p)^{n-x}.\n Mean/Var. \\mathbb{E}[X]=np,\\quad \\operatorname{Var}(X)=np(1-p).\n\n\n\nMultinomial\nModel. \\mathbf{X}=(X_1,\\ldots,X_k) \\sim \\operatorname{Multinomial}(n,\\mathbf{p}), with n\\in\\mathbb{N}, k\\ge 2, \\mathbf{p}=(p_1,\\ldots,p_k), p_i&gt;0, and \\sum_{i=1}^k p_i=1.\nSupport. \\mathbf{x}=(x_1,\\ldots,x_k) where x_i\\in\\{0,1,\\ldots,n\\} and \\sum_{i=1}^k x_i=n.\nPMF. \n\\Pr(\\mathbf{X}=\\mathbf{x})\n=\\frac{n!}{x_1!\\cdots x_k!}\\prod_{i=1}^k p_i^{\\,x_i}.\n Mean/Cov. \n\\mathbb{E}[X_i]=n p_i,\\qquad\n\\operatorname{Var}(X_i)=n p_i(1-p_i),\\qquad\n\\operatorname{Cov}(X_i,X_j)=-\\,n p_i p_j\\quad (i\\ne j).\n Vector form. \n\\mathbb{E}[\\mathbf{X}]=n\\,\\mathbf{p},\\qquad\n\\operatorname{Cov}(\\mathbf{X})=n\\left(\\operatorname{diag}(\\mathbf{p})-\\mathbf{p}\\mathbf{p}^\\top\\right).\n\nNote. For k=2, the first component X_1 \\sim \\operatorname{Bin}(n,p_1) (Binomial).\n\n\n\nPoisson\nModel. X \\sim \\operatorname{Pois}(\\lambda), \\lambda&gt;0.\nSupport. x=0,1,2,\\ldots.\nPMF. \n\\operatorname{Pr}(X=x)=\\frac{\\lambda^x e^{-\\lambda}}{x!}.\n Mean/Var. \\mathbb{E}[X]=\\lambda,\\quad \\operatorname{Var}(X)=\\lambda.\n\n\n\nGeometric\nModel. X \\sim \\operatorname{Geom}(p) (trials until first success, counting the success), 0&lt;p&lt;1.\nSupport. x=1,2,\\ldots.\nPMF. \n\\operatorname{Pr}(X=x)=p(1-p)^{x-1}.\n Mean/Var. \\mathbb{E}[X]=\\frac{1}{p},\\quad \\operatorname{Var}(X)=\\frac{1-p}{p^2}.\n\n\n\n\n\n\nWarningParameterisation alert\n\n\n\nSome texts start at x=0 (failures before the first success).\n\n\n\n\n\nNegative Binomial\nModel. X \\sim \\operatorname{NegBin}(r,p): number of trials to achieve the r-th success (counts the successes), r&gt;0 (often integer), 0&lt;p&lt;1.\nSupport. x=r,r+1,\\ldots.\nPMF. \n\\operatorname{Pr}(X=x) = \\binom{x-1}{r-1} p^{\\,r} (1-p)^{x-r}.\n Mean/Var. \\mathbb{E}[X]=\\frac{r}{p},\\quad \\operatorname{Var}(X)=\\frac{r(1-p)}{p^2}.\n\n\n\n\n\n\nWarningParameterisation alert\n\n\n\nAnother common version counts failures before the r-th success (x=0,1,\\dots) with different mean/variance. Always check which one is used.",
    "crumbs": [
      "Additional Material",
      "Formula Sheet"
    ]
  },
  {
    "objectID": "content/appendix/formula-sheet.html#continuous-distributions",
    "href": "content/appendix/formula-sheet.html#continuous-distributions",
    "title": "Formula Sheet",
    "section": "Continuous distributions",
    "text": "Continuous distributions\n\nUniform (continuous)\nModel. X \\sim \\mathcal{U}(a,b), a&lt;b.\nSupport. a&lt;x&lt;b.\nPDF. \nf_X(x;a,b)=\\frac{1}{b-a}.\n Mean/Var. \\mathbb{E}[X]=\\frac{a+b}{2},\\quad \\operatorname{Var}(X)=\\frac{(b-a)^2}{12}.\n\n\n\nExponential\nModel. X \\sim \\operatorname{Exponential}(\\lambda) with rate \\lambda&gt;0.\nSupport. x&gt;0.\nPDF. \nf_X(x;\\lambda)=\\lambda e^{-\\lambda x}.\n Mean/Var. \\mathbb{E}[X]=\\frac{1}{\\lambda},\\quad \\operatorname{Var}(X)=\\frac{1}{\\lambda^2}.\n\n\n\nGamma\nModel. X \\sim \\operatorname{Gamma}(a,b) with shape a&gt;0 and rate b&gt;0.\nSupport. x&gt;0.\nPDF. \nf_X(x;a,b)=\\frac{b^a}{\\Gamma(a)} x^{a-1} e^{-bx}.\n Mean/Var. \\mathbb{E}[X]=\\frac{a}{b},\\quad \\operatorname{Var}(X)=\\frac{a}{b^2}.\n\n\n\n\n\n\nWarningParameterisation alert\n\n\n\nMany sources use scale \\beta=1/b: then f(x)=\\frac{1}{\\Gamma(a)\\beta^a}x^{a-1}e^{-x/\\beta} and \\mathbb{E}[X]=a\\beta.\n\n\n\n\n\nInverse Gamma\nModel. X \\sim \\operatorname{InvGamma}(a,b), with a&gt;0, b&gt;0.\nSupport. x&gt;0.\nPDF. \nf_X(x;a,b)=\\frac{b^a}{\\Gamma(a)} x^{-(a-1)} e^{-bx^{-1}}.\n Statistics. \\mathbb{E}[X]=\\frac{b}{a-1},\\quad \\operatorname{Var}(X)=\\frac{b^2}{(a-1)^2(a-2)} and \\text{Mode}(X) = \\frac{b}{a+1} if a &gt; 2.\n\n\n\nNormal\nModel. X \\sim \\mathcal{N}(\\mu,\\sigma^2) with \\sigma&gt;0.\nSupport. x\\in\\mathbb{R}.\nPDF. \nf_X(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\n\\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right).\n Mean/Var. \\mathbb{E}[X]=\\mu,\\quad \\operatorname{Var}(X)=\\sigma^2.\n\nProperties\nSuppose X_1,\\ldots, X_n are independent normal random variables, then:\n\n\n\n\nLognormal\nModel. X \\sim \\operatorname{LogNormal}(\\mu,\\sigma^2) meaning \\ln X \\sim \\mathcal{N}(\\mu,\\sigma^2).\nSupport. x&gt;0.\nPDF. \nf_X(x;\\mu,\\sigma^2)=\\frac{1}{x\\sqrt{2\\pi\\sigma^2}}\n\\exp\\!\\left(-\\frac{(\\ln x-\\mu)^2}{2\\sigma^2}\\right).\n Mean/Var. \\mathbb{E}[X]=e^{\\mu+\\sigma^2/2},\\quad \\operatorname{Var}(X)=\\big(e^{\\sigma^2}-1\\big)e^{2\\mu+\\sigma^2}.\n\n\n\nChi-squared\nModel. X \\sim \\chi^2_\\nu with \\nu&gt;0 degrees of freedom.\nSupport. x&gt;0.\nPDF. \nf_X(x;\\nu)=\\frac{1}{2^{\\nu/2}\\Gamma(\\nu/2)}x^{\\nu/2-1}e^{-x/2}.\n Mean/Var. \\mathbb{E}[X]=\\nu,\\quad \\operatorname{Var}(X)=2\\nu.\n\n\n\n\n\n\nNote\n\n\n\n\\chi^2_\\nu is a special case of Gamma with a=\\nu/2, b=1/2.\n\n\n\n\n\nStudent-t\nModel. X \\sim t_\\nu with \\nu&gt;0 degrees of freedom.\nSupport. x\\in\\mathbb{R}.\nPDF. \nf_X(x;\\nu)=\\frac{\\Gamma\\!\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu\\pi}\\,\\Gamma\\!\\left(\\frac{\\nu}{2}\\right)}\n\\left(1+\\frac{x^2}{\\nu}\\right)^{-(\\nu+1)/2}.\n Mean/Var. \\mathbb{E}[X]=0 for \\nu&gt;1; undefined for \\nu\\le 1.\n\\operatorname{Var}(X)=\\frac{\\nu}{\\nu-2} for \\nu&gt;2; infinite for 1&lt;\\nu\\le 2; undefined for \\nu\\le 1.\n\n\n\nF distribution\nModel. X \\sim F_{d_1,d_2} with d_1,d_2&gt;0 degrees of freedom.\nSupport. x&gt;0.\nPDF. \nf_X(x;d_1,d_2)=\\frac{\\Gamma\\!\\left(\\frac{d_1+d_2}{2}\\right)}{\\Gamma\\!\\left(\\frac{d_1}{2}\\right)\\Gamma\\!\\left(\\frac{d_2}{2}\\right)}\n\\left(\\frac{d_1}{d_2}\\right)^{d_1/2}\\frac{x^{d_1/2-1}}{\\left(1+\\frac{d_1}{d_2}x\\right)^{(d_1+d_2)/2}}.\n Mean/Var. \\mathbb{E}[X]=\\frac{d_2}{d_2-2} for d_2&gt;2.\n\\operatorname{Var}(X)=\\frac{2d_2^2(d_1+d_2-2)}{d_1(d_2-2)^2(d_2-4)} for d_2&gt;4.\n\n\n\nBeta\nModel. X \\sim \\operatorname{Beta}(a,b), a&gt;0, b&gt;0.\nSupport. 0&lt;x&lt;1.\nPDF. \nf_X(x;a,b)=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\,x^{a-1}(1-x)^{b-1}.\n Mean/Var. \\mathbb{E}[X]=\\frac{a}{a+b},\\quad \\operatorname{Var}(X)=\\frac{ab}{(a+b)^2(a+b+1)}.\n\n\n\nWeibull\nModel. X \\sim \\operatorname{Weibull}(\\beta,\\theta), \\beta&gt;0, \\theta&gt;0.\nSupport. x &gt; 0.\nPDF. \nf_X(x) = \\frac{\\beta}{\\theta}x^{\\beta - 1} \\exp\\left(-\\frac{x^\\beta}{\\theta}\\right)",
    "crumbs": [
      "Additional Material",
      "Formula Sheet"
    ]
  },
  {
    "objectID": "content/appendix/formula-sheet.html#multivariate-distributions",
    "href": "content/appendix/formula-sheet.html#multivariate-distributions",
    "title": "Formula Sheet",
    "section": "Multivariate Distributions",
    "text": "Multivariate Distributions\n\nMultivariate Normal\nModel. \\mathbf{X} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu},\\Sigma) with \\Sigma positive definite.\nSupport. \\mathbf{x}\\in\\mathbb{R}^p.\nPDF. \nf_{\\mathbf{X}}(\\mathbf{x};\\boldsymbol{\\mu},\\Sigma)=\\frac{1}{(2\\pi)^{p/2}(\\det\\Sigma)^{1/2}}\n\\exp\\!\\left(-\\tfrac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right).\n Mean/Cov. \\mathbb{E}[\\mathbf{X}]=\\boldsymbol{\\mu},\\quad \\operatorname{Var}(\\mathbf{X})=\\Sigma.",
    "crumbs": [
      "Additional Material",
      "Formula Sheet"
    ]
  },
  {
    "objectID": "content/appendix/revision-sheet.html",
    "href": "content/appendix/revision-sheet.html",
    "title": "Revision Sheet",
    "section": "",
    "text": "Under Construction…",
    "crumbs": [
      "Additional Material",
      "Revision Sheet"
    ]
  },
  {
    "objectID": "content/appendix/distribution-explorer.html",
    "href": "content/appendix/distribution-explorer.html",
    "title": "Distribution Explorer",
    "section": "",
    "text": "ACCENT  = \"var(--brand-teal)\"\nACCENT2 = \"var(--brand-red)\"\nGRID    = \"var(--border)\"\n\n// Numerical helpers\nlinspace = (a, b, n=401) =&gt; Array.from({length:n}, (_,i)=&gt; a + (b-a)*(i/(n-1)))\n\n// Log-Gamma (Lanczos) and friends (for stable PMFs/PDFs)\nfunction logGamma(z){\n  const g = 7;\n  const p = [\n    0.99999999999980993, 676.5203681218851, -1259.1392167224028,\n    771.32342877765313, -176.61502916214059, 12.507343278686905,\n    -0.13857109526572012, 9.9843695780195716e-6, 1.5056327351493116e-7\n  ];\n  if(z &lt; 0.5){\n    return Math.log(Math.PI) - Math.log(Math.sin(Math.PI*z)) - logGamma(1 - z);\n  }\n  z -= 1;\n  let x = p[0];\n  for(let i=1; i&lt;p.length; i++) x += p[i] / (z + i);\n  const t = z + g + 0.5;\n  return 0.5*Math.log(2*Math.PI) + (z+0.5)*Math.log(t) - t + Math.log(x);\n}\n\nlogChoose = (n,k) =&gt; logGamma(n+1) - logGamma(k+1) - logGamma(n-k+1)\n\n// Discrete PMFs (stable in log-domain)\nbinomPMF = (n,p,k) =&gt; Math.exp(logChoose(n,k) + k*Math.log(p) + (n-k)*Math.log(1-p))\npoisPMF  = (lambda,k) =&gt; Math.exp(k*Math.log(lambda) - lambda - logGamma(k+1))\ngeomPMF1 = (p,k) =&gt; p * Math.pow(1-p, k-1) // support {1,2,...}\nnegbinPMF = (r,p,x) =&gt; {\n  if(x &lt; r) return 0;\n  return Math.exp(logChoose(x-1, r-1) + r*Math.log(p) + (x-r)*Math.log(1-p));\n}\n\n// Continuous PDFs\nnormPDF = (x,mu,sig) =&gt; Math.exp(-0.5*((x-mu)/sig)**2)/(sig*Math.sqrt(2*Math.PI))\nlognormPDF = (x,mu,sig) =&gt; x&lt;=0 ? 0 : Math.exp(-((Math.log(x)-mu)**2)/(2*sig*sig)) / (x*sig*Math.sqrt(2*Math.PI))\nunifPDF = (x,a,b) =&gt; (x&gt;a && x&lt;b) ? 1/(b-a) : 0\nexpPDF = (x,lambda) =&gt; x&gt;0 ? lambda*Math.exp(-lambda*x) : 0\ngammaPDF = (x,a,b) =&gt; { // shape a, rate b\n  if(x&lt;=0) return 0;\n  return Math.exp(a*Math.log(b) - logGamma(a) + (a-1)*Math.log(x) - b*x)\n}\nbetaPDF = (x,a,b) =&gt; {\n  if(x&lt;=0 || x&gt;=1) return 0;\n  const logB = logGamma(a)+logGamma(b)-logGamma(a+b);\n  return Math.exp((a-1)*Math.log(x) + (b-1)*Math.log(1-x) - logB)\n}\nchisqPDF = (x,nu) =&gt; gammaPDF(x, nu/2, 1/2)\ntPDF = (x,nu) =&gt; {\n  const logC = logGamma((nu+1)/2) - (0.5*Math.log(nu*Math.PI) + logGamma(nu/2));\n  return Math.exp(logC - ((nu+1)/2)*Math.log(1 + (x*x)/nu));\n}\nfPDF = (x,d1,d2) =&gt; {\n  if(x&lt;=0) return 0;\n  const logC = logGamma((d1+d2)/2) - (logGamma(d1/2)+logGamma(d2/2)) + (d1/2)*Math.log(d1/d2);\n  return Math.exp(logC + (d1/2 - 1)*Math.log(x) - ((d1+d2)/2)*Math.log(1 + (d1/d2)*x))\n}\n\n// Convenient domain heuristics\ndomainNormal = (mu,sig) =&gt; [mu - 4*sig, mu + 4*sig]\ndomainGamma  = (a,b) =&gt; [0, Math.max(5, a/b + 6*Math.sqrt(a)/b)]\ndomainExp    = (lambda) =&gt; [0, Math.max(5, 6/lambda)]\ndomainBeta   = [0,1]\ndomainPos    = [0, 10]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBernoulliBinomialPoissonGeometricNegative BinomialUniformExponentialGammaNormalLognormalChi-squaredStudent t\n\n\n\n{\n  const p = bern_p;\n  const data = [0, 1].map(x =&gt; ({ x, y: x ? p : 1 - p }));\n\n  const stats = md`**Mean** ${tex`= p`} = ${p.toFixed(2)}; \n  **Var** ${tex`= p(1-p)`} = ${(p * (1 - p)).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\", domain: [0, 1] },\n    x: { label: \"x\", type: \"band\", domain: [0, 1] },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof bern_p = Inputs.range([0.01, 0.99], {\n  value: 0.6, step: 0.01, label: md`${tex`p`}`\n})\n\n\n\n\n\n\n\n\n\n{\n  const n = binom_n, p = binom_p;\n  const data = Array.from({ length: n + 1 }, (_, k) =&gt; ({ x: k, y: binomPMF(n, p, k) }));\n  const xDomain = Array.from({ length: n + 1 }, (_, k) =&gt; k);  // &lt;-- 0..n categories\n\n  const stats = md`**Mean** ${tex`= np`} = ${(n * p).toFixed(2)}; \n  **Var** ${tex`= np(1-p)`} = ${(n * p * (1 - p)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n    y: { label: \"PMF\" },\n    x: { label: \"x\", type: \"band\", domain: xDomain, padding: 0.05 },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof binom_n = Inputs.range([1, 200], { value: 20, step: 1,  label: md`${tex`n`}` })\nviewof binom_p = Inputs.range([0.01, 0.99], { value: 0.3, step: 0.01, label: md`${tex`p`}` })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  // compute locally (no exported names)\n  const L     = pois_lambda;\n  const kmax  = Math.max(15, Math.ceil(L + 6*Math.sqrt(L)));\n  const pois_data = Array.from({length: kmax + 1}, (_, k) =&gt; ({ x: k, y: poisPMF(L, k) }));\n\n  // build the UI bits\n  const stats = md`**Mean** ${tex`= \\lambda`} = ${L.toFixed(2)}; \n  **Var** ${tex`= \\lambda`} = ${L.toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(pois_data, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\" }),\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return both in a single wrapper\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof pois_lambda = Inputs.range([0.2, 30], {\n  value: 6, step: 0.2, label: md`${tex`\\lambda`}`\n})\n\n\n\n\n\n\n\n\n\n{\n  // compute locally\n  const p = geom_p;\n  const raw   = Math.log(1e-4) / Math.log(1 - p);            // tail cutoff\n  const kmax  = Math.max(5, Math.min(200, Math.ceil(raw)));  // clamp for stability\n  const geom_data = Array.from({ length: kmax }, (_, i) =&gt; {\n    const k = i + 1; \n    return { x: k, y: geomPMF1(p, k) }; // PMF = p(1-p)^{k-1}\n  });\n\n  // stats readout\n  const stats = md`**Mean** ${tex`= 1/p`} = ${(1/p).toFixed(2)}; \n  **Var** ${tex`= (1-p)/p^2`} = ${(((1-p)/(p*p))).toFixed(2)}.`;\n\n  // plot\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(geom_data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return one wrapper node\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof geom_p = Inputs.range([0.02, 0.98], {\n  value: 0.3, step: 0.02, label: md`${tex`p`}`\n})\n\n\n\n\n\n\n\n\n\n{\n  const r = Math.round(negbin_r), p = negbin_p;\n  const mean = r / p, sd = Math.sqrt(r * (1 - p)) / p;\n  const xmax = Math.min(400, Math.ceil(mean + 6 * sd));\n\n  const data = Array.from({ length: Math.max(0, xmax - r + 1) }, (_, i) =&gt; {\n    const x = r + i;\n    return { x, y: negbinPMF(r, p, x) };\n  });\n\n  const stats = md`**Mean** ${tex`= r/p`} = ${(r/p).toFixed(2)}; \n  **Var** ${tex`= r(1-p)/p^2`} = ${((r*(1-p))/(p**2)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PMF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof negbin_r = Inputs.range([1, 30], {value: 5, step: 1, label: md`${tex`r`}`})\nviewof negbin_p = Inputs.range([0.02, 0.98], {value: 0.4, step: 0.02, label: md`${tex`p`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const a = unif_a, b = unif_b;\n  const data = linspace(a - 1, b + 1, 401).map(x =&gt; ({ x, y: unifPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= (a+b)/2`} = ${(((a+b)/2)).toFixed(2)}; \n  **Var** ${tex`= (b-a)^2/12`} = ${(((b-a)**2)/12).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof unif_a = Inputs.range([-5, 5], {value: -2, step: 0.1, label: md`${tex`a`}`})\nviewof unif_b = Inputs.range([unif_a + 0.2, unif_a + 10], {value: 3, step: 0.1, label: md`${tex`b`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const λ = exp_lambda;\n  const [lo, hi] = domainExp(λ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: expPDF(x, λ) }));\n\n  const stats = md`**Mean** ${tex`= 1/\\lambda`} = ${(1/λ).toFixed(2)}; \n  **Var** ${tex`= 1/\\lambda^2`} = ${((1/(λ**2))).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof exp_lambda = Inputs.range([0.2, 5], {value: 1, step: 0.1, label: md`${tex`\\lambda`}`})\n\n\n\n\n\n\n\n\n\n{\n  const a = gamma_a, b = gamma_b;\n  const [lo, hi] = domainGamma(a, b);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: gammaPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= a/b`} = ${(a/b).toFixed(2)}; \n  **Var** ${tex`= a/b^2`} = ${(a/(b**2)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof gamma_a = Inputs.range([0.5, 10], {value: 3, step: 0.1, label: md`${tex`a\\ \\text{(shape)}`}`})\nviewof gamma_b = Inputs.range([0.2, 5],  {value: 1, step: 0.1, label: md`${tex`b\\ \\text{(rate)}`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const μ = norm_mu, σ = norm_sig;\n  const [lo, hi] = domainNormal(μ, σ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: normPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= \\mu`} = ${μ.toFixed(2)}; \n  **Var** ${tex`= \\sigma^2`} = ${(σ**2).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n    width, height: 260,\n    style: { background: \"var(--plot-panel-bg)\", color: \"var(--brand-fg)\" },\n    x: { label: \"x\" }, y: { label: \"PDF\" },\n    marks: [\n      // shaded area under the PDF:\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n\n      // PDF outline:\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof norm_mu  = Inputs.range([-3, 3], {value: 0, step: 0.05, label: md`${tex`\\mu`}`})\nviewof norm_sig = Inputs.range([0.05, 3], {value: 1, step: 0.05, label: md`${tex`\\sigma`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const μ = lnorm_mu, σ = lnorm_sig;\n  const hi = Math.exp(μ + 5 * σ);\n  const data = linspace(0, hi).map(x =&gt; ({ x, y: lognormPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= e^{\\mu+\\sigma^2/2}`} = ${(Math.exp(μ + (σ**2)/2)).toFixed(2)}; \n  **Var** ${tex`= (e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2}`} = ${(((Math.exp(σ**2)-1)*Math.exp(2*μ + σ**2))).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n  \n}\n\n\n\n\n\n\n\nviewof lnorm_mu  = Inputs.range([-1.5, 2],  {value: 0,   step: 0.1, label: md`${tex`\\mu (\\log X)`}`})\nviewof lnorm_sig = Inputs.range([0.01, 1.5], {value: 0.6, step: 0.01, label: md`${tex`\\sigma (\\log X)`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const ν = Math.round(chi_nu);\n  const hi = Math.max(5, ν + 6 * Math.sqrt(2 * ν));\n  const data = linspace(0, hi).map(x =&gt; ({ x, y: chisqPDF(x, ν) }));\n\n  const stats = md`**Mean** ${tex`= \\nu`} = ${ν}; \n  **Var** ${tex`= 2\\nu`} = ${2*ν}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof chi_nu = Inputs.range([1, 40], {value: 8, step: 1, label: md`${tex`\\nu`}`})\n\n\n\n\n\n\n\n\n\n{\n  const ν = Math.round(t_nu);\n  const data = linspace(-6, 6).map(x =&gt; ({ x, y: tPDF(x, ν) }));\n\n  const stats = md`${tex`\\mathrm{E}[X]=0 (\\nu&gt;1)`}, \n  ${tex`\\operatorname{Var}(X)=\\nu/(\\nu-2)\\ (\\nu&gt;2)`}.  \n  Current: ${ν}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof t_nu = Inputs.range([1, 40], {value: 5, step: 1, label: md`${tex`\\nu`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nUse the tabs to switch distributions. Adjust the sliders to see how the PMF/PDF changes.",
    "crumbs": [
      "Additional Material",
      "Distribution Explorer"
    ]
  },
  {
    "objectID": "content/appendix/question-bank.html",
    "href": "content/appendix/question-bank.html",
    "title": "Question Bank",
    "section": "",
    "text": "bodyFont = getComputedStyle(document.body).fontFamily\n\n\n\n\n\n\n\nallQuestions = Array.from(document.querySelectorAll('.question'))\n\nallTags = Array.from(new Set(\n  allQuestions.flatMap(el =&gt; (el.dataset.tags || \"\")\n    .split(/\\s+/).map(t =&gt; t.trim()).filter(Boolean))\n)).sort()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  for (const el of allQuestions) {\n    // --- Tagbar (unchanged) ---\n    if (!el.querySelector('.tagbar')) {\n      const tags = (el.dataset.tags || \"\").split(/\\s+/).filter(Boolean);\n      const bar = document.createElement('div');\n      bar.className = 'tagbar';\n      bar.append(...tags.map(t =&gt; Object.assign(document.createElement('span'), {\n        className: 'tag', textContent: t\n      })));\n      el.appendChild(bar);\n    }\n\n    // --- Difficulty peppers in header (RHS) ---\n    const header = el.querySelector('.callout-header');\n    if (header && !header.querySelector('.difficulty-peppers')) {\n      const level = Number(el.dataset.difficulty ?? 0);\n\n      // Always show, but only add peppers if &gt;0\n      const span = document.createElement('span');\n      span.className = `difficulty-peppers level-${level}`;\n      span.setAttribute('aria-label', `Difficulty ${level}`);\n      span.textContent = level &gt; 0 ? `(${ \"🌶\".repeat(level) })` : \"( )\";\n      header.appendChild(span);\n    }\n  }\n  return html``  // silence\n}\n\n\n\n\n\n\n\nviewof typed = {\n  // --- DOM\n  const wrapper = html`&lt;div class=\"token-autocomplete\"&gt;&lt;/div&gt;`;\n  const labelEl = html`&lt;label class=\"token-label\"&gt;Filter by tags (type, space-separated):&lt;/label&gt;`;\n  const input   = html`&lt;input class=\"token-input\" type=\"text\" placeholder=\"e.g. bayes probability\"&gt;`;\n  wrapper.append(labelEl, input);\n\n  // --- PORTAL: suggestions list lives at document.body so it can overlay everything\n  const list = html`&lt;div class=\"token-suggestions\" role=\"listbox\" hidden&gt;&lt;/div&gt;`;\n  document.body.appendChild(list);\n\n  // Make sure it floats above all content\n  list.style.position = \"fixed\";\n  list.style.zIndex = \"9999\"; // high z-index to overlay everything\n\n  // --- value plumbing\n  Object.defineProperty(wrapper, \"value\", {\n    get() { return input.value; },\n    set(v) { input.value = v ?? \"\"; }\n  });\n\n  // --- helpers\n  const TAGS = () =&gt; (typeof allTags !== \"undefined\" ? allTags : []);\n  const tokens = () =&gt; input.value.split(/\\s+/).filter(Boolean);\n  const lastToken = () =&gt; (input.value.match(/(?:^|\\s)(\\S*)$/)?.[1]) ?? \"\";\n  const pretty = t =&gt; t.replace(/-/g, \" \").replace(/\\b\\w/g, c =&gt; c.toUpperCase());\n\n  // Position portal directly below the input, matching its width\n  const alignList = () =&gt; {\n    const r = input.getBoundingClientRect();\n    list.style.left = `${r.left}px`;\n    list.style.top  = `${r.bottom + 4}px`;\n    list.style.width = `${r.width}px`;\n  };\n\n  // --- render suggestions\n  let selectedIndex = -1;\n  const applyActiveStyles = () =&gt; {\n    const items = Array.from(list.children);\n    items.forEach((el, i) =&gt; el.classList.toggle(\"active\", i === selectedIndex));\n  };\n\n  function renderSuggestions() {\n    const q = lastToken().toLowerCase();\n    const already = new Set(tokens().map(s =&gt; s.toLowerCase()));\n    const tags = TAGS();\n\n    const candidates = q\n      ? tags.filter(t =&gt; t.toLowerCase().startsWith(q) && !already.has(t.toLowerCase()))\n      : [];\n\n    list.innerHTML = \"\";\n    if (candidates.length === 0) { list.hidden = true; return; }\n\n    for (const t of candidates.slice(0, 8)) {\n      const item = html`&lt;div class=\"token-suggestion\" role=\"option\" data-token=\"${t}\"&gt;${pretty(t)}&lt;/div&gt;`;\n      item.addEventListener(\"mousedown\", (e) =&gt; { e.preventDefault(); acceptSuggestion(t); });\n      list.appendChild(item);\n    }\n    selectedIndex = -1;\n    applyActiveStyles();\n    list.hidden = false;\n    alignList(); // ensure correct position when shown\n  }\n\n  function commit() {\n    const parts = tokens();\n    input.value = parts.join(\" \") + (parts.length ? \" \" : \"\");\n    wrapper.dispatchEvent(new Event(\"input\", { bubbles: true }));\n  }\n\n  function acceptSuggestion(tag) {\n    const parts = input.value.split(/\\s+/);\n    if (/\\S/.test(input.value)) parts.pop(); // replace last token\n    const set = new Set(parts.filter(Boolean).map(s =&gt; s.toLowerCase()));\n    if (!set.has(tag.toLowerCase())) parts.push(tag);\n    input.value = parts.filter(Boolean).join(\" \") + \" \";\n    list.hidden = true;\n    commit();\n    input.focus();\n  }\n\n  function moveSelection(delta) {\n    const items = Array.from(list.children);\n    if (items.length === 0) return;\n    selectedIndex = (selectedIndex + delta + items.length) % items.length;\n    applyActiveStyles();\n    if (selectedIndex &gt;= 0) items[selectedIndex].scrollIntoView({ block: \"nearest\" });\n  }\n\n  // --- events\n  input.addEventListener(\"input\", renderSuggestions);\n  input.addEventListener(\"focus\", () =&gt; { alignList(); }); // realign on focus\n\n  input.addEventListener(\"keydown\", (e) =&gt; {\n    if (!list.hidden && (e.key === \"ArrowDown\" || e.key === \"ArrowUp\")) {\n      e.preventDefault(); moveSelection(e.key === \"ArrowDown\" ? +1 : -1); return;\n    }\n    if (e.key === \"Enter\") {\n      if (!list.hidden && selectedIndex &gt;= 0) {\n        e.preventDefault();\n        const choice = list.children[selectedIndex]?.dataset.token;\n        if (choice) acceptSuggestion(choice);\n      } else {\n        commit();\n      }\n    } else if (e.key === \"Escape\") {\n      list.hidden = true;\n    }\n  });\n\n  // Delay blur to allow mousedown on suggestion to fire first\n  input.addEventListener(\"blur\", () =&gt; {\n    setTimeout(() =&gt; { list.hidden = true; commit(); }, 200);\n  });\n\n  // Close when clicking outside (remember list is outside wrapper now)\n  const onDocClick = (e) =&gt; {\n    if (e.target !== input && !list.contains(e.target)) list.hidden = true;\n  };\n  document.addEventListener(\"click\", onDocClick, true);\n\n  // Reposition on any scroll/resize (capture scrolls from nested containers)\n  const onViewportChange = () =&gt; { if (!list.hidden) alignList(); };\n  window.addEventListener(\"resize\", onViewportChange, { passive: true });\n  window.addEventListener(\"scroll\", onViewportChange, true);\n\n  // Initial alignment\n  queueMicrotask(alignList);\n\n  // Cleanup when the cell re-runs\n  wrapper.dispose = () =&gt; {\n    document.removeEventListener(\"click\", onDocClick, true);\n    window.removeEventListener(\"resize\", onViewportChange, { passive: true });\n    window.removeEventListener(\"scroll\", onViewportChange, true);\n    list.remove();\n  };\n\n  // Initial render\n  renderSuggestions();\n\n  return wrapper;\n}\n\n\n\n\n\n\n\nviewof chosen = Inputs.checkbox(allTags, {\n  label: md`Or pick tags:`,\n  value: []\n})\n\nviewof levels = Inputs.checkbox(\n  [0, 1, 2, 3],\n  {\n    label: md`Difficulty:`,\n    value: [0, 1, 2, 3],                 // default: show all\n    format: d =&gt; [\"Easy\", \"Medium\", \"Hard\", \"Too hard\"][d]\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  // Sync checkboxes to the committed text tokens\n  const lcMap = new Map(allTags.map(t =&gt; [t.toLowerCase(), t])); // lower → original\n  const typedNow = (typed || \"\").split(/\\s+/).filter(Boolean).map(s =&gt; s.toLowerCase());\n  const selected = typedNow.map(s =&gt; lcMap.get(s)).filter(Boolean);\n\n  const el = viewof chosen;\n  if (el && Array.isArray(el.value)) {\n    // compare sets to avoid churn\n    const cur = new Set(el.value);\n    let equal = selected.length === cur.size && selected.every(v =&gt; cur.has(v));\n    if (!equal) {\n      el.value = selected;\n      el.dispatchEvent(new Event(\"input\", {bubbles:true}));\n    }\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n{\n  const typedSet  = new Set((typed || \"\").split(/\\s+/).filter(Boolean));\n  const chosenSet = new Set(chosen || []);\n  const required  = new Set([...typedSet, ...chosenSet]);   // AND over tags\n  const chosenLv  = new Set(levels || []);                  // allowed levels\n\n  let shown = 0;\n  for (const el of allQuestions) {\n    // tags check\n    const elTags = new Set((el.dataset.tags || \"\").split(/\\s+/).filter(Boolean));\n    const passTags = required.size === 0 || [...required].every(t =&gt; elTags.has(t));\n\n    // difficulty check (0 default)\n    const level = Number(el.dataset.difficulty ?? 0);\n    const passDiff = chosenLv.has(level);\n\n    const show = passTags && passDiff;\n    el.style.display = show ? \"\" : \"none\";\n    if (show) shown += 1;\n  }\n\n  return html`&lt;div&gt;&lt;strong&gt;Showing ${shown}&lt;/strong&gt; of ${allQuestions.length} questions.&lt;/div&gt;`\n}\n\n\n\n\n\n\n\n\n\n\n\n\nImportantProbability of heads\n\n\n\nA fair coin is tossed 10 times. What is the probability of exactly 6 heads?\n\n\nSolution\n\nWork it via the Binomial: \n\\mathrm{Pr}(X=6)=\\binom{10}{6} (1/2)^{10}.",
    "crumbs": [
      "Additional Material",
      "Question Bank"
    ]
  },
  {
    "objectID": "content/ide/python-ide.html",
    "href": "content/ide/python-ide.html",
    "title": "Python IDE",
    "section": "",
    "text": "Editor\n    \nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 2*np.pi, 100)\nplt.plot(x, np.sin(x), label='sin(x)')\nplt.plot(x, np.cos(x), label='cos(x)')\nplt.legend()\nplt.title('Trigonometric Functions')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n    \n  \n\n  \n    \n      Output\n      \n        ▶ Run\n        Clear\n        Loading...",
    "crumbs": [
      "Additional Material",
      "Python IDE"
    ]
  }
]