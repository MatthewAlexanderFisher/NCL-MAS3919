[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "",
    "text": "Preface\nWelcome to the online notes for MAS3919 — Foundations of Machine Learning.\nThis course is co-taught for MAS3919 and MAS8607.\nStudents taking MAS8607 can expect to be examined on at least one of the Advanced Topics, indicated with a (\\star) in the table of contents, while these are non-examinable for MAS3919. There will be four Exercise Sheets in total, with solutions presented one week later at Problem Classes.\nThere will be one formative assignment [details] and one summative assignment[details] worth 20% of your overall mark. A written exam forms the remaining 80%.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-is-statistical-inference",
    "href": "index.html#what-is-statistical-inference",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "What is Statistical Inference?",
    "text": "What is Statistical Inference?\nStatistical inference is the process of using data from a sample to learn about a population. Sometimes the population is concrete (e.g. “all people in the country today”). In other situations we want to generalise beyond those we sampled to a broader target population (sometimes called a superpopulation), such as “future patients with similar characteristics”. Clear definitions and sensible assumptions are essential for valid conclusions.\nThere are two main types of statistical inference:\n\nFrequentist inference. Parameters are treated as fixed but unknown. Probability statements are about data we might observe under repeated sampling from the same model.\nBayesian inference. Parameters are treated as random with a prior distribution. Probability statements are about the parameter given the data via the posterior distribution.\n\nThe examples below are only to build intuition about the core difference between frequentist and Bayesian inference. Don’t worry about the details—we’ll cover them carefully later in the course.\n\n\n\n\n\n\n\nExample 1 (A comparison of Frequentist vs Bayesian inference) A survey asks n=20 students if they prefer study space A or B.\nSuppose x=12 prefer A. Compare a frequentist and a Bayesian estimate of the long-run proportion p who would choose A.\n\n   Solution \nFrequentist. The natural estimator is the sample proportion\n\n\\hat p=\\frac{x}{n}=\\frac{12}{20}=0.60.\n\nBayesian (with a uniform prior). Take a \\mathrm{Beta}(1,1) prior for p. The posterior is\n\np \\mid x \\sim \\mathrm{Beta}(1+x,\\,1+n-x)=\\mathrm{Beta}(13,9),\n\nwhose mean is\n\n\\mathrm{E}[p\\mid x]=\\frac{13}{13+9}=\\frac{13}{22}\\approx 0.591.\n\nInterpretation. The frequentist estimate \\hat p is a function of the data and treats p as fixed.\nThe Bayesian estimate is an expectation of p itself under the posterior distribution.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2 (Interpreting probability statements) Decide whether each statement is frequentist or Bayesian in spirit.\n\n“If we repeated the survey many times, the method we use would produce intervals that capture p about 95\\% of the time.”\n\n“Given the data from this survey and our prior, there is a 95\\% probability that p lies between 0.45 and 0.75.”\n\n\n   Solution \n\nFrequentist. This describes long-run coverage of a procedure over repeated samples with p fixed.\n\nBayesian. This is a probability statement about p given the observed data (a credible interval).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#useful-links",
    "href": "index.html#useful-links",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "Useful Links",
    "text": "Useful Links\n\nWeb based R: https://webr.sh/\nWeb based Jupyter Lab (for Python and R): https://jupyter.org/try-jupyter/lab/",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#further-reading",
    "href": "index.html#further-reading",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "Further Reading",
    "text": "Further Reading\n\nStatistical Inference. Casella, George.; Berger, Roger L.\nA student’s guide to Bayesian statistics. Lambert, Ben.\nTheory of statistics. Schervish, Mark J.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "content/main/part1/1-prob-theory.html",
    "href": "content/main/part1/1-prob-theory.html",
    "title": "1  Probability Theory",
    "section": "",
    "text": "1.1 Probability and Events\nBefore we delve into statistical inference, we briefly review key ideas from probability theory.\nWhen working with probability we need three basic ingredients1\nWe can write the definitions of complement, intersection and union formally with sets:",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "content/main/part1/1-prob-theory.html#probability-and-events",
    "href": "content/main/part1/1-prob-theory.html#probability-and-events",
    "title": "1  Probability Theory",
    "section": "",
    "text": "The sample space \\Omega. all possible outcomes of an experiment.\nExample: for a coin toss, \\Omega = \\{\\text{Heads}, \\text{Tails}\\}.\n\nEvents subsets of the sample space. We use capital letters A, B, \\ldots to denote events.\n\nThe complement of A is A^c, meaning A does not occur.\n\nThe intersection A \\cap B means A and B occur.\n\nThe union A \\cup B means A or B (or both) occur.\n\n\nA probability distribution \\mathrm{Pr}. Assigns numbers between 0 and 1 to events, with \\mathrm{Pr}(\\Omega)=1.\n\n\n\n\n\n\n\n\n\nDefinition 1.1 (Complement, Intersection and Union)  \n\nComplement: A^c = \\{x \\in \\Omega \\mid x \\notin A \\}.\nIntersection: A\\cap B = \\{x \\in \\Omega \\mid x \\in A \\text{ and } x \\in B\\}.\n\nUnion: A\\cup B = \\{x \\in \\Omega \\mid x \\in A \\text{ or } x \\in B\\}.\n\n\n\n\n\n\n\n\nShow Visualisation\n\n// Toggle: highlight selection (use explicit values for robust comparisons)\nviewof vennOp = Inputs.radio(\n  [\"None\", \"A\", \"B\", \"Aᶜ\", \"Union\", \"Intersection\"],\n  { value: \"None\", label: \"Highlight:\" }\n)\n\n\n\n\n\n\n\nvenn = {\n  const width = 480, height = 280;\n  const pad = 18;\n\n  const cxA = 190, cyA = 140, r = 90;   // circle A\n  const cxB = 290, cyB = 140;           // circle B\n\n  const svg = d3.create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height]);\n\n  // Sample space Ω (bounding rectangle)\n  const omega = svg.append(\"rect\")\n    .attr(\"x\", pad).attr(\"y\", pad)\n    .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n    .attr(\"rx\", 10)\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", \"currentColor\")\n    .attr(\"stroke-opacity\", 0.5);\n\n  // Label Ω\n  svg.append(\"text\")\n    .attr(\"x\", pad + 8).attr(\"y\", pad + 16)\n    .text(\"Ω\")\n    .style(\"font-weight\", 400)\n    .style(\"font-size\", \"18px\")\n    .style(\"fill\", \"var(--fg-muted)\");\n\n  // Colors (CSS vars with fallbacks)\n  const colA   = \"var(--brand-teal, #14b8a6)\";\n  const colB   = \"var(--brand-red, #ef4444)\";\n  const hilite = \"var(--brand-orange, #F39C65)\";\n  const grid   = \"var(--plot-grid, #94a3b8)\";\n\n  // --- Defs: clips & mask for A^c ---\n  const defs = svg.append(\"defs\");\n\n  defs.append(\"clipPath\").attr(\"id\", \"clipA\")\n    .append(\"circle\").attr(\"cx\", cxA).attr(\"cy\", cyA).attr(\"r\", r);\n\n  defs.append(\"clipPath\").attr(\"id\", \"clipB\")\n    .append(\"circle\").attr(\"cx\", cxB).attr(\"cy\", cyB).attr(\"r\", r);\n\n  // Mask for A^c: white keeps, black removes (subtract circle A from Ω rect)\n  const m = defs.append(\"mask\").attr(\"id\", \"maskAc\");\n  m.append(\"rect\")\n    .attr(\"x\", pad).attr(\"y\", pad)\n    .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n    .attr(\"rx\", 10)\n    .attr(\"fill\", \"white\");\n  m.append(\"circle\")\n    .attr(\"cx\", cxA).attr(\"cy\", cyA).attr(\"r\", r)\n    .attr(\"fill\", \"black\");\n\n  // Base sets (always lightly transparent)\n  svg.append(\"circle\")\n    .attr(\"cx\", cxA).attr(\"cy\", cyA).attr(\"r\", r)\n    .attr(\"fill\", colA).attr(\"fill-opacity\", 0.4);\n\n  svg.append(\"circle\")\n    .attr(\"cx\", cxB).attr(\"cy\", cyB).attr(\"r\", r)\n    .attr(\"fill\", colB).attr(\"fill-opacity\", 0.4);\n\n  // Highlight layer\n  if (vennOp === \"A\") {\n    svg.append(\"circle\")\n      .attr(\"cx\", cxA).attr(\"cy\", cyA).attr(\"r\", r)\n      .attr(\"fill\", hilite).attr(\"fill-opacity\", 0.99);\n\n  } else if (vennOp === \"B\") {\n    svg.append(\"circle\")\n      .attr(\"cx\", cxB).attr(\"cy\", cyB).attr(\"r\", r)\n      .attr(\"fill\", hilite).attr(\"fill-opacity\", 0.99);\n\n  } else if (vennOp === \"Aᶜ\") {\n    // Draw Ω in orange, but masked to remove A\n    svg.append(\"rect\")\n      .attr(\"x\", pad).attr(\"y\", pad)\n      .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n      .attr(\"rx\", 10)\n      .attr(\"fill\", hilite).attr(\"fill-opacity\", 0.99)\n      .attr(\"mask\", \"url(#maskAc)\");\n\n  } else if (vennOp === \"Union\") {\n    // A ∪ B: overlay both circles solid orange\n    svg.append(\"circle\")\n      .attr(\"cx\", cxA).attr(\"cy\", cyA).attr(\"r\", r)\n      .attr(\"fill\", hilite).attr(\"fill-opacity\", 0.99);\n    svg.append(\"circle\")\n      .attr(\"cx\", cxB).attr(\"cy\", cyB).attr(\"r\", r)\n      .attr(\"fill\", hilite).attr(\"fill-opacity\", 0.99);\n\n  } else if (vennOp === \"Intersection\") {\n    // A ∩ B: clip B by A (equivalently clip A by B)\n    svg.append(\"g\").attr(\"clip-path\", \"url(#clipA)\")\n      .append(\"circle\")\n      .attr(\"cx\", cxB).attr(\"cy\", cyB).attr(\"r\", r)\n      .attr(\"fill\", hilite).attr(\"fill-opacity\", 0.99);\n  }\n\n  // Labels A and B\n  svg.append(\"text\")\n    .attr(\"x\", cxA - 26).attr(\"y\", cyA - 8)\n    .text(\"A\")\n    .style(\"font-size\", \"14px\")\n    .style(\"font-weight\", 600)\n    .style(\"fill\", \"var(--fg-muted)\");\n\n  svg.append(\"text\")\n    .attr(\"x\", cxB + 22).attr(\"y\", cyB - 8)\n    .text(\"B\")\n    .style(\"font-size\", \"14px\")\n    .style(\"font-weight\", 600)\n    .style(\"fill\", \"var(--fg-muted)\");\n\n  // Subtle baseline\n  svg.append(\"line\")\n    .attr(\"x1\", pad).attr(\"x2\", width - pad)\n    .attr(\"y1\", height - pad - 0.5).attr(\"y2\", height - pad - 0.5)\n    .attr(\"stroke\", grid).attr(\"stroke-opacity\", 0.2);\n\n  return svg.node();\n}\n\n\n\n\n\n\n\n\nFigure 1.1: Venn diagram of two events A and B inside the sample space \\Omega.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.2 (Addition rule (inclusion–exclusion)) For any two events A, B\\subseteq \\Omega, we have \n\\mathrm{Pr}(A \\cup B) = \\mathrm{Pr}(A) + \\mathrm{Pr}(B) - \\mathrm{Pr}(A \\cap B).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.1 (A quick inclusion–exclusion check) Roll a fair six-sided die. Let A=\\{\\text{even}\\} and B=\\{\\text{number} \\ge 4\\}. Compute \\mathrm{Pr}(A\\cup B).\n\n   Solution \nWe have\n\n\\mathrm{Pr}(A)=3/6=1/2 (even outcomes 2,4,6).\n\n\\mathrm{Pr}(B)=3/6=1/2 (outcomes 4,5,6).\n\n\\mathrm{Pr}(A\\cap B)=2/6=1/3 (outcomes 4,6).\n\nBy inclusion–exclusion 1.2, \n\\mathrm{Pr}(A\\cup B)=\\tfrac{1}{2}+\\tfrac{1}{2}-\\tfrac{1}{3}=\\tfrac{2}{3}.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.3 (Mutually Exclusive, Exhaustive Events, and Partitions)  \n\nTwo events A and B are mutually exclusive (or disjoint) if they cannot occur together: \n\\mathrm{Pr}(A \\cap B) = 0.\n\nTwo events A and B are exhaustive if at least one of them must occur: \n\\mathrm{Pr}(A \\cup B) = 1.\n\nMore generally, a collection of events \\{B_1,\\ldots,B_k\\} is exhaustive if \\bigcup_{i=1}^k B_i = \\Omega, where \\Omega is the sample space.\nA collection of events \\{B_1,\\ldots,B_k\\} forms a partition of \\Omega if they are both mutually exclusive and exhaustive. Equivalently,\n\nB_i \\cap B_j = \\varnothing for all i \\neq j (non-overlapping), and\n\n\\bigcup_{i=1}^k B_i = \\Omega (their union is the whole sample space).\n\n\n\n\n\n\n\n\nShow Visualisation\n\n{\n  const width = 720, height = 360;\n  const pad = 20;\n\n  // colour cycle from theme accents\n  const brand = [\n    \"var(--brand-teal, #55C3CB)\",\n    \"var(--brand-orange, #F39C65)\",\n    \"var(--brand-purple, #A180DA)\",\n    \"var(--brand-mint, #DDFFEB)\",\n    \"var(--brand-red, #e65660)\"\n  ];\n  const col = i =&gt; brand[i % brand.length];\n\n  // seeded RNG so \"Reseed\" changes layout deterministically per click\n  const rng = d3.randomLcg(reseed || 1);\n\n  // generate n sites inside Ω (inset by padding)\n  const sites = d3.range(n).map(i =&gt; ({\n    name: `B${i+1}`,\n    x: pad + rng() * (width - 2*pad),\n    y: pad + rng() * (height - 2*pad)\n  }));\n\n  const delaunay = d3.Delaunay.from(sites, d =&gt; d.x, d =&gt; d.y);\n  const vor = delaunay.voronoi([pad, pad, width - pad, height - pad]);\n\n  const svg = d3.create(\"svg\")\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .style(\"background\", \"var(--brand-bg)\")\n    .style(\"font-family\", bodyFont)\n    .style(\"font-size\", \"14px\");\n\n  // --- defs: rounded-rect clip for Ω ---\n  const defs = svg.append(\"defs\");\n  defs.append(\"clipPath\")\n    .attr(\"id\", \"clipOmega\")\n    .append(\"rect\")\n      .attr(\"x\", pad).attr(\"y\", pad)\n      .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n      .attr(\"rx\", 10);\n\n  // cells (clipped to rounded Ω so no sharp outer box)\n  const g = svg.append(\"g\").attr(\"clip-path\", \"url(#clipOmega)\");\n  const polys = [];  // store polygons for centroid labelling\n\n  for (let i = 0; i &lt; sites.length; i++) {\n    const poly = vor.cellPolygon(i);\n    if (!poly) continue;\n    polys.push({ i, poly, name: sites[i].name });\n    g.append(\"path\")\n      .attr(\"d\", d3.line()(poly))\n      .attr(\"fill\", col(i))\n      .attr(\"fill-opacity\", 0.2)\n      .attr(\"stroke\", \"currentColor\")\n      .attr(\"stroke-opacity\", 0.28);\n  }\n\n  // label font size adapts to n (clamped between 10px and 14px)\n  const fz = Math.max(10, Math.min(14, 16 - 0.5 * (n - 3)));\n\n  // labels at polygon centroids (true centre for convex Voronoi cells)\n  svg.append(\"g\")\n    .selectAll(\"text\")\n    .data(polys.map(d =&gt; {\n      const [cx, cy] = d3.polygonCentroid(d.poly);\n      return { x: cx, y: cy, name: d.name };\n    }))\n    .join(\"text\")\n      .attr(\"x\", d =&gt; d.x)\n      .attr(\"y\", d =&gt; d.y)\n      .text(d =&gt; d.name)\n      .attr(\"font-weight\", 700)\n      .attr(\"fill\", \"currentColor\")\n      .attr(\"font-size\", `${fz}px`)\n      .attr(\"text-anchor\", \"middle\")\n      .attr(\"dominant-baseline\", \"middle\");\n\n  // Ω frame (single rounded rectangle, drawn last)\n  svg.append(\"rect\")\n    .attr(\"x\", pad).attr(\"y\", pad)\n    .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n    .attr(\"rx\", 10)\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", \"currentColor\")\n    .attr(\"stroke-opacity\", 0.55);\n\n  // Ω label\n  svg.append(\"text\")\n    .attr(\"x\", pad + 8).attr(\"y\", pad + 16)\n    .text(\"Ω\")\n    .style(\"font-weight\", 400)\n    .style(\"font-size\", \"18px\")\n    .attr(\"fill\", \"currentColor\");\n\n  return svg.node();\n}\n\n\n\n\n\n\n\n\nFigure 1.2: A decomposition of the sample space \\Omega into a partition B_1,\\ldots,B_k. Subsets B_i are mutually exclusive and exhaustive; every point in \\Omega lies in exactly one B_i.\n\n\n\n\n\nviewof controls = {\n  const resBtn = Inputs.button(\"Reseed points\");\n  resBtn.classList.add(\"btn-resim\");\n\n  const leftForm = Inputs.form(\n    { n: Inputs.range([3, 50], { value: 10, step: 1, label: md`${tex`k`}: number of sets` }) },\n    { submit: false }\n  );\n  const rightForm = Inputs.form({ reseed: resBtn }, { submit: false });\n\n  const root = html`&lt;div class=\"controls-wrap\"&gt;\n    &lt;details class=\"controls-root\" open&gt;\n      &lt;summary&gt;Partition controls&lt;/summary&gt;\n      &lt;div class=\"controls-grid\"&gt;\n        &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Number of regions&lt;/h4&gt;&lt;/div&gt;\n        &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Randomisation&lt;/h4&gt;&lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/details&gt;\n  &lt;/div&gt;`;\n\n  const grid = root.querySelector(\".controls-grid\");\n  const leftCol = grid.children[0];\n  const rightCol = grid.children[1];\n  leftCol.append(leftForm);\n  rightCol.append(rightForm);\n\n  const getValue = () =&gt; ({ ...leftForm.value, ...rightForm.value });\n  const update = () =&gt; {\n    root.value = getValue();\n    root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true }));\n  };\n  grid.addEventListener(\"input\", update);\n  queueMicrotask(update);\n  return root;\n}\n\n// reactive bindings for the plot\nn = controls.n\nreseed = controls.reseed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.4 (Conditional probability) If \\mathrm{Pr}(B) &gt; 0, the probability of A given B is \n\\mathrm{Pr}(A \\mid B) = \\frac{\\mathrm{Pr}(A \\cap B)}{\\mathrm{Pr}(B)}.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.5 (Independence) Two events A and B are independent if knowing that one occurs does not change the probability of the other: \n\\mathrm{Pr}(A \\cap B) = \\mathrm{Pr}(A)\\mathrm{Pr}(B).\n Equivalently, \n\\mathrm{Pr}(A\\mid B) = \\mathrm{Pr}(A) \\quad \\text{and} \\quad \\mathrm{Pr}(B\\mid A) = \\mathrm{Pr}(B)\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 1.1 (Law of Total Probability) If B_1,\\dots,B_k form a partition 1.3 of the sample space (mutually exclusive and exhaustive events), then for any event A: \n\\mathrm{Pr}(A) = \\sum_{i=1}^k \\mathrm{Pr}(A \\mid B_i)\\mathrm{Pr}(B_i).\n\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 1.1. Since B_1\\ldots, B_n form a partition of \\Omega, we can decompose any event A in a disjoint union of intersections: \nA = \\bigcup_{i=1}^n (A\\cap B_i).\n By induction on the addition rule 1.2, we thus have \n\\mathrm{Pr}(A) = \\sum_{i=1}^n \\mathrm{Pr}(A\\cap B_i).\n By the definition of conditional probability 1.4, we have \\mathrm{Pr}(A\\cap B_i) = \\mathrm{Pr}(A\\mid B_i) \\mathrm{Pr}(B_i). Therefore,\n\n\\mathrm{Pr}(A) =  \\sum_{i=1}^n \\mathrm{Pr}(A \\mid B_i)\\mathrm{Pr}(B_i).\n\n\n\n\n\n\n\nShow Visualisation\n\n{\n  const width = 720, height = 360;\n  const pad = 20;\n\n  // colours\n  const brand = [\n    \"var(--brand-teal, #55C3CB)\",\n    \"var(--brand-purple, #A180DA)\",\n    \"var(--brand-mint, #DDFFEB)\",\n    \"var(--brand-red, #e65660)\"\n  ];\n  const col = i =&gt; brand[i % brand.length];\n  const orange = \"var(--brand-orange, #F39C65)\";\n\n  // deterministic RNG\n  const rng = d3.randomLcg(2);\n\n  // Voronoi sites\n  const sites = d3.range(n2).map(i =&gt; ({\n    name: `B${i+1}`,\n    x: pad + rng() * (width - 2*pad),\n    y: pad + rng() * (height - 2*pad)\n  }));\n\n  const delaunay = d3.Delaunay.from(sites, d =&gt; d.x, d =&gt; d.y);\n  const vor = delaunay.voronoi([pad, pad, width - pad, height - pad]);\n\n  const svg = d3.create(\"svg\")\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .style(\"background\", \"var(--brand-bg)\")\n    .style(\"font-family\", bodyFont)\n    .style(\"font-size\", \"14px\");\n\n  // --- defs: rounded-rect clip for Ω + per-cell clipPaths + ellipse for A ---\n  const defs = svg.append(\"defs\");\n\n  defs.append(\"clipPath\")\n    .attr(\"id\", \"clipOmega-lotp2\")\n    .append(\"rect\")\n      .attr(\"x\", pad).attr(\"y\", pad)\n      .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n      .attr(\"rx\", 10);\n\n  // Per-cell clipPaths (so we can draw A∩B_i by clipping the ellipse to each cell)\n  for (let i = 0; i &lt; sites.length; i++) {\n    const poly = vor.cellPolygon(i);\n    if (!poly) continue;\n    defs.append(\"clipPath\")\n      .attr(\"id\", `clipCell-lotp2-${i}`)\n      .append(\"path\")\n      .attr(\"d\", d3.line()(poly));\n  }\n\n  // A: ellipse geometry\n  const Ax = width * 0.50, Ay = height * 0.52;  // centre\n  const Arx = width * 0.42, Ary = height * 0.4;\n\n  // Draw A outline (thin) so learners see the target set even before fills\n  svg.append(\"ellipse\")\n    .attr(\"cx\", Ax).attr(\"cy\", Ay)\n    .attr(\"rx\", Arx).attr(\"ry\", Ary)\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", orange)\n    .attr(\"stroke-width\", 2)\n    .attr(\"clip-path\", \"url(#clipOmega-lotp2)\");\n\n  // --- Voronoi cells: visible strokes on TOP of orange pieces ---\n  const strokes = svg.append(\"g\").attr(\"clip-path\", \"url(#clipOmega-lotp2)\");\n  const polys = [];\n  for (let i = 0; i &lt; sites.length; i++) {\n    const poly = vor.cellPolygon(i);\n    if (!poly) continue;\n    polys.push({ i, poly, name: sites[i].name });\n    strokes.append(\"path\")\n      .attr(\"d\", d3.line()(poly))\n      .attr(\"stroke\", \"currentColor\")\n      .attr(\"fill\", col(i))\n      .attr(\"fill-opacity\", 0.2)\n      .attr(\"stroke-opacity\", 0.55);\n  }\n\n  // Labels at polygon centroids; adaptive font size\n  const fz2 = Math.max(10, Math.min(14, 16 - 0.3 * (n2 - 3)));\n  svg.append(\"g\")\n    .selectAll(\"text\")\n    .data(polys.map(d =&gt; {\n      const [cx, cy] = d3.polygonCentroid(d.poly);\n      return { x: cx, y: cy, name: d.name };\n    }))\n    .join(\"text\")\n      .attr(\"x\", d =&gt; d.x)\n      .attr(\"y\", d =&gt; d.y)\n      .text(d =&gt; d.name)\n      .attr(\"font-weight\", 700)\n      .attr(\"fill\", \"var(--fg-muted)\")\n      .attr(\"font-size\", `${fz2}px`)\n      .attr(\"text-anchor\", \"middle\")\n      .attr(\"dominant-baseline\", \"middle\");\n\n  // --- A∩B_i pieces (orange), revealed up to 'frame2' ---\n  const overlaps = svg.append(\"g\").attr(\"clip-path\", \"url(#clipOmega-lotp2)\");\n  for (let i = 0; i &lt; sites.length; i++) {\n    overlaps.append(\"ellipse\")\n      .attr(\"cx\", Ax).attr(\"cy\", Ay)\n      .attr(\"rx\", Arx).attr(\"ry\", Ary)\n      .attr(\"fill\", orange)\n      .attr(\"fill-opacity\", i &lt; frame2 ? 1. : 0)  // reveal progressively\n      .attr(\"clip-path\", `url(#clipCell-lotp2-${i})`);\n  }\n\n\n  // Ω frame\n  svg.append(\"rect\")\n    .attr(\"x\", pad).attr(\"y\", pad)\n    .attr(\"width\", width - 2*pad).attr(\"height\", height - 2*pad)\n    .attr(\"rx\", 10)\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", \"currentColor\")\n    .attr(\"stroke-opacity\", 0.55);\n\n  // Ω label\n  svg.append(\"text\")\n    .attr(\"x\", pad + 8).attr(\"y\", pad + 16)\n    .text(\"Ω\")\n    .style(\"font-weight\", 400)\n    .style(\"font-size\", \"18px\")\n    .attr(\"fill\", \"currentColor\");\n\n  // A label\n  svg.append(\"text\")\n    .attr(\"x\", Ax).attr(\"y\", Ay)\n    .text(\"A\")\n    .attr(\"fill\", \"currentColor\")\n    .attr(\"font-size\", 18)\n    .attr(\"font-weight\", 700)\n    .attr(\"text-anchor\", \"middle\");\n\n  return svg.node();\n}\n\n\n\n\n\n\n\n\nFigure 1.3: Law of Total Probability visualised. An event A (orange) overlaps a partition B_1,\\ldots,B_{k} of \\Omega. The shaded pieces A\\cap B_i decompose \\operatorname{Pr}(A) as \\operatorname{Pr}(A)= \\sum_i \\operatorname{Pr}(A \\cap B_i).\n\n\n\n\n\n// Animation driver: each button click restarts the reveal\nframe2 = {\n  if (!click2) return 0;\n  const delay = 600;\n  let i = 0;\n  while (i &lt;= n2) {\n    yield i;\n    await Promises.delay(delay);\n    i++;\n  }\n  return i;\n}\n\n\n\n\n\n\n\nviewof controls2 = {\n  const leftForm  = Inputs.form(\n    { n: Inputs.range([3, 50], { value: 10, step: 1, label: md`${tex`k`}: number of sets` }) },\n    { submit:false }\n  );\n\n  const playBtn = Inputs.button(\"▶ Play\");\n  playBtn.classList.add(\"btn-resim\");  // reuse your teal button style\n\n  const rightForm = Inputs.form({ click2: playBtn }, { submit:false });\n\n  const root = html`&lt;div class=\"controls-wrap\"&gt;\n    &lt;details class=\"controls-root\" open&gt;\n      &lt;summary&gt;Law of Total Probability controls&lt;/summary&gt;\n      &lt;div class=\"controls-grid\"&gt;\n        &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Partition size&lt;/h4&gt;&lt;/div&gt;\n        &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Animation&lt;/h4&gt;&lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/details&gt;\n  &lt;/div&gt;`;\n\n  const grid = root.querySelector(\".controls-grid\");\n  grid.children[0].append(leftForm);\n  grid.children[1].append(rightForm);\n\n  const getValue = () =&gt; ({ ...leftForm.value, ...rightForm.value });\n  const update = () =&gt; { root.value = getValue(); root.dispatchEvent(new CustomEvent(\"input\", { bubbles:true })); };\n  grid.addEventListener(\"input\", update);\n  queueMicrotask(update);\n  return root;\n}\n\n// reactive\nn2     = controls2.n\nclick2 = controls2.click2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 1.2 (Bayes’ Theorem) If \\mathrm{Pr}(B) &gt; 0, then \n\\mathrm{Pr}(A \\mid B) = \\frac{\\mathrm{Pr}(B \\mid A)\\mathrm{Pr}(A)}{\\mathrm{Pr}(B)}.\n\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 1.2. From the definition of conditional probability 1.4,\n\n\\mathrm{Pr}(A \\mid B) = \\frac{\\mathrm{Pr}(A \\cap B)}{\\mathrm{Pr}(B)}.\n\nBut the intersection A \\cap B can also be written the other way round: \n\\mathrm{Pr}(A \\cap B) = \\mathrm{Pr}(B \\cap A).\n\nUsing the definition of conditional probability again, \n\\mathrm{Pr}(B \\cap A) = \\mathrm{Pr}(B \\mid A)\\mathrm{Pr}(A).\n\nSubstituting this into the first expression gives \n\\mathrm{Pr}(A \\mid B) = \\frac{\\mathrm{Pr}(B \\mid A)\\mathrm{Pr}(A)}{\\mathrm{Pr}(B)}.\n\nThis completes the proof.\n\n\n\n\n\n\n\n\n\n\n\nExample 1.2 (Student Example) Seventy percent of students are attentive in lectures and thirty percent are not. If a student is attentive the probability of passing the course is 0.8. If a student is not attentive the probability of passing the course is 0.1.\n\nA student is selected at random. What is the probability that they pass the course?\nGiven that the student passed the course, what is the probability that they were attentive?\n\n\n   Solution \nLet\n\nP denote the event of a student passing the course.\nA denote the event of a student being attentive.\nA^c denote the event of a student not being attentive.\n\n\nAttentive and inattentive form a partition. By the law of total probability,\n\n\n\\mathrm{Pr}(P)=\\mathrm{Pr}(P\\mid A)\\mathrm{Pr}(A)+\\mathrm{Pr}(P\\mid A^c)\\mathrm{Pr}(A^c)=0.8\\times0.7+0.1\\times0.3=0.59.\n\n\nUsing Bayes’ theorem,\n\n\n\\mathrm{Pr}(A\\mid P)=\\frac{\\mathrm{Pr}(P\\mid A)\\mathrm{Pr}(A)}{\\mathrm{Pr}(P)}\n=\\frac{0.8\\times0.7}{0.59}=0.949\\ \\text{(3 s.f.)}.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "content/main/part1/1-prob-theory.html#random-variables",
    "href": "content/main/part1/1-prob-theory.html#random-variables",
    "title": "1  Probability Theory",
    "section": "1.2 Random Variables",
    "text": "1.2 Random Variables\nWe use upper-case letters for random variables, e.g. X, Y, X_1, X_2,\\dots.\n\nCumulative distribution function (cdf). For any (real-valued) random variable X,\n\nF(x)=\\mathrm{Pr}(X\\le x).\n\nDiscrete case (pmf). If X is discrete, its probability mass function is\n\np(x)=\\mathrm{Pr}(X=x),\\qquad \\sum_x p(x)=1.\n\nContinuous case (pdf). If X is continuous, its probability density function satisfies\n\nf(x)=\\frac{\\partial F(x)}{\\partial x},\\qquad \\mathrm{Pr}(a&lt;X\\le b)=\\int_a^b f(x)\\,\\mathrm{d}x,\\qquad \\int_{-\\infty}^{\\infty} f(x)\\,\\mathrm{d}x=1.\n\n\n\n\n\n\n\n\n\nExample 1.3 (Discrete CDF.) Let X be the outcome of a fair six-sided die. Find p(x) and F(3).\n\n   Solution \np(x)=\\mathrm{Pr}(X=x)=1/6 for x\\in\\{1,2,3,4,5,6\\}, and 0 otherwise.\nF(3)=\\mathrm{Pr}(X\\le 3)=\\mathrm{Pr}(\\{1,2,3\\})=3\\times(1/6)=1/2.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.4 Let X\\sim \\mathrm{Uniform}(0,1). Compute \\mathrm{Pr}(0.2&lt;X&lt;0.5).\n\n   Solution \nHere f(x)=1 for 0&lt;x&lt;1 and 0 otherwise.\n\n\\mathrm{Pr}(0.2&lt;X&lt;0.5)=\\int_{0.2}^{0.5} 1\\,dx = 0.3.\n\n\n\n\n\n\n\n1.2.1 Joint, Marginal, and Conditional Densities\nSuppose X and Y are random variables with joint PDF/PMF f_{XY}(x,y) (often written f(x,y)). From this joint distribution we can define:\n\nMarginal distributions: the distribution of each variable on its own.\n\nConditional distributions: the distribution of one variable given the other.\n\nIndependence: the case where the joint factorises.\n\n\n\n\n\n\n\n\nDefinition 1.6 (Marginal Distributions) If we only care about X, regardless of Y, we integrate/sum out Y: \nf_X(x) = \\int f(x,y)\\,\\mathrm{d}y.\n Similarly for f_Y(y).\nNote: knowing the marginals does not determine the joint.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.7 (Conditional Densities) For y in the support of Y with f_Y(y) &gt; 0, we define: \nf_{X \\mid Y}(x \\mid y) = \\frac{f(x,y)}{f_Y(y)}.\n This describes the distribution of X given Y=y.\n\n\n\n\n\n\n\n\n\n\n\nTheorem 1.3 (Law of Total Probability) We can recover the marginal by “averaging” the conditional over Y: \nf_X(x) = \\int f_{X \\mid Y}(x \\mid y) f_Y(y)\\,\\mathrm{d}y.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.8 (Independence) X and Y are independent if and only if \nf(x,y) = f_X(x) f_Y(y).\n In this case, f_{X \\mid Y}(x \\mid y) = f_X(x): knowing Y tells us nothing about X.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "content/main/part1/1-prob-theory.html#expectations-variances-and-covariances",
    "href": "content/main/part1/1-prob-theory.html#expectations-variances-and-covariances",
    "title": "1  Probability Theory",
    "section": "1.3 Expectations, Variances and Covariances",
    "text": "1.3 Expectations, Variances and Covariances\n\n\n\n\n\n\n\nDefinition 1.9 (Expected Value) The expected value (or population mean) of X is \n\\mathrm{E}[X] =\n\\begin{cases}\n\\displaystyle \\sum_{\\text{all } x} x\\,p_X(x), & \\text{if $X$ is discrete}, \\\\\n\\displaystyle \\int_{-\\infty}^{\\infty} x\\,f_X(x)\\,\\mathrm{d}x, & \\text{if $X$ is continuous}.\n\\end{cases}\n\nWe often write \\mu = \\mathrm{E}[X]. This is a measure of location.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.10 (Expectation of g(X)) Let g(\\cdot) be any function and X a random variable with PMF p_X (discrete) or PDF f_X (continuous). The expected value of g(X) is \n\\mathrm{E}[g(X)] =\n\\begin{cases}\n\\displaystyle \\sum_{\\text{all } x} g(x)\\,p_X(x), & \\text{if $X$ is discrete},\\\\\n\\displaystyle \\int_{-\\infty}^{\\infty} g(x)\\,f_X(x)\\,\\mathrm{d}x, & \\text{if $X$ is continuous}.\n\\end{cases}\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.11 (Expectation (Bivariate)) If (X,Y) is a pair of random variables with joint PMF p_{X,Y} (discrete) or joint PDF f_{X,Y} (continuous), then for any function g(x,y) \n\\mathrm{E}[g(X,Y)] =\n\\begin{cases}\n\\displaystyle \\sum_{\\text{all } x}\\sum_{\\text{all } y} g(x,y)\\,p_{X,Y}(x,y), & \\text{if $(X,Y)$ are discrete},\\\\\n\\displaystyle \\int\\!\\!\\!\\int g(x,y)\\,f_{X,Y}(x,y)\\,\\mathrm{d}x\\,\\mathrm{d}y, & \\text{if $(X,Y)$ are continuous}.\n\\end{cases}\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.12 (Moments) The quantities \\mathrm{E}[X], \\mathrm{E}[X^2], \\mathrm{E}[X^3], \\ldots are the (raw) moments of X.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.13 (Variance) The population variance of X is \n\\mathrm{Var}(X) = \\mathrm{E}\\!\\left[(X-\\mathrm{E}[X])^2\\right]\n= \\mathrm{E}[X^2] - \\big(\\mathrm{E}[X]\\big)^2.\n We often write \\sigma^2 = \\mathrm{Var}(X). This is a measure of spread.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.14 (Standard Deviation) The population standard deviation is the positive square root of the variance: \n\\mathrm{SD}(X) = \\sqrt{\\mathrm{Var}(X)}.\n We often write \\sigma = \\mathrm{SD}(X). It shares the same units as X and measures spread.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.15 (Covariance) For two random variables X and Y, the covariance is \n\\mathrm{Cov}(X,Y)\n= \\mathrm{E}\\!\\left[(X-\\mathrm{E}[X])(Y-\\mathrm{E}[Y])\\right]\n= \\mathrm{E}[XY] - \\mathrm{E}[X]\\mathrm{E}[Y].\n It measures linear association: positive if Y tends to increase with X; negative if Y tends to decrease as X increases.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.16 (Correlation) The correlation (often denoted \\rho) is the scaled covariance \n\\rho = \\mathrm{Corr}(X,Y) = \\frac{\\mathrm{Cov}(X,Y)}{\\mathrm{SD}(X)\\,\\mathrm{SD}(Y)}.\n Correlation always satisfies \\rho \\in [-1,1].\n\n\n\n\n\n\n\n\n\n\n\nTheorem 1.4 (Independence \\Rightarrow Zero Covariance) If X and Y are independent, then \\mathrm{Cov}(X,Y)=0.\nNote. The converse need not hold: it is possible to have \\mathrm{Cov}(X,Y)=0 while X and Y are not independent.\n\n\n\n\n\n\n\n\n\n\n\nExample 1.5 (Variance of a Bernoulli Random Variable) A Bernoulli random variable 1.1 X takes only the values 0 and 1, with probabilities \n\\operatorname{Pr}(X=1) = p, \\qquad \\operatorname{Pr}(X=0) = 1-p, \\qquad 0 \\leq p \\leq 1.\n\nFor what value of p is the variance maximised?\n\n   Solution \nWe compute the mean and variance of X.\n\n\\mathrm{E}[X] = 1 \\cdot p + 0 \\cdot (1-p) = p,\n\n\n\\mathrm{E}[X^2] = 1^2 \\cdot p + 0^2 \\cdot (1-p) = p.\n\nTherefore, \n\\mathrm{Var}(X) = \\mathrm{E}[X^2] - \\big(\\mathrm{E}[X]\\big)^2 = p - p^2 = p(1-p).\n\n\nTo find the value of p that maximises this variance, consider the function \nf(p) = p(1-p), \\quad 0 \\leq p \\leq 1.\n\nDifferentiate: \nf'(p) = 1 - 2p.\n\nSetting f'(p) = 0 gives p = \\tfrac{1}{2}.\nSecond derivative: \nf''(p) = -2 &lt; 0,\n so this is indeed a maximum.\nFinally, check the boundary values: \nf(0) = 0, \\qquad f(1) = 0, \\qquad f\\!\\left(\\tfrac{1}{2}\\right) = \\tfrac{1}{4}.\n\n\nConclusion.\nThe variance of a Bernoulli random variable is maximised at\n\np = \\tfrac{1}{2}, \\quad \\mathrm{Var}(X) = \\tfrac{1}{4}.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "content/main/part1/1-prob-theory.html#non-examinable-material",
    "href": "content/main/part1/1-prob-theory.html#non-examinable-material",
    "title": "1  Probability Theory",
    "section": "1.4 Non-Examinable Material",
    "text": "1.4 Non-Examinable Material\n\n\n\n\n\n\nWarningNon-Examinable Content\n\n\n\nThis section provides definitions and results that are used in non-examinable proofs and remarks elsewhere in the notes.\nNone of the material in this section is examinable.\n\n\n\n\n1.4.1 Convergence of Random Variables\n\n\n\n\n\n\n\nDefinition 1.17 (Convergence in Probability) A sequence of random variables X_n is said to converge in probability to a random variable X if, for every \\varepsilon &gt; 0,\n\n\\Pr\\big(|X_n - X| &gt; \\varepsilon\\big) \\;\\longrightarrow\\; 0\n\\quad \\text{as } n \\to \\infty.\n\nWe write this as \nX_n \\xrightarrow{p} X.\n\nIntuitively: as n grows, the probability that X_n is far from X becomes negligible.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1.18 (Convergence in Distribution) A sequence of random variables X_n is said to converge in distribution to a random variable X if, for all continuity points x of F_X,\n\nF_{X_n}(x) \\;\\longrightarrow\\; F_X(x)\n\\quad \\text{as } n \\to \\infty,\n\nwhere F_{X_n} and F_X are the cumulative distribution functions.\nWe write this as \nX_n \\xrightarrow{d} X.\n\nIntuitively: the distribution of X_n “settles down” and approaches that of X.\n\n\n\n\n\n\n\n\n\n\nNoteRelationship\n\n\n\nConvergence in probability is stronger than convergence in distribution:\n\nX_n \\xrightarrow{p} X \\;\\;\\;\\implies\\;\\;\\; X_n \\xrightarrow{d} X.\n But not the other way around.\n\n\n\n\n\n1.4.2 Probability Inequalities\n\n\n\n\n\n\n\nProposition 1.1 (Chebyshev’s Inequality) If a random variable X has mean \\mu and variance \\sigma^2 &lt; \\infty, then for any \\varepsilon &gt; 0,\n\n\\Pr\\big(|X - \\mu| \\geq \\varepsilon\\big)\n\\;\\leq\\; \\frac{\\sigma^2}{\\varepsilon^2}.\n\nThis provides a bound on the probability of large deviations from the mean.\n\n\n\n\n\n\n\n1.4.3 Factorising the Joint\n\n\n\n\n\n\n\nProposition 1.2 (The Chain Rule) Let \\underline{X} = (X_1,\\ldots, X_n) with joint PDF/PMF f(\\underline{x}). Then \nf(\\underline{x}) \\;=\\; f(x_1)\\;\\prod_{t=2}^n f \\big(x_t \\mid x_1, \\ldots, x_{t-1}\\big).\n\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 1.3 (Not Examinable). We use the definition of conditional PDF/PMF (Definition 1.7) and induction.\n\nBase case (n=2). By definition, \nf(x_2\\mid x_1) \\;=\\; \\frac{f(x_1,x_2)}{f(x_1)} \\quad \\text{(for $f(x_1)&gt;0$),}\n hence f(x_1,x_2)=f(x_1)\\,f(x_2\\mid x_1).\nInductive step. For k\\ge 2, \nf(x_1,\\ldots,x_k)\n\\;=\\; f(x_1,\\ldots,x_{k-1})\\, f(x_k\\mid x_1,\\ldots,x_{k-1}),\n again by Definition 1.7: \nf(x_k\\mid x_1,\\ldots,x_{k-1})\n\\;=\\; \\frac{f(x_1,\\ldots,x_k)}{f(x_1,\\ldots,x_{k-1})}.\n Iterating this factorisation from k=2 up to k=n yields \nf(x_1,\\ldots,x_n)\n\\;=\\; f(x_1)\\prod_{t=2}^n f(x_t\\mid x_1,\\ldots,x_{t-1}).\n\n\nTelescoping viewpoint. Equivalently, \n\\prod_{t=2}^n f(x_t\\mid x_1,\\ldots,x_{t-1})\n= \\prod_{t=2}^n \\frac{f(x_1,\\ldots,x_t)}{f(x_1,\\ldots,x_{t-1})}\n= \\frac{f(x_1,\\ldots,x_n)}{f(x_1)},\n so rearranging gives the same result.\n\nRemarks.\n\nThe argument applies to both PMFs and PDFs (assuming the relevant conditionals exist).\nThe identity does not assume independence; it is always valid wherever the conditionals are defined.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "content/main/part1/1-prob-theory.html#footnotes",
    "href": "content/main/part1/1-prob-theory.html#footnotes",
    "title": "1  Probability Theory",
    "section": "",
    "text": "Note on Probability Theory. Formally, a probability space is written as a triple (\\Omega,\\Sigma,P), where \\Sigma is the collection of “measurable” events. This level of mathematical detail goes beyond what we need in this course and will not be assessed. (See the Wikipedia article on probability spaces if you are curious.)↩︎",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probability Theory</span>"
    ]
  },
  {
    "objectID": "content/main/part1/2-what-is-stats-inference.html",
    "href": "content/main/part1/2-what-is-stats-inference.html",
    "title": "2  What is Statistical Inference?",
    "section": "",
    "text": "2.1 Statistical Inference as “Inverse Probability”\nStatistical inference underpins experimental science, machine learning, clinical trials, and more. The overall aim is:\nTypical conclusions include estimating a proportion or mean, quantifying uncertainty, comparing groups, or predicting future outcomes.\nIn probability theory, the usual direction is:\nIn statistical inference, we reverse the problem:\nFormally, we (usually) assume our data are an i.i.d. sample:\nX_1,\\ldots,X_n \\stackrel{\\text{iid}}{\\sim} \\mathrm{Distribution}(\\theta).\nThe goal of statistical inference is to use the observed sample to learn about \\theta, and hence about the underlying population.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Statistical Inference?</span>"
    ]
  },
  {
    "objectID": "content/main/part1/2-what-is-stats-inference.html#sec-stat-inf-as-inv-prob",
    "href": "content/main/part1/2-what-is-stats-inference.html#sec-stat-inf-as-inv-prob",
    "title": "2  What is Statistical Inference?",
    "section": "",
    "text": "Start with a distribution f(x \\mid \\theta) (the model, with known parameter \\theta).\nUse it to generate random samples, or calculate probabilities of events involving the data.\n\n\n\nWe observe data \\underline{x} = (x_1,\\ldots,x_n).\nThe distribution f(x \\mid \\theta) is only partially known, through the unknown parameter \\theta.\nOur task is to use the sample to learn about \\theta, and hence about the population distribution.\n\n\n\n\nIndependent: knowing the value of one X_i gives no information about any other.\n\nIdentically distributed: each X_i comes from the same population distribution f(x \\mid \\theta).\n\n\n\n\n\n\n\n\nImportant 2.3: Terminology: Random Sample\n\n\n\n\n\n\nA sample 2.2 means the n random variables we collect from the population, X_1,\\dots,X_n. These need not be independent or identically distributed.\nA random sample is the special case where the X_i are assumed independent and identically distributed (i.i.d.) from the same distribution: \nX_1, \\dots, X_n \\stackrel{\\text{iid}}{\\sim} \\mathrm{Distribution}(\\theta).\n\n\nMost of the inference procedures in this course are developed under the random-sample (iid) assumption.\n\n\n\n\n2.1.1 Statistical Inference by Eye\nAs an informal starting point, suppose X_1,\\ldots,X_n are sampled from a \\mathcal{N}(\\mu,\\sigma^2) distribution, with \\mu and \\sigma^2 unknown.\nTry to “guess” \\mu and \\sigma^2 by eye from the data:\n\n\n   Show Visualisation \n\napproxSigma = Math.sqrt(approxVar)\n\n// density histogram + normal pdf (returns an SVG node)\nhistVis = {\n  const colHist  = \"var(--brand-teal, #55C3CB)\";\n  const colCurve = \"var(--brand-red, #e65660)\";\n  const gridCol  = \"var(--plot-grid, #94a3b8)\";\n\n  // --- x-domain based on data (with padding) ---\n  const xMin = d3.min(data), xMax = d3.max(data);\n  const pad = 0.4 * (xMax - xMin || 1);\n  const domain = [xMin - pad, xMax + pad];\n\n  const binCount = bins ?? 30;\n\n  // --- compute density bins manually: density = count / (n * binWidth) ---\n  const bin = d3.bin().domain(domain).thresholds(binCount);\n  const B = bin(data);\n  const n = data.length;\n  for (const b of B) b.density = b.length / (n * (b.x1 - b.x0));\n\n  // --- normal pdf on same domain ---\n  const xs = d3.range(domain[0], domain[1], (domain[1] - domain[0]) / 400);\n  const normalPdf = (x, mu, sigma) =&gt; (1/(sigma*Math.sqrt(2*Math.PI))) * Math.exp(-0.5*((x-mu)/sigma)**2);\n  const curve = xs.map(x =&gt; ({ x, y: normalPdf(x, approxMu, approxSigma) }));\n\n  // --- shared y-domain (max of both) ---\n  const ymax = 1.1 * Math.max(\n    d3.max(B, d =&gt; d.density) ?? 0,\n    d3.max(curve, d =&gt; d.y) ?? 0\n  );\n\n  return Plot.plot({\n    height: 360,\n    marginLeft: 50,\n    marginBottom: 50,\n    x: { label: \"x\", domain },\n    y: { label: \"Density\", grid: true, domain: [0, ymax], tickSize: 6 },\n    style: {\n      background: \"var(--brand-bg)\",\n      fontSize: 14,\n      fontFamily: bodyFont,\n      width: \"100%\",\n      display: \"block\",\n      margin: \"0 auto\",\n      maxWidth: \"1200px\",\n      color: \"var(--fg-strong, currentColor)\"\n    },\n    marks: [\n      // density histogram (teal)\n      Plot.rectY(\n        B,\n        { x1: d =&gt; d.x0, x2: d =&gt; d.x1, y: d =&gt; d.density,\n          fill: colHist, fillOpacity: 0.35, stroke: colHist, strokeOpacity: 0.7 }\n      ),\n      // normal pdf (orange)\n      Plot.line(curve, { x: \"x\", y: \"y\", stroke: colCurve, strokeWidth: 2.5 }),\n      // baseline\n      Plot.ruleY([0], { stroke: gridCol, strokeOpacity: 0.4 })\n    ]\n  });\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu_min = mu_true - muHalfWidth\nmu_max = mu_true + muHalfWidth\nvar_min = 0\nvar_max = sig2Max\n\n// Responsive 2D slider (scales with its container)\nviewof muVar2D = {\n  // Logical drawing size (not CSS pixels)\n  const width = 220, height = 220;\n  const margin = {top: 20, right: 5, bottom: 5, left: 5};\n  const W = width - margin.left - margin.right;\n  const H = height - margin.top - margin.bottom;\n\n  // --- helper: clamp number to [lo, hi] ---\n  const clamp = (v, lo, hi) =&gt; Math.min(hi, Math.max(lo, v));\n\n  // Scales (y increases upward in data space)\n  const x = d3.scaleLinear().domain([mu_min, mu_max]).range([0, W]).clamp(true);\n  const y = d3.scaleLinear().domain([var_min, var_max]).range([H, 0]).nice().clamp(true);\n\n  // Initial value\n  let state = {\n    approxMu: clamp(mu_true, mu_min, mu_max),\n    approxVar: clamp((var_max - var_min) * 0.4, var_min, var_max)\n  };\n\n  const bg = \"var(--plot-panel-bg)\";\n  const grid = \"var(--plot-grid, #94a3b8)\";\n  const colHandle = \"var(--brand-red, #e65660)\";\n  const colAccent = \"var(--brand-teal, #55C3CB)\";\n\n  // Wrapper that controls responsive size\n  const wrap = html`&lt;div style=\"\n    width: 100%;\n    max-width: 320px;      /* cap size; tweak as you like */\n    aspect-ratio: 1 / 1;   /* keep it square */\n    display: block;\n  \"&gt;&lt;/div&gt;`;\n\n  // SVG uses logical coords; CSS scales it\n  const svg = d3.create(\"svg\")\n    .attr(\"viewBox\", `0 0 ${width} ${height}`)\n    .attr(\"preserveAspectRatio\", \"xMidYMid meet\")\n    .style(\"width\", \"100%\")\n    .style(\"height\", \"100%\")\n    .style(\"background\", \"transparent\")\n    .attr(\"stroke-opacity\", 0.)\n    .style(\"font-family\", bodyFont)\n    .style(\"font-size\", \"14px\");\n\n  const g = svg.append(\"g\").attr(\"transform\", `translate(${margin.left},${margin.top})`);\n\n  // Background panel\n  g.append(\"rect\")\n    .attr(\"x\", 0).attr(\"y\", 0).attr(\"width\", W).attr(\"height\", H)\n    .attr(\"rx\", 10)\n    .attr(\"fill\", bg)\n    .attr(\"stroke\", grid).attr(\"stroke-opacity\", 0.5);\n\n  // Crosshairs\n  const crossX = g.append(\"line\")\n    .attr(\"stroke\", colAccent)\n    .attr(\"stroke-opacity\", 0.7)\n    .attr(\"stroke-width\", 1.5);\n\n  const crossY = g.append(\"line\")\n    .attr(\"stroke\", colAccent)\n    .attr(\"stroke-opacity\", 0.7)\n    .attr(\"stroke-width\", 1.5);\n\n  // Handle\n  const handle = g.append(\"circle\")\n    .attr(\"r\", 5)\n    .attr(\"fill\", colHandle)\n    .attr(\"stroke\", \"white\")\n    .attr(\"stroke-width\", 1.5)\n    .style(\"cursor\", \"grab\");\n\n  // Readout\n  const readout = svg.append(\"text\")\n    .attr(\"x\", width / 2)        // center horizontally\n    .attr(\"y\", margin.top / 1.5) // just above the chart area\n    .attr(\"text-anchor\", \"middle\")\n    .attr(\"fill\", \"var(--fg-strong, currentColor)\")\n    .style(\"font-weight\", 400);\n\n  function updateVisual() {\n    const cx = x(state.approxMu), cy = y(state.approxVar);\n    crossX.attr(\"x1\", 0).attr(\"x2\", W).attr(\"y1\", cy).attr(\"y2\", cy);\n    crossY.attr(\"x1\", cx).attr(\"x2\", cx).attr(\"y1\", 0).attr(\"y2\", H);\n    handle.attr(\"cx\", cx).attr(\"cy\", cy);\n    readout.text(`μ≈ ${state.approxMu.toFixed(2)},        σ²≈ ${state.approxVar.toFixed(2)}`);\n  }\n\n  function setFromPointer(evt) {\n    const [px, py] = d3.pointer(evt, g.node()); // in SVG user units (matches viewBox)\n    const mu = clamp(x.invert(px), mu_min, mu_max);\n    const vv = clamp(y.invert(py), var_min, var_max);\n    state = { approxMu: mu, approxVar: vv };\n    root.value = { approxMu: state.approxMu, approxVar: state.approxVar };\n    root.dispatchEvent(new CustomEvent(\"input\", {bubbles: true}));\n    updateVisual();\n  }\n\n  // Interaction overlay\n  g.append(\"rect\")\n    .attr(\"x\", 0).attr(\"y\", 0).attr(\"width\", W).attr(\"height\", H)\n    .attr(\"fill\", \"transparent\")\n    .style(\"cursor\", \"crosshair\")\n    .on(\"pointerdown\", function(evt) {\n      this.setPointerCapture?.(evt.pointerId);\n      handle.style(\"cursor\", \"grabbing\");\n      setFromPointer(evt);\n    })\n    .on(\"pointermove\", function(evt) {\n      if (evt.pressure &gt; 0 || evt.buttons) setFromPointer(evt);\n    })\n    .on(\"pointerup\", function(evt) {\n      this.releasePointerCapture?.(evt.pointerId);\n      handle.style(\"cursor\", \"grab\");\n    });\n\n  // Root element with .value is the wrapper (so CSS controls size)\n  const root = wrap;\n  root.append(svg.node());\n  root.value = { approxMu: state.approxMu, approxVar: state.approxVar };\n\n  updateVisual();\n  return root;\n}\n\n// Reactive outputs\napproxMu = muVar2D.approxMu\napproxVar = muVar2D.approxVar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Layout container placing the histogram (left, 2fr) and slider (right, 1fr)\n{\n  const wrap = html`&lt;div style=\"\n    display: grid;\n    grid-template-columns: 3fr 1fr;  /* change to 3fr 1fr for ~3:1 */\n    gap: 0.5rem;\n    align-items: start; /* left plot stays top-aligned */\n  \"&gt;&lt;/div&gt;`;\n\n  // Histogram (left)\n  wrap.append(histVis);\n\n  // Slider (right, vertically centered)\n  const sliderBox = html`&lt;div style=\"display:flex; align-items:center; height:100%\"&gt;&lt;/div&gt;`;\n  sliderBox.append(viewof muVar2D);\n  wrap.append(sliderBox);\n\n  return wrap;\n}\n\n\n\n\n\n\n\n// data\ndata = {\n  resample; // reacts to the \"Resimulate data\" button\n  const rnd = d3.randomNormal(mu_true, sigma_true);\n  return Array.from({ length: n }, () =&gt; rnd());\n}\n\n\n\n\n\n\n\nviewof controls = {\n  const resimBtn = Inputs.button(\"Resimulate data\");\n  resimBtn.classList.add(\"btn-resim\");\n\n  const leftForm = Inputs.form({\n    n: Inputs.range([1, 400], { value: 50, step: 1, label: md`${tex`n`}` }),\n    mu_true: Inputs.range([-5, 5], { value: 0.5, step: 0.05, label: md`${tex`\\mu_{\\text{true}}`}` }),\n    sigma_true: Inputs.range([0.3, 4], { value: 1.2, step: 0.05, label: md`${tex`\\sigma_{\\text{true}}`}` })\n  }, { submit: false });\n\n  const rightForm = Inputs.form({\n    muHalfWidth: Inputs.range([1, 10], { value: 5, step: 0.05, label: md`${tex`\\mu\\text{-range}`}` }),\n    sig2Max: Inputs.range([0.2, 10], { value: 5, step: 0.05, label: md`${tex`\\sigma^2\\text{ max}`}` }),\n    bins: Inputs.range([10, 60], { value: 12, step: 1, label: \"Histogram bins\" })\n  }, { submit: false });\n\n  const root = html`&lt;details class=\"controls-root\" open&gt;\n    &lt;summary&gt;Simulation controls&lt;/summary&gt;\n    &lt;div class=\"controls-grid\"&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Data & truth&lt;/h4&gt;&lt;/div&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Grid & display&lt;/h4&gt;&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/details&gt;`;\n\n  const grid = root.querySelector(\".controls-grid\");\n  grid.children[0].append(leftForm);\n  grid.children[1].append(rightForm);\n\n  const btnWrap = html`&lt;div style=\"display:flex; justify-content:flex-start; margin-top:6px;\"&gt;&lt;/div&gt;`;\n  btnWrap.append(resimBtn);\n  grid.children[1].append(btnWrap);\n\n  const getValue = () =&gt; ({ ...leftForm.value, ...rightForm.value, resim: resimBtn.value });\n  const update = () =&gt; { root.value = getValue(); root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true })); };\n\n  grid.addEventListener(\"input\", update);\n  queueMicrotask(update);\n  return root;\n}\n\n// --- Expose reactive vars\nn = controls.n\nmu_true = controls.mu_true\nsigma_true = controls.sigma_true\nmuHalfWidth = controls.muHalfWidth\nsig2Max = controls.sig2Max\nbins = controls.bins\nresample = controls.resim",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Statistical Inference?</span>"
    ]
  },
  {
    "objectID": "content/main/part1/2-what-is-stats-inference.html#sec-types-of-data",
    "href": "content/main/part1/2-what-is-stats-inference.html#sec-types-of-data",
    "title": "2  What is Statistical Inference?",
    "section": "2.2 Types of Data",
    "text": "2.2 Types of Data\nBefore we build statistical models, it helps to think about the kinds of data we might collect. Different data types naturally lead to different models.\n\n2.2.1 Univariate vs. Multivariate data\n\n\n\n\n\n\nImportant 2.4: Terminology: Unit\n\n\n\n\n\nAn observational unit (or simply unit) is a single element of the population on which we make a measurement.\n\nIn a survey of students: each student is a unit.\n\nIn a clinical trial: each patient is a unit.\n\nIn a manufacturing study: each product is a unit.\n\nIn an image analysis study: each image is a unit.\n\n\n\n\n\nUnivariate data: a single measurement per observational unit.\n\nExample: the height of each student in a class.\n\nMultivariate data: two or more measurements on each unit.\n\nExample: the height and weight of each student (bivariate); or height, weight, and age (multivariate).\n\n\nData are often represented in tables.\n\nUnivariate dataMultivariate data\n\n\nEach unit has one measurement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n\n\n\n\nEarthquakes\n4\n0\n2\n6\n4\n0\n2\n8\n5\n7\n\n\n\n\n\nTable 2.1: Earthquake counts. Table shows the number of UK earthquakes of magnitude ≥2 on the Richter scale each year.\n\n\n\nHere, the units are the years (2011–2020), and the (single) variable is the annual count of UK earthquakes.\n\n\nEach unit has two or more measurements.\n\n\n\n\n\n\nStation\nRainfall (mm)\nWind speed (km/h)\nPressure (hPa)\n\n\n\n\nA\n214.8\n87\n995\n\n\nB\n196.3\n91\n992\n\n\nC\n180.2\n79\n1001\n\n\nD\n205.5\n94\n998\n\n\nE\n209.0\n89\n997\n\n\n…\n…\n…\n…\n\n\n\n\n\nTable 2.2: Weather data. Average rainfall, wind speed, and air pressure recorded at weather stations during a storm.\n\n\n\nHere, the units are the weather stations (during the same storm), and the variables are rainfall (mm), wind speed (km/h), and pressure (hPa).\n\n\n\nSome data is extremely high-dimensional:\n\n\n\n\n\n\n\nExample 2.1 (Image Data) An image is made of a grid of pixels, where each pixel is a colour.\nA colour can be represented by three channels: red, green, and blue1.\n\n\n\n\n\n\nFigure 2.1: A 32×32 image of a cat, broken into its three colour channels (red, green, blue). Each pixel has three values (one per channel), making the image a high-dimensional observation.\n\n\n\nEach pixel has multiple measurements (one per channel), so images are an example of high-dimensional multivariate data. To see why, consider the size of real images:\n\nA tiny image of size 32\\times 32 pixels with 3 channels (RGB) already has 32\\times 32 \\times 3 = 3072 measurements.\nA small image of size 128 \\times 128 pixels with 3 channels (RGB) has\n128 \\times 128 \\times 3 \\approx 50{,}000 measurements.\n\nA “HD” photo of size 1920 \\times 1080 (1080p) contains over\n1920 \\times 1080 \\times 3 \\approx 6.2 million measurements.\n\nSo even a single image can be thought of as a very high-dimensional observation. And videos are higher still: sequences of such images evolving over time2.\n\n\n\n\n\n\n\n\n\n\nWarningNon-Examinable Content: Multivariate Data\n\n\n\nIn this course we focus only on univariate data (one measurement per observational unit).\nAlthough many real-world problems involve multivariate data (two or more measurements on the same unit), this topic will be studied in later statistics courses.\n\n\n\n\n2.2.2 Numerical data\n\nContinuous: can take any real value in an interval.\n\nExamples: height, weight, reaction time.\nModels: Normal, Exponential, Uniform.\n\nDiscrete numeric: counts, usually non-negative integers.\n\nExamples: number of accidents in a week, number of goals in a football match.\nModels: Binomial, Poisson, Geometric.\n\n\n\nContinuous dataDiscrete dataMixed data\n\n\n\n\n\n\n\n\nStar\nApparent magnitude\n\n\n\n\nSirius\n–1.46\n\n\nVega\n0.03\n\n\nAltair\n0.77\n\n\nDeneb\n1.25\n\n\n…\n…\n\n\n\n\n\nTable 2.3: Astronomy data. The brightness of a star (its magnitude) is measured on a continuous scale. .\n\n\n\n\n\n\n\n\n\n\n\nMatch\nHome goals\nAway goals\n\n\n\n\nNewcastle United vs Arsenal\n7\n0\n\n\nManchester United vs Liverpool F.C.\n0\n1\n\n\nTottenham Hotspur vs Chelsea F.C.\n1\n3\n\n\nAston Villa vs Leeds United\n3\n2\n\n\nWest Ham United vs Manchester City\n0\n4\n\n\nBrighton & Hove Albion vs Everton\n2\n2\n\n\nLeicester City vs Southampton\n1\n0\n\n\nWolverhampton Wanderers vs Brentford\n2\n1\n\n\nCrystal Palace vs Fulham\n0\n1\n\n\nNottingham Forest vs Bournemouth\n1\n1\n\n\n…\n…\n…\n\n\n\n\n\nTable 2.4: Sports analytics. Goals scored in football matches are discrete counts. Each match provides multivariate discrete data (two counts per unit).\n\n\n\n\n\nIn practice, most datasets are mixed\n\n\n\n\n\n\nPatient\nAge (years)\nReaction time (ms)\nSmoker (yes/no)\n\n\n\n\nA\n22\n318\nYes\n\n\nB\n35\n241\nNo\n\n\nC\n41\n267\nYes\n\n\nD\n29\n452\nNo\n\n\n…\n…\n…\n…\n\n\n\n\n\nTable 2.5: Medical study. Here each patient (unit) has both continuous and discrete measurements.\n\n\n\n\n\n\n\n\n2.2.3 Categorical data\n\nNominal: categories with no natural order.\n\nExamples: hair colour, brand of cereal, country of birth.\n\nOrdinal: categories with a natural order, but not numerical spacing.\n\nExamples: customer satisfaction ratings (“poor”, “fair”, “good”, “excellent”).\n\n\nCategorical data are often summarised in contingency tables (tables of counts).\n\nOne-way tableTwo-way table\n\n\nIf we record the colours of sweets drawn from a bag:\n\n\n\nColour\nCount\n\n\n\n\nRed\nR\n\n\nBlue\nB\n\n\nGreen\nG\n\n\nTotal\nn\n\n\n\nThis simple one-way table leads naturally to the multinomial model 1.3.\n\n\nSuppose we also record the shop where each sweet was bought (Shop A or Shop B).\nNow we cross-classify by both colour and shop:\n\n\n\nColour\nShop A\nShop B\nTotal\n\n\n\n\nRed\nR_A\nR_B\nR\n\n\nBlue\nB_A\nB_B\nB\n\n\nGreen\nG_A\nG_B\nG\n\n\nTotal\nn_A\nn_B\nn\n\n\n\nThis two-way contingency table allows us to ask questions like:\n\n“Are colours distributed differently across shops?”\n\nLater in the course we will see this leads to the chi-squared test of independence.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Statistical Inference?</span>"
    ]
  },
  {
    "objectID": "content/main/part1/2-what-is-stats-inference.html#statistical-models",
    "href": "content/main/part1/2-what-is-stats-inference.html#statistical-models",
    "title": "2  What is Statistical Inference?",
    "section": "2.3 Statistical Models",
    "text": "2.3 Statistical Models\nWhenever we perform statistical inference, we must specify a model.\nIn Section 2.1 we wrote \nX_1,\\ldots,X_n \\stackrel{\\text{iid}}{\\sim} \\mathrm{Distribution}(\\theta)\n using \\mathrm{Distribution}(\\theta) as a placeholder for “some distribution indexed by \\theta”.\nWe now make this precise:\n\nA statistical model is a mathematical description of how we think the data are generated.\nConcretely, it is a family of possible distributions, one for each parameter value in a parameter space \\Theta.\n\n\n\n\n\n\n\n\nExample 2.2 (Exponential model) Suppose we are interested in modelling waiting times until some event occurs (e.g. the time between customer arrivals at a service desk).\nA natural assumption is that the data are i.i.d. exponential 2.2: \nX_1,\\ldots, X_n \\stackrel{\\text{iid}}{\\sim}\\mathrm{Exponential}(\\lambda).\n\n\nModel: each X_i is i.i.d. exponential with rate \\lambda\nParameter: \\theta = \\lambda\nParameter space3 : \\Theta = \\{ \\lambda \\mid \\lambda &gt; 0\\} = (0,\\infty)\n\nThe exponential model often arises in Poisson processes, where events occur independently at a constant rate (e.g. radioactive decay, arrivals at a bus stop).\n\n\n\n\n\n\n\n\n\n\n\nExample 2.3 (Normal model) In Section 2.1.1 we assumed the data were i.i.d. Normal with unknown mean and variance: \nX_1,\\ldots, X_n \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2).\n\n\nModel: each X_i is i.i.d. Normal with mean \\mu and variance \\sigma^2\nParameters: \\theta = (\\mu,\\sigma^2)\n\nParameter space4 : \\Theta = \\{ (\\mu, \\sigma^2) \\mid \\mu \\in \\mathbb{R}, \\sigma^2 &gt; 0 \\} = \\mathbb{R} \\times (0,\\infty)\n\nThis model is widely used, e.g. for measurement error or traits like human height.\n\n\n\n\n\n\n\n\n\n\nTipCommon Misconceptions\n\n\n\n\nParameter \\neq statistic.\nA parameter \\theta describes a feature of the population (e.g. p, \\mu, \\sigma^2).\nA statistic (e.g. \\bar{X}, a sample proportion) is calculated from the sample and used to learn about \\theta.\n“Random sample” is not just “whatever data we found”.\nA random sample means data collected in a way that makes the i.i.d. assumption reasonable (e.g. independent trials, simple random sampling).\n\nExample: If your population is all humans on the planet, then sampling only your family would not be random and could bias inference.\n\nModels are approximations.\nIn practice you should treat models as useful simplifications, not as exact descriptions of reality. It’s important to choose them sensibly, and be prepared to adjust if they don’t fit the data well.\n\n\n\n\n\n\n\n\n\n\nExample 2.4 (From words to a model) A questionnaire records whether each respondent would recommend a service (“yes” or “no”). Write down a simple model and identify the parameter.\n\n   Solution \nLet X_i=1 if respondent i says “yes”, and 0 otherwise.\nAssume X_1,\\ldots,X_n \\stackrel{\\text{iid}}{\\sim}\\mathrm{Bernoulli}(p).\n\nModel: \\mathcal{P} = \\{ \\mathrm{Bernoulli}(p) : 0 &lt; p &lt; 1 \\}\n\nParameter: \\theta = p\n\nParameter space: \\Theta = (0,1)\n\nHere p is the long-run proportion of “yes” responses.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.5 (A slightly richer example) A bag contains sweets of three colours \\{\\text{red},\\text{blue},\\text{green}\\}. You draw n sweets with replacement and record counts (R,B,G). Propose a model and identify the parameters.\n\n   Solution \nEach draw is an independent categorical outcome with probabilities (p_R,p_B,p_G) for red/blue/green. After n draws, we observe the count vector (R,B,G).\nA natural model is the multinomial 1.3 distribution:\n\nModel: (R,B,G) \\sim \\mathrm{Multinomial}\\!\\left(n;\\,p_R,p_B,p_G\\right) with p_R+p_B+p_G=1\n(equivalently, X_1,\\dots,X_n \\stackrel{\\text{iid}}{\\sim} \\mathrm{Categorical}(p_R,p_B,p_G) and (R,B,G) are the totals).\nParameters: \\theta = (p_R,p_B,p_G)\n\nParameter space: the 2-simplex \\;\\Theta=\\{(p_R,p_B,p_G)\\in[0,1]^3 \\mid \\,p_R+p_B+p_G=1\\}\n\nIf you only had two colours, the multinomial distribution would become the binomial distribution 1.2.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.6 (Machine learning example) In image classification, each “training” example is a pair (X_i,Y_i) where X_i is an image and Y_i\\in\\{0,1\\}. A generic probabilistic model specifies \n\\mathrm{Pr}_\\theta(Y=1\\mid X=x)=g_\\theta(x),\n for some family of functions g_\\theta (e.g. a neural network).\nWhat are the sample, population, model, and parameter?\n\n   Solution \n\nSample: the dataset \\{(X_i,Y_i)\\}_{i=1}^n.\n\nPopulation: the (conceptual) set of all image–label pairs of interest; equivalently, the joint distribution of (X,Y) in the real world we care about.\n\nModel: we specify the conditional distribution of Y given X, Y \\mid X \\sim \\mathrm{Bernoulli}\\big(g_\\theta(X)\\big), i.e. \\operatorname{Pr}_\\theta(Y=1\\mid X=x)=g_\\theta(x).\nParameter: \\theta indexes the function g_\\theta (e.g. regression coefficients or neural-network weights).\n\nParameter space: \\Theta\\subseteq\\mathbb{R}^d (dimension d depends on the chosen model class).\n\nCommon misconception: confusing the training sample (finite) with the population (conceptual/infinite). The goal of inference is to use the sample to learn \\theta so that the model generalises to the population.\n\n\n\n\n\n\n\n\n\n\n\nWarningNon-Examinable Content: Specifying Statistical Models\n\n\n\nIn this course we concentrate on how to carry out statistical inference once a model has been chosen.\nIn all assessed questions the statistical model will be provided. Your task will be to perform inference by working with the parameter(s), using methods such as:\n\nParameter Estimation 4\nInterval Estimation 7\nHypothesis Testing 9\n\n\n\nThe (non-examinable) formal definition of a statistical model is the following:\n\n\n\n\n\n\n\nDefinition 2.1 (Statistical Model (non-examinable)) A statistical model5 is a family of probability distributions labelled by a parameter value: \n\\mathcal{P}=\\{P_\\theta \\mid \\theta\\in\\Theta\\},\n\nwhere:\n\nP_\\theta is one possible distribution the data might follow,\n\\theta is the parameter,\n\\Theta is the parameter space (the set of all possible parameter values).",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Statistical Inference?</span>"
    ]
  },
  {
    "objectID": "content/main/part1/2-what-is-stats-inference.html#footnotes",
    "href": "content/main/part1/2-what-is-stats-inference.html#footnotes",
    "title": "2  What is Statistical Inference?",
    "section": "",
    "text": "Note on images. Some image formats, such as .png, include an alpha channel (the “A” channel), which specifies pixel transparency.↩︎\nNote on compression. In practice, images are often compressed (e.g. JPEG, PNG), which reduces file size by exploiting redundancy in pixel values. Statistically, though, the raw number of pixel measurements still reflects the dimensionality of the data.↩︎\nSet notation. There are several equivalent ways to write sets:\n\nSet-builder notation: \\{\\lambda \\mid \\lambda &gt; 0\\}\n\nInterval notation: (0,\\infty)\n\nNamed set: \\mathbb{R}^+\n\nAll three describe the same set. In this course, we recommend using set-builder notation when writing statistical models and their parameter spaces.↩︎\nSet notation (multiple parameters). When a model has several parameters, it is best to use set-builder notation and collect the parameters into a vector \n    \\underline{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_p).\n   The parameter space can then be written as \n    \\Theta = \\{(\\theta_1,\\ldots,\\theta_p) \\mid \\theta_1 \\in S_1,\\ \\ldots,\\ \\theta_p \\in S_p\\}.\n  \nHere each S_j is the set of allowed values for parameter \\theta_j. To construct \\Theta, simply read off the constraints on each parameter from the definition of the distribution (see the Formula Sheet 0.0.0.0.1).\nFor example, in the Normal model:\n\n\\mu \\in \\mathbb{R} (any real number),\n\n\\sigma^2 \\in (0,\\infty) (variance must be positive),\n\nso the parameter space is\n\n    \\Theta = \\mathbb{R} \\times (0,\\infty).\n  \nThis is called a Cartesian product: we form the parameter space by taking all possible pairs (\\mu, \\sigma^2) where the first component is from \\mathbb{R} and the second from (0,\\infty).\nIntuitively, it’s just “all combinations” of the allowed values for each parameter.↩︎\nNote on Statistical models. Strictly speaking, the model refers to the joint distribution of the full dataset. If X_1,\\dots,X_n are i.i.d. from P_\\theta, then the model is \n\\mathcal{P} = \\{ P_\\theta^n \\mid \\theta \\in \\Theta \\}.\n But for intuition, we usually just describe the distribution of a single observation, X_i \\sim P_\\theta, and keep in mind that the whole dataset follows from this.↩︎",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Statistical Inference?</span>"
    ]
  },
  {
    "objectID": "content/main/part1/3-types-of-inference.html",
    "href": "content/main/part1/3-types-of-inference.html",
    "title": "3  Types of Inference",
    "section": "",
    "text": "3.1 Philosophies of Inference\nStatistical inference is about using a sample to learn about a population. There are two fundamentally different philosophies of inference, and several types of inferential tasks that appear in both.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part1/3-types-of-inference.html#philosophies-of-inference",
    "href": "content/main/part1/3-types-of-inference.html#philosophies-of-inference",
    "title": "3  Types of Inference",
    "section": "",
    "text": "3.1.1 Frequentist Inference\nFrequentist inference is based on the idea of long-run frequency.\n\nThe data are considered random, as they represent one possible outcome of repeated sampling from the population.\nThe parameter \\theta is fixed but unknown.\nInference is about constructing procedures (estimators, tests, intervals) that perform well under repeated sampling.\n\nPreview examples (we will return to these later): the sample mean \\hat{\\mu} as an estimator of \\mu, a t-test for comparing means, or a 95\\% confidence interval.\n\n\n3.1.2 Bayesian Inference\nBayesian inference is based on subjective probability as degree of belief.\n\nThe data are fixed once observed.\nThe parameter \\theta is treated as a random variable, with uncertainty described by a prior distribution \\pi(\\theta).\nInference updates this prior in light of the data, giving a posterior distribution \\pi(\\theta \\mid \\text{data}).\n\nPreview examples (we will return to these later): a posterior mean as an estimator of \\mu, a 95\\% credible interval, or comparing hypotheses via posterior probabilities.\n\n\n3.1.3 Key Differences\n\n\n\n\n\n\n\n\nPerspective\nFrequentist Inference\nBayesian Inference\n\n\n\n\nParameter\nFixed but unknown\nRandom variable with a prior\n\n\nSample\nRandom (from repeated sampling)\nFixed (once observed)\n\n\nProbability\nLong-run frequency\nDegree of belief\n\n\nGoal\nConstruct estimators, tests, CIs\nUpdate beliefs via posterior\n\n\nPrior Knowledge\nIgnored or minimal (e.g. non-informative)\nExplicitly modelled via prior distribution\n\n\nOutput\nEstimators, confidence intervals, p-values\nPosterior distribution, credible intervals",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part1/3-types-of-inference.html#sec-inference-tasks",
    "href": "content/main/part1/3-types-of-inference.html#sec-inference-tasks",
    "title": "3  Types of Inference",
    "section": "3.2 Inference Tasks",
    "text": "3.2 Inference Tasks\nRegardless of philosophy, the core tasks of inference are similar. Suppose we want to infer a parameter \\theta from data:\n\nPoint Estimation Give a single “best guess” \\hat{\\theta} for the parameter.\n\nFrequentist: choose an estimator with good properties (e.g. unbiasedness).\nBayesian: often the posterior mean, median, or mode.\n\nInterval Estimation Quantify uncertainty in \\theta by reporting a range.\n\nFrequentist: confidence interval\n\nL \\leq \\theta \\leq U\n\nwith a given long-run coverage probability.\nBayesian: credible interval, the posterior probability that \\theta lies in [L,U] is, say, 95\\%.\n\nHypothesis Testing Ask a yes/no question about the parameter \\theta. This is done by formalising a claim (the null hypothesis) such as \n     H_0: \\theta \\in \\Theta_0,\n and then using the data to judge whether this claim is compatible with the evidence.\n\nFrequentist approach: base the decision on a test statistic and its distribution under H_0, leading to a p-value or a comparison with a significance level.\nBayesian approach: compare hypotheses using posterior probabilities or Bayes factors, quantifying how much the data shift our beliefs.\n\nPrediction Use data to predict future or unobserved outcomes.\n\nFrequentist: predictive distributions based on sampling models.\nBayesian: posterior predictive distribution, integrating over parameter uncertainty.",
    "crumbs": [
      "Part I — Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part2/4-freq-point-estimation.html",
    "href": "content/main/part2/4-freq-point-estimation.html",
    "title": "4  Frequentist Point Estimation",
    "section": "",
    "text": "4.1 Estimators vs. Estimates\nA statistic is any function of the sample \nT \\;=\\; T(X_1,\\dots,X_n).\nBecause it is built from the random variables X_1,\\dots,X_n, the statistic T itself is a random quantity: its value varies from sample to sample. Once the data have been observed (x_1,\\dots,x_n), plugging them into the same formula produces a single non-random number, which we denote by t_{\\mathrm{obs}} (or simply t).\nWhen we pick a statistic for the specific purpose of approximating a parameter \\theta, we call it an estimator. Its realised value is the estimate.\nAn estimator is a random variable; an estimate is its realised value.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Frequentist Point Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part2/4-freq-point-estimation.html#estimators-vs.-estimates",
    "href": "content/main/part2/4-freq-point-estimation.html#estimators-vs.-estimates",
    "title": "4  Frequentist Point Estimation",
    "section": "",
    "text": "Concept\nNotation\nDescription\n\n\n\n\nEstimator\n\\hat{\\theta} = \\hat{\\theta}(X_1, \\dots, X_n)\nA function of the data. A rule for producing an estimate.\n\n\nEstimate\n\\hat{\\theta}_{\\text{obs}} = \\hat{\\theta}(x_1, \\dots, x_n)\nThe numerical value you get after plugging in your data.\n\n\n\n\n\n4.1.1 Sample Mean and Variance\nTwo of the most important estimators are the sample mean and sample variance.\n\n\n\n\n\n\n\nDefinition 4.1 (Sample Mean) The sample mean of a random sample X_1,\\ldots,X_n is\n\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\n\n\n\n\nFor observed data x_1,\\ldots,x_n, the corresponding estimate is\n\n\\bar x \\;=\\; \\frac{1}{n}\\sum_{i=1}^n x_i,\n\nand we will frequently use the shorthand\n\n\\sum_{i=1}^n x_i \\;=\\; n\\,\\bar x.\n\n\n\n\n\n\n\n\nDefinition 4.2 (Sample Variance) For a random sample X_1,\\ldots,X_n, the (unbiased) sample variance is\n\nS^2 \\;=\\; \\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\bar X)^2.\n\n\n\n\n\nFor observed data x_1,\\ldots,x_n, the corresponding estimate is\n\ns^2 \\;=\\; \\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar x)^2.\n\n\n\n\n\n\n\nTipRemark (Why n-1?)\n\n\n\n\n\n\nRemark 4.1 (Why n-1?). The factor \\tfrac{1}{n-1} in the definition of S^2 is called Bessel’s correction.\nIt accounts for the fact that the deviations (X_i-\\bar X) satisfy the constraint \\sum_{i=1}^n (X_i-\\bar X)=0, leaving only n-1 degrees of freedom.\nUnder an i.i.d. model with finite variance \\sigma^2, this choice makes S^2 unbiased: \n\\mathrm{E}[S^2]=\\sigma^2.\n\nSee Example 4.3 for more details.\n\n\n\n\nThe following representation of the sample variance is convenient in theoretical derivations (e.g. the unbiasedness of S^2) and in practice, where precomputed totals \\sum_i X_i and \\sum_i X_i^2 allow immediate evaluation of S^2.\n\n\n\n\n\n\n\nProposition 4.1 (Alternative Form of the Sample Variance) For a random sample X_1,\\ldots,X_n with sample mean \\bar X, the sample variance 4.2 admits the computational identity \nS^2 \\;=\\; \\frac{1}{n-1}\\left(\\sum_{i=1}^n X_i^{2}\\;-\\; n\\,\\bar X^{\\,2}\\right).\n This is often convenient in deriving properties of the sample variance and, in practice, when sums of squares are already available.\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 4.1. Starting from Definition 4.2 and expanding the quadratic, we have \nS^2=\\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\bar X)^2,\n expand the square and sum term-by-term: \n\\sum_{i=1}^n (X_i-\\bar X)^2\n= \\sum_{i=1}^n \\bigl(X_i^2 - 2\\bar X\\,X_i + \\bar X^{\\,2}\\bigr)\n= \\sum_{i=1}^n X_i^2 \\;-\\; 2\\bar X \\sum_{i=1}^n X_i \\;+\\; \\sum_{i=1}^n \\bar X^{\\,2}.\n Since \\sum_{i=1}^n X_i = n\\bar X and \\sum_{i=1}^n \\bar X^{\\,2}= n\\bar X^{\\,2}, this becomes \n\\sum_{i=1}^n (X_i-\\bar X)^2\n= \\sum_{i=1}^n X_i^2 \\;-\\; 2n\\bar X^{\\,2} \\;+\\; n\\bar X^{\\,2}\n= \\sum_{i=1}^n X_i^2 \\;-\\; n\\bar X^{\\,2}.\n Dividing by n-1 yields the stated identity.\n\n\n\n\n\n\n4.1.2 The Randomness of Estimators\nAn estimator is a rule that turns a random sample into a number:\n\n\\hat\\theta \\;=\\; \\hat{\\theta}(X_1,\\ldots,X_n).\n\nSince X_1,\\ldots,X_n are random variables, the output \\hat\\theta is also a random variable. Its value changes from sample to sample; only after we observe data (x_1,\\ldots,x_n) do we get the estimate \\hat\\theta_{\\text{obs}}=\\hat{\\theta}(x_1,\\ldots,x_n), a fixed number.\n\n\nShow Visualisation\nThe left panel shows one random sample of size n and its sample mean \\bar x. The right panel approximates the sampling distribution of \\bar X by repeatedly drawing fresh samples of size n from the same model (parameters held fixed) and plotting the resulting means - only the data vary from run to run.\n\nmutable rngSeed = 1\nmutable meanHistory = []\nmutable resampleClicks = 0\nmutable resetClicks = 0\nmutable lastSamplesPerClick = 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  if (reset &gt; resetClicks) {\n    mutable meanHistory = [];\n    mutable resetClicks = reset;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n{\n  if (controls.samplesPerClick !== lastSamplesPerClick) {\n    mutable lastSamplesPerClick = controls.samplesPerClick;\n    mutable resampleClicks = 0; // Reset to match the new button's counter\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n{\n  if (resample &gt; resampleClicks) {\n    // Add the current mean to history first\n    mutable meanHistory = [...meanHistory, xbar];\n    \n    // If doing multiple samples, add the additional ones\n    if (controls.samplesPerClick &gt; 1) {\n      const additionalMeans = [];\n      for (let i = 1; i &lt; controls.samplesPerClick; i++) {\n        const rand = d3.randomNormal.source(d3.randomLcg(rngSeed + i))(controls.trueMu, controls.trueSigma);\n        const sample = d3.range(controls.n).map(rand);\n        additionalMeans.push(d3.mean(sample));\n      }\n      mutable meanHistory = [...meanHistory, ...additionalMeans];\n    }\n    \n    // Update seed for next sample (which will be displayed)\n    mutable rngSeed = rngSeed + controls.samplesPerClick;\n    mutable resampleClicks = resample;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n\n\nfunction styledButton(label, cls, options = {}) {\n  const el = Inputs.button(label, options);\n  const btn = el.querySelector('button');\n  if (btn) btn.classList.add(cls);\n  return el;\n}\n\n// Define themed buttons with updated label for multi-sample\nviewof resample = styledButton(\n  controls.samplesPerClick &gt; 1 \n    ? `Resample (×${controls.samplesPerClick})` \n    : \"Resample\", \n  \"btn-resample\", \n  { reduce: c =&gt; (c ?? 0) + 1 }\n);\n\nviewof reset = styledButton(\"Reset\", \"btn-reset\", {\n  reduce: c =&gt; (c ?? 0) + 1\n});\n\n// --- Current sample (always visible) ---\nX = {\n  const rand = d3.randomNormal.source(d3.randomLcg(rngSeed))(controls.trueMu, controls.trueSigma);\n  return d3.range(controls.n).map(rand);\n}\nxbar = d3.mean(X)\n\n// ========= Left panel: current sample ========= \n// Compute histogram bins and densities once \nleftBins = d3.bin().domain(xDomain).thresholds(controls.bins)(X)\nleftDensities = leftBins.map(b =&gt; b.length / controls.n / Math.max(1e-9, b.x1 - b.x0) )\nleftYMax = Math.max(0.1, d3.max(leftDensities) || 0.1);\n\n// ========= Shared computation =========\nxPad = 3 * controls.trueSigma\nxDomain = [controls.trueMu - xPad, controls.trueMu + xPad]\nmid      = 0.5 * (xDomain[0] + xDomain[1]);\nanchor   = xbar &lt; mid ? \"start\" : \"end\";   // right of line if on left half, else left\n\nleftPlot = Plot.plot({\n  width: Math.min(600, Math.max(320, width/2 - 20)),\n  height: 320,\n  style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont,\n    fontSize: 14,\n  },\n  x: { label: \"Data\", domain: xDomain },\n  y: { label: \"Density\", domain: [0, leftYMax * 1.1] },\n  marks: [\n    // histogram\n    Plot.rectY(leftBins, {\n      x1: d =&gt; d.x0,\n      x2: d =&gt; d.x1,\n      y: d =&gt; d.length / controls.n / Math.max(1e-9, d.x1 - d.x0),\n      fill: \"var(--brand-teal)\",\n      fillOpacity: 0.4\n    }),\n\n    // ticks at data points\n    Plot.ruleX(X, {\n      y1: 0,\n      y2: leftYMax * 0.05,\n      stroke: \"var(--brand-teal)\",\n      strokeWidth: 2,\n      strokeOpacity: 0.8\n    }),\n\n    // sample mean line + label\n    Plot.ruleX([xbar], {\n      stroke: \"currentColor\",\n      strokeDasharray: \"4,3\",\n      strokeWidth: 2\n    }),\n    // label \n    Plot.text([xbar], {\n      x: d =&gt; d,\n      y: leftYMax * 0.95,\n      text: d =&gt; `x̄ = ${d.toFixed(2)}`,\n      textAnchor: anchor,\n      dx: xbar &lt; mid ? 8 : -8,\n      dy: -2,\n      fontSize: 14,\n      fill: \"currentColor\"\n    }),\n    Plot.ruleY([0]),\n  ]\n});\n\n// ========= Right panel: saved sample means =========\nmeans = meanHistory\n\n// Domain for right panel\nmPad = 3 * controls.trueSigma / Math.sqrt(controls.n)\nmDomain = means.length &gt; 0 \n  ? [\n      Math.min(d3.min(means), controls.trueMu - mPad, xbar - 0.1),\n      Math.max(d3.max(means), controls.trueMu + mPad, xbar + 0.1)\n    ]\n  : [controls.trueMu - mPad, controls.trueMu + mPad]\n\n// True distribution PDF\nsampleMeanPdf = (x) =&gt; {\n  const variance = controls.trueSigma ** 2 / controls.n;\n  return (1 / Math.sqrt(2 * Math.PI * variance)) *\n    Math.exp(-((x - controls.trueMu) ** 2) / (2 * variance));\n}\n\npdfData = d3.range(mDomain[0], mDomain[1], (mDomain[1] - mDomain[0]) / 200)\n  .map(x =&gt; ({ x, y: sampleMeanPdf(x) }));\n\n// Compute histogram for means if we have any\nrightBins = means.length &gt; 0 \n  ? d3.bin().domain(mDomain).thresholds(controls.bins)(means)\n  : [];\nrightDensities = rightBins.map(b =&gt; \n  b.length / means.length / Math.max(1e-9, b.x1 - b.x0)\n);\nrightYMax = Math.max(\n  d3.max(rightDensities) || 0.1,\n  controls.showTrue ? d3.max(pdfData, d =&gt; d.y) || 0.1 : 0.1\n);\n\nrightPlot = Plot.plot({\n  width: Math.min(600, Math.max(320, width/2 - 20)),\n  height: 320,\n  style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont,\n    fontSize: 14,\n  },\n  x: { label: \"x̄\", domain: mDomain },\n  y: { label: \"Density\", domain: [0, rightYMax * 1.1] },\n  marks: [\n    // Histogram of means\n    means.length &gt; 0 ? Plot.rectY(\n      rightBins,\n      {\n        x1: d =&gt; d.x0,\n        x2: d =&gt; d.x1,\n        y: d =&gt; d.length / means.length / (d.x1 - d.x0),\n        fill: \"var(--brand-red)\",\n        fillOpacity: 0.3\n      }\n    ) : null,\n    // Vertical lines for saved means (like left plot)\n    means.length &gt; 0 ? Plot.ruleX(means, {\n      y1: 0,\n      y2: rightYMax * 0.05,\n      stroke: \"var(--brand-red)\",\n      strokeWidth: 2,\n      strokeOpacity: 0.8\n    }) : null,\n    // Current sample mean (not yet in history)\n    Plot.ruleX([xbar], {\n      y1: 0,\n      y2: rightYMax * 0.07,\n      stroke: \"currentColor\",\n      strokeWidth: 3,\n      strokeOpacity: 1\n    }),\n    // Label for current mean\n    Plot.text([xbar], {\n      x: d =&gt; d,\n      y: rightYMax * 0.08,\n      text: \"current\",\n      textAnchor: \"middle\",\n      fontSize: 10,\n      fill: \"currentColor\"\n    }),\n    // True distribution\n    Plot.line(pdfData, {\n      x: \"x\",\n      y: \"y\",\n      strokeWidth: 2,\n      stroke: \"var(--brand-red)\",\n      strokeOpacity: controls.showTrue ? 1 : 0\n    }),\n    Plot.ruleY([0])\n  ].filter(d =&gt; d !== null)\n})\n\n// ========= Display =========\n{\n  for (const f of [viewof resample, viewof reset]) {\n    f.style.margin = \"0\";\n    f.style.width = \"100%\";\n    f.style.maxWidth = \"none\";\n    f.style.display = \"flex\";\n  }\n  viewof resample.style.justifyContent = \"flex-start\";\n  viewof reset.style.justifyContent = \"flex-end\";\n\n  return html`&lt;div class=\"ojs-toolbar-grid\"&gt;\n    &lt;div class=\"left\"&gt;${viewof resample}&lt;/div&gt;\n    &lt;div class=\"center\"&gt;\n      &lt;div&gt;${tex`\\bar{x} = ${xbar.toFixed(2)}`}&lt;/div&gt;\n      &lt;div style=\"font-size:0.8em; opacity:0.7\"&gt;\n        ${means.length} sample${means.length !== 1 ? 's' : ''} collected\n      &lt;/div&gt;\n    &lt;/div&gt;\n    &lt;div class=\"right\"&gt;${viewof reset}&lt;/div&gt;\n  &lt;/div&gt;\n\n  &lt;style&gt;\n    .ojs-toolbar-grid{\n      display:grid;\n      grid-template-columns:1fr auto 1fr;\n      align-items:center;\n      width:100%;\n      box-sizing:border-box;\n      margin:0; padding:0;\n    }\n    .ojs-toolbar-grid form{\n      margin:0 !important;\n      width:100% !important;\n      max-width:none !important;\n      display:flex !important;\n    }\n    .ojs-toolbar-grid .left form{ justify-content:flex-start !important; }\n    .ojs-toolbar-grid .right form{ justify-content:flex-end !important; }\n\n    .btn.btn-resample{ background: var(--brand-teal); color:#fff; border:none; }\n    .btn.btn-resample:hover{ background: var(--brand-teal-hover); }\n    .btn.btn-reset{ background: var(--brand-red); color:#fff; border:none; }\n    .btn.btn-reset:hover{ background: var(--brand-red-hover); }\n    .btn.btn-resample:focus-visible,\n    .btn.btn-reset:focus-visible{\n      outline: 2px solid currentColor;\n      outline-offset: 2px;\n    }\n\n    .ojs-toolbar-grid .center{\n      text-align:center;\n      font-size:0.9rem;\n      color: var(--brand-fg);\n    }\n  &lt;/style&gt;`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div style=\"max-width:100%; display:flex; gap:14px; align-items:flex-start; flex-wrap:nowrap;\"&gt;\n  &lt;div&gt;${leftPlot}&lt;/div&gt;\n  &lt;div&gt;${rightPlot}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\nviewof controls = {\n  const leftForm = Inputs.form({\n    n: Inputs.range([1, 400], { value: 10, step: 1, label: md`${tex`n`}` }),\n    trueMu: Inputs.range([-2, 2], { value: 0, step: 0.1, label: md`${tex`\\mu_{\\text{true}}`}` }),\n    trueSigma: Inputs.range([0.3, 3], { value: 1, step: 0.1, label: md`${tex`\\sigma_{\\text{true}}`}` })\n  }, { submit: false });\n\n  const rightForm = Inputs.form({\n    samplesPerClick: Inputs.range([1, 10], { \n      value: 1, \n      step: 1, \n      label: \"Samples per click\" \n    }),\n    bins: Inputs.range([10, 60], { value: 24, step: 1, label: \"Histogram bins\" }),\n    showTrue: Inputs.toggle({ label: md`Show ${tex`\\bar{X}`} distribution`, value: false })\n  }, { submit: false });\n\n  const root = html`&lt;details class=\"controls-root\" open&gt;\n    &lt;summary&gt;Simulation controls&lt;/summary&gt;\n    &lt;div class=\"controls-grid\"&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Data & truth&lt;/h4&gt;&lt;/div&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Display & actions&lt;/h4&gt;&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/details&gt;`;\n  \n  root.querySelector(\".controls-grid\").children[0].append(leftForm);\n  root.querySelector(\".controls-grid\").children[1].append(rightForm);\n\n  const getValue = () =&gt; ({ ...leftForm.value, ...rightForm.value });\n  const update = () =&gt; {\n    root.value = getValue();\n    root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true }));\n  };\n\n  leftForm.addEventListener(\"input\", update);\n  rightForm.addEventListener(\"input\", update);\n\n  queueMicrotask(update);\n  return root;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 4.3 (Sampling Distribution) The sampling distribution of an estimator \\hat\\theta=\\hat{\\theta}(X_1,\\ldots,X_n) is the probability distribution of \\hat\\theta induced by the joint distribution of (X_1,\\ldots,X_n).\n\n\n\n\nThe properties 4.2 of an estimator, such as bias and standard error, are defined via this distribution.\nIn general, however, deriving an exact sampling distribution is hard, because:\n\nIt depends on the chosen statistical model for the data (the distribution of X_i).\n\nThe estimator \\hat\\theta may be a complicated/nonlinear function of the sample.\n\nIn a few special cases, however, we can derive the full sampling distribution of the estimator.\n\n\n\n\n\n\n\nProposition 4.2 (Normal Random Sample: Sampling Distribution of \\bar{X}) If \nX_1,\\dots,X_n \\overset{\\text{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2),\n then \n\\bar{X} \\;\\sim\\; \\mathcal{N}\\!\\left(\\mu,\\ \\frac{\\sigma^2}{n}\\right).\n\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 4.2. Averages are linear combinations: \\bar X=\\tfrac1n\\sum_{i=1}^n X_i. By the properties of the normal distribution 2.5.1, a linear combination of independent Normal variables is Normal. Moreover, \n\\mathrm{E}[\\bar X]=\\tfrac1n\\sum \\mathrm{E}[X_i]=\\mu,\\qquad\n\\mathrm{Var}(\\bar X)=\\tfrac{1}{n^2}\\sum \\mathrm{Var}(X_i)=\\frac{\\sigma^2}{n}.\n So \\bar X\\sim \\mathcal N\\!\\left(\\mu,\\sigma^2/n\\right).\n\n\n\n\n\n\n\n\n\n\n\nProposition 4.3 (Normal Random Sample: Sampling Distribution of S^2) If\n\nX_1,\\dots,X_n \\overset{\\text{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2),\n\nthen\n\nThe scaled sample variance follows a chi-squared distribution: \n  \\dfrac{(n-1)S^2}{\\sigma^2} \\;\\sim\\; \\chi^2_{\\,n-1},\n  \nThe sample mean \\bar{X} and the sample variance S^2 are independent random variables.\n\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 4.3 (Not Examinable). The proof relies on the following property of the \\chi^2_p distribution: For p i.i.d. standard normal random variables \nZ_1,\\ldots, Z_p \\overset{\\text{iid}}{\\sim} \\mathcal{N}(0, 1)\n their squared sum is \\chi^2_p distributed: \n\\sum_{i=1}^p Z_i^2 \\sim \\chi^2_p.\n\nThe key idea in the following proof to express \\dfrac{(n-1)S^2}{\\sigma^2} as a sum of n-1 i.i.d. standard normal random variables.\nStep 1 (Standardise and express S^2 as a residual sum of squares). Define the standardised variables\n\nY_i \\;=\\; \\frac{X_i-\\mu}{\\sigma}\\quad (i=1,\\dots,n), \\qquad\n\\text{so } Y_1,\\dots,Y_n \\overset{\\text{iid}}{\\sim} \\mathcal{N}(0, 1).\n\nLet \\bar Y = \\tfrac1n\\sum_{i=1}^n Y_i = \\dfrac{\\bar X-\\mu}{\\sigma}. Then\n\n\\sum_{i=1}^n (X_i-\\bar X)^2\n= \\sigma^2 \\sum_{i=1}^n \\bigl( Y_i-\\bar Y \\bigr)^2,\n\nso\n\n\\frac{(n-1)S^2}{\\sigma^2}\n= \\sum_{i=1}^n \\bigl( Y_i-\\bar Y \\bigr)^2.\n\nThus \\dfrac{(n-1)S^2}{\\sigma^2} is the sum of squares of residuals after projecting Y onto its mean.\nThe remaining steps are to manipulate \\sum_{i=1}^n \\bigl( Y_i-\\bar Y \\bigr)^2 as a sum of n-1 i.i.d. squared standard Normal random variables.\nStep 2 (Define n-1 “difference of mean vs next observation” variables). For k=1,\\dots,n-1, let \\bar Y_k=\\tfrac1k\\sum_{i=1}^k Y_i and define\n\nZ_k \\;=\\; \\sqrt{\\frac{k}{k+1}}\\;\\bigl(\\bar Y_k - Y_{k+1}\\bigr).\n\nEach Z_k is a linear combination of independent \\mathcal N(0,1), hence Normal. Also,\n\n\\mathrm{E}[Z_k]=0,\\qquad\n\\mathrm{Var}(Z_k)=\\frac{k}{k+1}\\Bigl(\\mathrm{Var}(\\bar Y_k)+\\mathrm{Var}(Y_{k+1})\\Bigr)\n=\\frac{k}{k+1}\\Bigl(\\frac{1}{k}+1\\Bigr)=1,\n\nso Z_k\\sim \\mathcal N(0,1).\nStep 3 (The Z_k are independent).\nFix 1\\le j&lt;k\\le n-1. Write Z_j=a_j(\\bar Y_j-Y_{j+1}) with a_j=\\sqrt{j/(j+1)}, and\n\nZ_k=a_k(\\bar Y_k-Y_{k+1}),\\qquad a_k=\\sqrt{\\frac{k}{k+1}},\\qquad\n\\bar Y_k=\\frac{1}{k}\\sum_{i=1}^k Y_i.\n\nView each Z as a linear combination of the Y_i. The coefficients are:\n\nfor Z_j: a_j\\cdot \\frac1j on Y_1,\\dots,Y_j; -a_j on Y_{j+1}; 0 otherwise;\nfor Z_k: a_k\\cdot \\frac1k on Y_1,\\dots,Y_k; -a_k on Y_{k+1}; 0 otherwise.\n\nUsing independence and \\mathrm{Var}(Y_i)=1,\n\n\\mathrm{Cov}(Z_j,Z_k)=\\sum_{i=1}^n \\text{(coeff of }Y_i\\text{ in }Z_j)\\times \\text{(coeff of }Y_i\\text{ in }Z_k).\n\nOnly i=1,\\dots,j and i=j+1 overlap. Hence\n\n\\mathrm{Cov}(Z_j,Z_k)\n=\\sum_{i=1}^j \\Bigl(a_j\\frac1j\\Bigr)\\Bigl(a_k\\frac1k\\Bigr)\n\\;+\\; \\Bigl(-a_j\\Bigr)\\Bigl(a_k\\frac1k\\Bigr)\n= a_ja_k\\Bigl(\\frac{j}{jk}-\\frac{1}{k}\\Bigr)=0.\n\nThus the Z_k are pairwise uncorrelated. Since they are all Normal (linear combos of independent Normals), uncorrelated \\Rightarrow independent. So Z_1,\\dots,Z_{n-1} are independent \\mathcal N(0,1).\nStep 4 (\\tfrac{(n-1)S^2}{\\sigma^2}= \\sum_{k=1}^{n-1} Z_k^2 ).\nDefine S_k=\\sum_{i=1}^k (Y_i-\\bar Y_k)^2 (so S_n=\\sum_{i=1}^n (Y_i-\\bar Y)^2). Write Y_i-\\bar Y_{k+1} = (Y_i-\\bar Y_k) + (\\bar Y_k-\\bar Y_{k+1}), use \\sum_{i=1}^k (Y_i-\\bar Y_k)=0 to kill the cross-term, and note \\bar Y_{k+1}-\\bar Y_k=\\tfrac{Y_{k+1}-\\bar Y_k}{k+1}.\nTherefore, we have the recursive formula for S_k: \nS_{k+1} \\;=\\; S_k \\;+\\; \\frac{k}{k+1}\\,\\bigl(\\bar Y_k - Y_{k+1}\\bigr)^2\n\\qquad (k=1,\\dots,n-1).\n\nBy induction, \nS_n\n=\\sum_{k=1}^{n-1}\\frac{k}{k+1}\\,\\bigl(\\bar Y_k - Y_{k+1}\\bigr)^2\n=\\sum_{k=1}^{n-1} Z_k^2.\n\nConclusion From the previous step, we have shown\n\n\\frac{(n-1)S^2}{\\sigma^2}\n=\\sum_{i=1}^n (Y_i-\\bar Y)^2\n=\\sum_{k=1}^{n-1} Z_k^2,\n\na sum of n-1 independent standard Normal squares, hence\n\n\\boxed{\\;\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{\\,n-1}\\;}.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Frequentist Point Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part2/4-freq-point-estimation.html#sec-estimator-properties",
    "href": "content/main/part2/4-freq-point-estimation.html#sec-estimator-properties",
    "title": "4  Frequentist Point Estimation",
    "section": "4.2 Properties of Estimators",
    "text": "4.2 Properties of Estimators\nWhen we use a statistic to estimate a parameter, we want to judge how good an estimator is.\nThree fundamental properties guide this assessment:\n\nBias: Does the estimator hit the right target on average?\nVariance/Standard Error: How much does it fluctuate from sample to sample?\nMean Squared Error (MSE): A combined measure that balances both bias and variance.\n\nIn this section we first look at bias 4.4, variance 4.5, and standard error 4.6, then bring them together through the MSE 4.8.\n\n\n\n\n\n\nTipRemark (Properties via Moments)\n\n\n\n\n\n\nRemark 4.2 (Properties via Moments). In the previous section we introduced the sampling distribution 4.3 of an estimator.\nThe key idea for what follows is that we don’t need the entire distribution to study how good an estimator is. The main properties — bias, variance, standard error, and MSE — can all be expressed in terms of expectations (i.e. moments 1.12).\nSo in practice, we will usually only need to work with the first and second moments of \\hat\\theta, rather than its full sampling distribution.\n\n\n\n\n\n4.2.1 Bias, Variance, and Standard Error\n\n\n\n\n\n\n\nDefinition 4.4 (Bias of an Estimator) The bias of an estimator \\hat{\\theta} for a parameter \\theta is the difference between its expected value and the true parameter value:\n\n\\mathrm{Bias}(\\hat{\\theta}) = \\mathrm{E}[\\hat{\\theta}] - \\theta.\n\n\nIf \\mathrm{Bias}(\\hat{\\theta}) = 0, the estimator is called unbiased.\nOtherwise, it is biased: it systematically over- or under-estimates \\theta.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4.1 (Bias of the Sample Mean) Suppose X_1,\\dots,X_n \\overset{\\text{iid}}{\\sim} \\mathrm{Distribution}(\\mu,\\sigma^2) with mean \\mu.\nShow that the sample mean\n\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i\n\nis an unbiased estimator of \\mu.\n\n   Solution \nWe compute the expectation of \\bar{X}:\n\n\\mathrm{E}[\\bar{X}]\n= \\mathrm{E}\\!\\left[\\frac{1}{n}\\sum_{i=1}^n X_i\\right]\n= \\frac{1}{n}\\sum_{i=1}^n \\mathrm{E}[X_i].\n\nSince each X_i has mean \\mu,\n\n\\mathrm{E}[\\bar{X}] = \\frac{1}{n}(n\\mu) = \\mu.\n\nTherefore,\n\n\\mathrm{Bias}(\\bar{X})\n= \\mathrm{E}[\\bar{X}] - \\mu\n= \\mu - \\mu = 0.\n\nSo the sample mean \\bar{X} is an unbiased estimator of \\mu.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 4.5 (Variance of an Estimator) The variance measures how much the estimator fluctuates around its expectation:\n\n\\mathrm{Var}(\\hat{\\theta}) = \\mathrm{E}\\!\\big[(\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}])^2\\big].\n\nA smaller variance means the estimator is more concentrated and less “noisy.”\n\n\n\n\n\n\n\n\n\n\n\nExample 4.2 (Variance of the Sample Mean) Suppose X_1,\\ldots,X_n is a random sample such that \\mathrm{Var}(X_i) = \\sigma^2.\nShow that \n\\mathrm{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\n\n   Solution \nSince the data X_i are independent and have common variance \\sigma^2, we have\n\n\\mathrm{Var}(\\bar{X})\n= \\frac{1}{n^2} \\mathrm{Var}\\left[\\sum_{i=1}^n X_i\\right] = \\frac{1}{n^2} \\sum_{i=1}^n \\mathrm{Var}(X_i)\n= \\frac{\\sigma^2}{n}.\n\nSo as n increases, \\bar{X} becomes more tightly clustered around \\mu.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4.3 (Bias of the Sample Variance) Suppose X_1,\\ldots,X_n is a random sample such that \n\\mathrm{E}[X_i]=\\mu \\quad \\text{and} \\quad \\mathrm{Var}(X_i)=\\sigma^2&lt;\\infty.\n Consider the class of estimators \nS_c^{2} \\;=\\; \\frac{1}{c} \\sum_{i=1}^n (X_i-\\bar X)^2.\n Find c such that S_c^{2} is unbiased for \\sigma^2.\n\n   Solution \n\nNote: In the following, we use the fact that, for any random variable Y, \n\\mathrm{Var}(Y) = \\mathrm{E}[Y^2] - \\mathrm{E}[Y]^2 \\Rightarrow \\mathrm{E}[Y^2] = \\mathrm{Var}(Y) + \\mathrm{E}[Y]^2.\n\n\nWe seek c such that \\mathrm{E}[S_c^{2}] = \\sigma^2.\nUsing the computational identity 4.1, \n\\sum_{i=1}^n (X_i-\\bar X)^2 \\;=\\; \\sum_{i=1}^n X_i^2 \\;-\\; n\\,\\bar X^{\\,2}.\n\nHence, taking expectations termwise, \n\\mathrm{E}[X_i^2]=\\sigma^2+\\mu^2,\\qquad\n\\mathrm{E}[\\bar X^{\\,2}]=\\mathrm{Var}(\\bar X)+\\{\\mathrm{E}[\\bar X]\\}^2=\\frac{\\sigma^2}{n}+\\mu^2.\n Therefore \n\\mathrm{E}\\!\\left[\\sum_{i=1}^n (X_i-\\bar X)^2\\right]\n= n(\\sigma^2+\\mu^2) - n\\!\\left(\\frac{\\sigma^2}{n}+\\mu^2\\right)\n= (n-1)\\sigma^2.\n It follows that \n\\mathrm{E}[S_c^{2}] = \\frac{(n-1)\\sigma^2}{c}\n Unbiasedness \\mathrm{E}[S_c^{2}]=\\sigma^2 gives c=n-1.\nConclusion. The unbiased estimator is \nS^{2} \\;=\\; \\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\bar X)^2.\n\n\n\n\n\n\nIn the next visualisation we look at the bias of the naive sample variance:\n\nS^2_n = \\frac{1}{n}\\sum_{i=1}^n (X_i-\\bar{X})^2.\n\nFrom Example 4.3, the bias is\n\n\\mathrm{Bias}(S^2_n) = -\\frac{\\sigma^2}{n}.\n\nThis means S^2_n systematically underestimates the true population variance \\sigma^2.\n\n\nShow Visualisation\nIn the right-hand panel of the simulation, notice how the sampling distribution of S^2_n is centred below \\sigma^2. As n increases, the bias shrinks (since -\\sigma^2/n \\to 0), but for small n the underestimation is quite visible.\n\naddLegendTopRight = (svg, items, {\n  padding = 8,\n  gap = 10,                // you can keep this small now\n  swatch = 17,\n  fontFamily = bodyFont,\n  fontSize = 12,\n  corner = 10,             // distance from top-right\n  bg = \"var(--header-bg)\",\n  border = \"var(--border)\"\n} = {}) =&gt; {\n  const root = d3.select(svg);\n\n  // Build legend; park it off-screen so it still participates in layout.\n  const g = root.append(\"g\")\n    .attr(\"class\", \"plot-legend\")\n    .attr(\"font-family\", fontFamily)\n    .attr(\"font-size\", fontSize)\n    .attr(\"pointer-events\", \"none\")\n    .attr(\"transform\", \"translate(-1000000,-1000000)\");\n\n  const rowGap = 8;\n  const rows = g.selectAll(\"g.row\")\n    .data(items)\n    .join(\"g\")\n      .attr(\"class\", \"row\")\n      .attr(\"transform\", (d, i) =&gt; `translate(0, ${i * (fontSize + rowGap) + fontSize / 2})`);\n\n  // swatch\n  rows.append(\"line\")\n    .attr(\"x1\", 0).attr(\"x2\", swatch)\n    .attr(\"y1\", 0).attr(\"y2\", 0)\n    .attr(\"stroke\", d =&gt; d.stroke)\n    .attr(\"stroke-width\", d =&gt; d.strokeWidth ?? 2)\n    .attr(\"stroke-dasharray\", d =&gt; d.dasharray ?? null)\n    .attr(\"stroke-linecap\", \"butt\");\n\n  // label\n  rows.append(\"text\")\n    .attr(\"x\", swatch + gap)\n    .attr(\"y\", 0)\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"fill\", d =&gt; d.stroke)\n    .attr(\"font-weight\", \"600\")\n    .text(d =&gt; d.label);\n\n  const labels = rows.select(\"text\");\n\n  // Background (inserted now; sized after measurement)\n  const bgRect = g.insert(\"rect\", \":first-child\")\n    .attr(\"class\", \"legend-bg\")\n    .attr(\"rx\", 8).attr(\"ry\", 8)\n    .attr(\"fill\", bg)\n    .attr(\"fill-opacity\", 0.9)\n    .attr(\"stroke\", border);\n\n  function place() {\n    // 1) Ensure labels' *painted* left edge starts at swatch+gap\n    let adjusted = false;\n    labels.each(function () {\n      const t = this;\n      const b = t.getBBox();\n      const desiredLeft = swatch + gap;   // in the row's coord system\n      const overshoot = desiredLeft - b.x; // &gt;0 means glyph extends left\n      if (overshoot &gt; 0.1) {\n        const x = parseFloat(t.getAttribute(\"x\")) || 0;\n        t.setAttribute(\"x\", x + overshoot);\n        adjusted = true;\n      }\n    });\n\n    // If we adjusted any label, schedule another frame so BBoxes settle\n    if (adjusted) {\n      requestAnimationFrame(place);\n      return;\n    }\n\n    // 2) Size background to content\n    const content = g.node().getBBox();\n    if (!content || content.width === 0 || content.height === 0) {\n      requestAnimationFrame(place);\n      return;\n    }\n\n    const boxW = content.width + 2 * padding;\n    const boxH = content.height + 2 * padding;\n\n    bgRect\n      .attr(\"x\", content.x - padding)\n      .attr(\"y\", content.y - padding)\n      .attr(\"width\", boxW)\n      .attr(\"height\", boxH);\n\n    // 3) Anchor to SVG viewBox top-right\n    const vb = svg.viewBox?.baseVal;\n    const vbx = vb?.x ?? 0;\n    const vby = vb?.y ?? 0;\n    const vbw = vb?.width\n      ?? (+svg.getAttribute(\"width\") || svg.getBBox().width || svg.getBoundingClientRect().width);\n\n    const tx = Math.round(vbx + vbw - boxW - corner);\n    const ty = Math.round(vby + corner);\n\n    g.attr(\"transform\", `translate(${tx}, ${ty})`);\n  }\n\n  requestAnimationFrame(place);\n};\n\n\n\n\n\n\n\nmutable biasRngSeed = 1\nmutable varianceHistory = []\nmutable biasResampleClicks = 0\nmutable biasResetClicks = 0\nmutable biasLastSamplesPerClick = 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  if (biasReset &gt; biasResetClicks) {\n    mutable varianceHistory = [];\n    mutable biasResetClicks = biasReset;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n{\n  if (biasControls.biasSamplesPerClick !== biasLastSamplesPerClick) {\n    mutable biasLastSamplesPerClick = biasControls.biasSamplesPerClick;\n    mutable biasResampleClicks = 0;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n{\n  if (biasResample &gt; biasResampleClicks) {\n    // Add the current variance to history first\n    mutable varianceHistory = [...varianceHistory, sampleVar];\n    \n    // If doing multiple samples, add the additional ones\n    if (biasControls.biasSamplesPerClick &gt; 1) {\n      const additionalVariances = [];\n      for (let i = 1; i &lt; biasControls.biasSamplesPerClick; i++) {\n        const rand = d3.randomNormal.source(d3.randomLcg(biasRngSeed + i))(biasControls.biasTrueMu, biasControls.biasTrueSigma);\n        const sample = d3.range(biasControls.biasN).map(rand);\n        const mean = d3.mean(sample);\n        // Biased variance estimator (1/n)\n        const variance = d3.sum(sample, d =&gt; (d - mean) ** 2) / biasControls.biasN;\n        additionalVariances.push(variance);\n      }\n      mutable varianceHistory = [...varianceHistory, ...additionalVariances];\n    }\n    \n    // Update seed for next sample (which will be displayed)\n    mutable biasRngSeed = biasRngSeed + biasControls.biasSamplesPerClick;\n    mutable biasResampleClicks = biasResample;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n\n\nfunction biasStyledButton(label, cls, options = {}) {\n  const el = Inputs.button(label, options);\n  const btn = el.querySelector('button');\n  if (btn) btn.classList.add(cls);\n  return el;\n}\n\n// Define themed buttons with updated label for multi-sample\nviewof biasResample = biasStyledButton(\n  biasControls.biasSamplesPerClick &gt; 1 \n    ? `Resample (×${biasControls.biasSamplesPerClick})` \n    : \"Resample\", \n  \"btn-resample\", \n  { reduce: c =&gt; (c ?? 0) + 1 }\n);\n\nviewof biasReset = biasStyledButton(\"Reset\", \"btn-reset\", {\n  reduce: c =&gt; (c ?? 0) + 1\n});\n\n// --- Current sample (always visible) ---\nbiasX = {\n  const rand = d3.randomNormal.source(d3.randomLcg(biasRngSeed))(biasControls.biasTrueMu, biasControls.biasTrueSigma);\n  return d3.range(biasControls.biasN).map(rand);\n}\nbiasXbar = d3.mean(biasX)\n// Biased variance estimator (1/n instead of 1/(n-1))\nsampleVar = d3.sum(biasX, d =&gt; (d - biasXbar) ** 2) / biasControls.biasN\n// Unbiased variance for comparison\nunbiasedVar = biasControls.biasN &gt; 1 ? d3.sum(biasX, d =&gt; (d - biasXbar) ** 2) / (biasControls.biasN - 1) : 0\n\n// ========= Left panel: current sample ========= \nbiasLeftBins = d3.bin().domain(biasXDomain).thresholds(biasControls.biasBins)(biasX)\nbiasLeftDensities = biasLeftBins.map(b =&gt; b.length / biasControls.biasN / Math.max(1e-9, b.x1 - b.x0))\nbiasLeftYMax = Math.max(0.1, d3.max(biasLeftDensities) || 0.1);\n\n// ========= Shared computation =========\nbiasXPad = 3 * biasControls.biasTrueSigma\nbiasXDomain = [biasControls.biasTrueMu - biasXPad, biasControls.biasTrueMu + biasXPad]\n\nbiasLeftPlot = Plot.plot({\n  width: Math.min(600, Math.max(320, width/2 - 20)),\n  height: 320,\n  marginTop: 20,\n  marginRight: 20,\n  marginBottom: 40,\n  marginLeft: 50,\n  style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont,\n    fontSize: 14,\n  },\n  x: { label: \"Data\", domain: biasXDomain },\n  y: { label: \"Density\", domain: [0, biasLeftYMax * 1.1] },\n  marks: [\n    // histogram\n    Plot.rectY(biasLeftBins, {\n      x1: d =&gt; d.x0,\n      x2: d =&gt; d.x1,\n      y: d =&gt; d.length / biasControls.biasN / Math.max(1e-9, d.x1 - d.x0),\n      fill: \"var(--brand-teal)\",\n      fillOpacity: 0.4\n    }),\n    Plot.ruleY([0]),\n    // ticks at data points\n    Plot.ruleX(biasX, {\n      y1: 0,\n      y2: biasLeftYMax * 0.05,\n      stroke: \"var(--brand-teal)\",\n      strokeWidth: 2,\n      strokeOpacity: 0.8\n    }),\n  ]\n});\n\n// ========= Right panel: saved sample variances =========\nvariances = varianceHistory\ntrueVariance = biasControls.biasTrueSigma ** 2\n\n// Calculate empirical bias\nempiricalMean = variances.length &gt; 0 ? d3.mean(variances) : null\nempiricalBias = empiricalMean !== null ? empiricalMean - trueVariance : null\n\n// Domain for right panel\nvarPad = trueVariance * 2\nvarDomain = variances.length &gt; 0 \n  ? [\n      Math.min(d3.min(variances), 0),\n      Math.max(d3.max(variances), trueVariance + varPad, sampleVar + 0.1)\n    ]\n  : [0, trueVariance + varPad]\n\n// Compute histogram for variances if we have any\nbiasRightBins = variances.length &gt; 0 \n  ? d3.bin().domain(varDomain).thresholds(biasControls.biasBins)(variances)\n  : [];\nbiasRightDensities = biasRightBins.map(b =&gt; \n  b.length / variances.length / Math.max(1e-9, b.x1 - b.x0)\n);\nbiasRightYMax = Math.max(\n  d3.max(biasRightDensities) || 0.1,\n  0.1\n);\n\n// ------- usage inside your cell that creates the plot -------\nbiasRightPlot = {\n  // Ensure d3 exists in this runtime\n  const d3 = globalThis.d3 ?? await require(\"d3@7\");\n\n  const svg = Plot.plot({\n    width: Math.min(600, Math.max(320, width / 2 - 20)),\n    height: 320,\n    style: {\n      background: \"var(--plot-panel-bg)\",\n      color: \"var(--brand-fg)\",\n      fontFamily: bodyFont,\n      fontSize: 14\n    },\n    x: { label: \"sₙ²\", domain: varDomain },\n    y: { label: \"Density\", domain: [0, biasRightYMax * 1.1] },\n    marks: [\n      variances.length &gt; 0 ? Plot.rectY(\n        biasRightBins,\n        {\n          x1: d =&gt; d.x0,\n          x2: d =&gt; d.x1,\n          y: d =&gt; d.length / variances.length / (d.x1 - d.x0),\n          fill: \"var(--brand-red)\",\n          fillOpacity: 0.3\n        }\n      ) : null,\n      variances.length &gt; 0 ? Plot.ruleX(variances, {\n        y1: 0,\n        y2: biasRightYMax * 0.05,\n        stroke: \"var(--brand-red)\",\n        strokeWidth: 2,\n        strokeOpacity: 0.8\n      }) : null,\n      Plot.ruleX([sampleVar], {\n        y1: 0,\n        y2: biasRightYMax * 0.07,\n        stroke: \"currentColor\",\n        strokeWidth: 3,\n        strokeOpacity: 1\n      }),\n      Plot.ruleX([trueVariance], {\n        stroke: \"var(--brand-purple)\",\n        strokeWidth: 3,\n        strokeOpacity: biasControls.biasShowTrue ? 1 : 0\n      }),\n      empiricalMean !== null && biasControls.biasShowTrue ? Plot.ruleX([empiricalMean], {\n        stroke: \"var(--brand-red)\",\n        strokeWidth: 2,\n        strokeDasharray: \"6,3\",\n        strokeOpacity: 1\n      }) : null,\n      Plot.ruleY([0])\n    ].filter(Boolean)\n  });\n\n  // Legend items\n  const items = [];\n  if (biasControls.biasShowTrue) {\n    items.push({ label: `σ² = ${trueVariance.toFixed(2)}`, stroke: \"var(--brand-purple)\", strokeWidth: 3 });\n  }\n  if (empiricalMean !== null && biasControls.biasShowTrue) {\n    items.push({ label: `E[Sₙ²] ≈ ${empiricalMean.toFixed(3)}`, stroke: \"var(--brand-red)\", strokeWidth: 2, dasharray: \"6,3\" });\n  }\n\n  if (items.length) addLegendTopRight(svg, items, { fontFamily: bodyFont, fontSize: 12, corner: 10 });\n\n  return svg;\n}\n\n\n// ========= Display =========\n{\n  for (const f of [viewof biasResample, viewof biasReset]) {\n    f.style.margin = \"0\";\n    f.style.width = \"100%\";\n    f.style.maxWidth = \"none\";\n    f.style.display = \"flex\";\n  }\n  viewof biasResample.style.justifyContent = \"flex-start\";\n  viewof biasReset.style.justifyContent = \"flex-end\";\n\n  return html`&lt;div class=\"ojs-toolbar-grid\"&gt;\n    &lt;div class=\"left\"&gt;${viewof biasResample}&lt;/div&gt;\n    &lt;div class=\"center\"&gt;\n      ${empiricalBias !== null && biasControls.biasShowTrue ? html`\n      &lt;div&gt;${tex`s_n^2 = ${sampleVar.toFixed(3)} \\,`}  and  ${tex`\\, \\text{Bias}(S_n^2) \\approx ${empiricalBias.toFixed(3)}`}&lt;/div&gt;\n      ` : html`&lt;div&gt;${tex`s^2 = ${sampleVar.toFixed(3)}`}&lt;/div&gt;`}\n      &lt;div style=\"font-size:0.8em; opacity:0.7\"&gt;\n        ${variances.length} sample${variances.length !== 1 ? 's' : ''} collected\n      &lt;/div&gt;\n    &lt;/div&gt;\n    &lt;div class=\"right\"&gt;${viewof biasReset}&lt;/div&gt;\n  &lt;/div&gt;\n\n  &lt;style&gt;\n    .ojs-toolbar-grid{\n      display:grid;\n      grid-template-columns:1fr auto 1fr;\n      align-items:center;\n      width:100%;\n      box-sizing:border-box;\n      margin:0; padding:0;\n    }\n    .ojs-toolbar-grid form{\n      margin:0 !important;\n      width:100% !important;\n      max-width:none !important;\n      display:flex !important;\n    }\n    .ojs-toolbar-grid .left form{ justify-content:flex-start !important; }\n    .ojs-toolbar-grid .right form{ justify-content:flex-end !important; }\n\n    .btn.btn-resample{ background: var(--brand-teal); color:#fff; border:none; }\n    .btn.btn-resample:hover{ background: var(--brand-teal-hover); }\n    .btn.btn-reset{ background: var(--brand-red); color:#fff; border:none; }\n    .btn.btn-reset:hover{ background: var(--brand-red-hover); }\n    .btn.btn-resample:focus-visible,\n    .btn.btn-reset:focus-visible{\n      outline: 2px solid currentColor;\n      outline-offset: 2px;\n    }\n\n    .ojs-toolbar-grid .center{\n      text-align:center;\n      font-size:0.9rem;\n      color: var(--brand-fg);\n    }\n  &lt;/style&gt;`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div style=\"max-width:100%; display:flex; gap:14px; align-items:flex-start; flex-wrap:nowrap;\"&gt;\n  &lt;div&gt;${biasLeftPlot}&lt;/div&gt;\n  &lt;div&gt;${biasRightPlot}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\nviewof biasControls = {\n  const leftForm = Inputs.form({\n    biasN: Inputs.range([2, 100], { value: 5, step: 1, label: md`${tex`n`}` }),\n    biasTrueMu: Inputs.range([-2, 2], { value: 0, step: 0.1, label: md`${tex`\\mu_{\\text{true}}`}` }),\n    biasTrueSigma: Inputs.range([0.3, 3], { value: 1, step: 0.1, label: md`${tex`\\sigma_{\\text{true}}`}` })\n  }, { submit: false });\n\n  const rightForm = Inputs.form({\n    biasSamplesPerClick: Inputs.range([1, 10], { \n      value: 1, \n      step: 1, \n      label: \"Samples per click\" \n    }),\n    biasBins: Inputs.range([10, 60], { value: 24, step: 1, label: \"Histogram bins\" }),\n    biasShowTrue: Inputs.toggle({ label: md`Show empirical bias & true ${tex`\\sigma^2`}`, value: true })\n  }, { submit: false });\n  \n  const root = html`&lt;div class=\"controls-wrap\"&gt;\n    &lt;details class=\"controls-root\" open&gt;\n      &lt;summary&gt;Simulation controls&lt;/summary&gt;\n      &lt;div class=\"controls-grid\"&gt;\n        &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Data & truth size&lt;/h4&gt;&lt;/div&gt;\n        &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Display & actions&lt;/h4&gt;&lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/details&gt;\n  &lt;/div&gt;`;\n\n  root.querySelector(\".controls-grid\").children[0].append(leftForm);\n  root.querySelector(\".controls-grid\").children[1].append(rightForm);\n\n  const getValue = () =&gt; ({ ...leftForm.value, ...rightForm.value });\n  const update = () =&gt; {\n    root.value = getValue();\n    root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true }));\n  };\n\n  leftForm.addEventListener(\"input\", update);\n  rightForm.addEventListener(\"input\", update);\n\n  queueMicrotask(update);\n  return root;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipRemark (Notes on Example 4.3)\n\n\n\n\n\n\nRemark 4.3 (Notes on Example 4.3). \n\nDistributional assumptions. No Normality is required: the conclusion holds for i.i.d. observations with finite variance, \\mathrm{Var}(X_i)=\\sigma^2&lt;\\infty.\nMLE under Normality. If the data are Normal, the maximum-likelihood estimator is \n\\hat\\sigma^2_{\\text{MLE}}=\\frac{1}{n}\\sum_{i=1}^n (X_i-\\bar X)^2,\n which is biased downward: \n\\mathrm{E}\\!\\left[\\hat\\sigma^2_{\\text{MLE}}\\right]=\\frac{n-1}{n}\\,\\sigma^2\n\\quad\\big(\\text{bias}=-\\sigma^2/n\\big).\n See Example 5.12 for full details.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 4.6 (Standard Error) The standard error of an estimator \\hat{\\theta} of \\theta, is just the standard deviation of the estimator:\n\n\\mathrm{S.E.}(\\hat{\\theta}) = \\sqrt{\\mathrm{Var}(\\hat{\\theta})}.\n\nIt gives a scale for how much we expect the estimator to vary from sample to sample.\n\n\n\n\n\n\n4.2.2 Mean Squared Error (MSE)\nSo far we have seen that estimators can have bias and variance. Both are important, but it is often useful to combine them into a single overall measure of accuracy.\nTo get there, we start with the basic idea of error.\n\n\n\n\n\n\n\nDefinition 4.7 (Error) The error of an estimator is the difference between the estimate and the true parameter:\n\n\\mathrm{Error}(\\hat{\\theta}) = \\hat{\\theta} - \\theta.\n\n\n\n\n\nThis captures exactly “how far off” our estimate is. But there are two problems:\n\nThe error is a random variable (it depends on the sample we happened to draw).\nThe error can be positive or negative — so if we just averaged it across many samples, the positives and negatives might cancel out, misleading us into thinking the estimator is more accurate than it really is.\n\nTo fix this, we square the error (so it’s always positive) and then take its expectation (so we measure its typical size across many samples).\n\n\n\n\n\n\n\nDefinition 4.8 (Mean Squared Error (MSE)) The MSE of an estimator \\hat{\\theta} of \\theta is\n\n\\mathrm{MSE}(\\hat{\\theta})=\\mathrm{E}\\!\\big[(\\hat{\\theta}-\\theta)^2\\big].\n\nThis measures the average squared distance between the estimator and the true parameter value.\n\n\n\n\n\n\n\n\n\n\nTipRemark (Why Squared Error?)\n\n\n\n\n\n\nRemark 4.5 (Why Squared Error?). The MSE is built to solve the two problems with using the error 4.7:\n\nSquaring makes all errors positive (so no cancellation).\nExpectation removes randomness and shows the long-run behaviour of the estimator.\n\nBut squaring isn’t the only possible choice. For example, we could use absolute error and define the Mean Absolute Error (MAE):\n\n\\mathrm{MAE}(\\hat{\\theta}) = \\mathrm{E}\\!\\big[ \\lvert \\hat{\\theta} - \\theta \\rvert \\big].\n\nThis is also a sensible measure. In fact, in practice people sometimes prefer MAE because it is less sensitive to occasional very large errors.\nSo why is MSE so common in theory?\n\nIt penalises large deviations more strongly, which can be useful.\nIt is mathematically easier to work with. Many nice algebraic decompositions (like the bias-variance decomposition 4.4) only hold neatly for squared error.\n\n\n\n\n\nDirectly using the definition 4.8 of MSE can be awkward. A more useful identity decomposes MSE into bias and variance:\n\n\n\n\n\n\n\nProposition 4.4 (MSE: Bias–Variance Decomposition) For any estimator \\hat{\\theta},\n\n\\mathrm{MSE}(\\hat{\\theta})\n= \\mathrm{Bias}(\\hat{\\theta})^2+\\mathrm{Var}(\\hat{\\theta}).\n\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 4.4. Start from the definition:\n\n\\mathrm{MSE}(\\hat{\\theta})=\\mathrm{E}\\!\\big[(\\hat{\\theta}-\\theta)^2\\big].\n\nStep 1 (add–and–subtract the mean). Let m=\\mathrm{E}[\\hat{\\theta}]. Then\n\n\\hat{\\theta}-\\theta\n=\\big(\\hat{\\theta}-m\\big)+\\big(m-\\theta\\big).\n\nStep 2 (expand the square).\n\n(\\hat{\\theta}-\\theta)^2\n=\\big(\\hat{\\theta}-m\\big)^2\n+2\\big(\\hat{\\theta}-m\\big)\\big(m-\\theta\\big)\n+\\big(m-\\theta\\big)^2.\n\nStep 3 (take expectations; use linearity).\n\n\\mathrm{E}\\!\\big[(\\hat{\\theta}-\\theta)^2\\big]\n=\\underbrace{\\mathrm{E}\\!\\big[(\\hat{\\theta}-m)\\!^2\\big]}_{\\mathrm{Var}(\\hat{\\theta})}\n+2\\,(m-\\theta)\\,\\underbrace{\\mathrm{E}\\!\\big[\\hat{\\theta}-m\\big]}_{=\\,0}\n+\\underbrace{(m-\\theta)^2}_{\\mathrm{Bias}(\\hat{\\theta})^2}.\n\nThe middle term vanishes because \\mathrm{E}[\\hat{\\theta}-m]=\\mathrm{E}[\\hat{\\theta}]-m=0. Hence\n\n\\mathrm{MSE}(\\hat{\\theta})\n=\\mathrm{Var}(\\hat{\\theta})+\\big(\\mathrm{E}[\\hat{\\theta}]-\\theta\\big)^2\n=\\mathrm{Var}(\\hat{\\theta})+\\mathrm{Bias}(\\hat{\\theta})^2.\n\n\n\n\n\n\n\n\n\n\n\nTipRemark (Why this helps)\n\n\n\n\n\n\nRemark 4.5 (Why this helps). \n\nIf \\hat{\\theta} is unbiased, then \\mathrm{MSE}(\\hat{\\theta})=\\mathrm{Var}(\\hat{\\theta}).\nIn general there is a bias–variance trade-off: a small intentional bias can reduce variance enough to lower MSE (common in shrinkage/regularised estimators).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4.4 (MSE of Sample Mean) Suppose we have a random sample\n\nX_1,\\dots,X_n  \\overset{\\text{iid}}{\\sim} \\mathrm{Distribution}(\\underline{\\theta})\n\nand we wish to estimate its population mean \\mu with \\hat{\\mu} = c\\bar{X}, where c is a constant.\nCompute the MSE of this estimator.\n\n   Solution \n\nBias:\n\n\\mathrm{Bias}(\\hat{\\mu}) = (c-1)\\mu.\n\nVariance:\n\n\\mathrm{Var}(\\hat{\\mu}) = c^2 \\frac{\\sigma^2}{n}.\n\nMSE:\n\n\\mathrm{MSE}(\\hat{\\mu})\n= \\frac{c^2\\sigma^2}{n} + (c-1)^2 \\mu^2.\n\n\nThis shows how a biased estimator can still have low MSE if variance is reduced.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4.5 (MSE of Three Estimators) Suppose that a random variable X has expected value \\mathrm{E}[X] = 2\\theta and variance \\mathrm{Var}(X) = \\theta^2, where \\theta &gt; 0 is an unknown parameter.\nAnother random variable Y, independent of X, has \\mathrm{E}[Y] = 3\\theta and \\mathrm{Var}(Y) = 2\\theta^2.\nConsider the following three estimators of \\theta:\n\n\\hat{\\theta}_1 = X/2,\n\n\\hat{\\theta}_2 = Y/3,\n\n\\hat{\\theta}_3 = (3X + 2Y)/12.\n\nCompute the MSE of each estimator, and recommend the best one.\n\n   Solution \nWe use the rules of expectation and variance for linear functions of random variables (independence of X and Y is needed for the variance of \\hat{\\theta}_3).\n\nEstimator (i): \\hat{\\theta}_1 = X/2\n\nMean:\n\n\\mathrm{E}[\\hat{\\theta}_1] = \\frac{\\mathrm{E}[X]}{2} = \\frac{2\\theta}{2} = \\theta.\n\nVariance:\n\n\\mathrm{Var}(\\hat{\\theta}_1) = \\frac{\\mathrm{Var}(X)}{4} = \\frac{\\theta^2}{4}.\n\nSince unbiased, \\mathrm{MSE}(\\hat{\\theta}_1) = \\tfrac{\\theta^2}{4}.\n\n\nEstimator (ii): \\hat{\\theta}_2 = Y/3\n\nMean:\n\n\\mathrm{E}[\\hat{\\theta}_2] = \\frac{\\mathrm{E}[Y]}{3} = \\frac{3\\theta}{3} = \\theta.\n\nVariance:\n\n\\mathrm{Var}(\\hat{\\theta}_2) = \\frac{\\mathrm{Var}(Y)}{9} = \\frac{2\\theta^2}{9}.\n\nSince unbiased, \\mathrm{MSE}(\\hat{\\theta}_2) = \\tfrac{2\\theta^2}{9}.\n\n\nEstimator (iii): \\hat{\\theta}_3 = (3X + 2Y)/12\n\nMean:\n\n\\mathrm{E}[\\hat{\\theta}_3] = \\frac{3\\,\\mathrm{E}[X] + 2\\,\\mathrm{E}[Y]}{12}\n= \\frac{3(2\\theta) + 2(3\\theta)}{12} = \\theta.\n\nVariance (using independence):\n\n\\mathrm{Var}(\\hat{\\theta}_3)\n= \\frac{1}{144}\\Big(9\\,\\mathrm{Var}(X) + 4\\,\\mathrm{Var}(Y)\\Big)\n= \\frac{1}{144}(9\\theta^2 + 8\\theta^2)\n= \\frac{17}{144}\\theta^2.\n\nSince unbiased, \\mathrm{MSE}(\\hat{\\theta}_3) = \\tfrac{17}{144}\\theta^2.\n\n\nComparison:\n- \\mathrm{MSE}(\\hat{\\theta}_1) = 0.25\\theta^2\n- \\mathrm{MSE}(\\hat{\\theta}_2) \\approx 0.222\\theta^2\n- \\mathrm{MSE}(\\hat{\\theta}_3) \\approx 0.118\\theta^2\nThus, \\hat{\\theta}_3 has the smallest MSE and is the best choice.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Frequentist Point Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part2/4-freq-point-estimation.html#central-limit-theorem-clt",
    "href": "content/main/part2/4-freq-point-estimation.html#central-limit-theorem-clt",
    "title": "4  Frequentist Point Estimation",
    "section": "4.3 Central Limit Theorem (CLT)",
    "text": "4.3 Central Limit Theorem (CLT)\n\n\n\n\n\n\n\nTheorem 4.1 (Central Limit Theorem (CLT)) Let X_1, X_2, \\ldots be an infinite sequence of independent and identically distributed random variables with finite mean \\mu=\\mathrm{E}[X_1] and finite variance \\sigma^2=\\mathrm{Var}(X_1)&lt;\\infty.\nDefine the sample mean \n\\bar X_n \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i.\n Then, regardless of the original distribution of the X_i, \n\\frac{\\bar X_n - \\mu}{\\sigma/\\sqrt{n}} \\;\\xrightarrow{\\,d\\,}\\; \\mathcal N(0,1)\\quad\\text{as } n\\to\\infty.\n\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 4.5 (Not Examinable). We do not give a proof here. An outline is provided in separate practice exercises (not examinable).\nNote. The notation \\xrightarrow{d} means convergence in distribution: the distribution of the random variable on the left approaches the distribution on the right as n grows.\n\n\n\n\nThe CLT is remarkable: it tells us that whatever the original distribution of the data, the sample mean is approximately Normal for sufficiently large n, and the approximation improves as n increases.\nIn practice, for a reasonable sample size we may write \n\\bar X_n \\;\\overset{\\text{approx.}}{\\sim}\\; \\mathcal N\\!\\left(\\mu,\\ \\frac{\\sigma^2}{n}\\right),\n not only for Normal samples but for many non-Normal populations as well. What counts as “reasonable” depends on how skewed/heavy-tailed the original distribution is; often n&gt;20 suffices, and in many settings even smaller n will do.\nBecause \\bar X_n = \\tfrac{1}{n}\\sum_{i=1}^n X_i, the CLT also yields an approximation for sums: \n\\sum_{i=1}^n X_i \\;\\overset{\\text{approx.}}{\\sim}\\; \\mathcal N\\!\\left(n\\mu,\\ n\\sigma^2\\right).\n\n\n\n\n\n\n\nTipCommon misconceptions\n\n\n\nThe CLT does not say the data become Normal; it says the distribution of the sample mean becomes approximately Normal as n grows.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Frequentist Point Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part2/4-freq-point-estimation.html#sec-estimator-asymp-properties",
    "href": "content/main/part2/4-freq-point-estimation.html#sec-estimator-asymp-properties",
    "title": "4  Frequentist Point Estimation",
    "section": "4.4 Asymptotic Properties of Estimators",
    "text": "4.4 Asymptotic Properties of Estimators\n\n\n\n\n\n\nImportant 4.2: Terminology: Asymptotic in Statistics\n\n\n\n\n\nAn asymptotic property of an estimator is a property that emerges in the limit as the number of observations n \\to \\infty.\nIn other words, it describes the large-sample behaviour of an estimator.\n\n\n\nSo far, we have judged estimators by properties that hold for a fixed sample size n, such as bias 4.4, variance 4.5, and MSE 4.8.\nIt is also useful to consider how estimators behave when the sample size grows very large.\nThese are known as the asymptotic (large-sample) properties of estimators.\nFormally, suppose we have a random sample\n\nX_1, X_2, \\ldots, X_n \\;\\overset{\\text{iid}}{\\sim}\\; \\mathrm{Distribution}(\\theta),\n\nand a sequence of estimators of \\theta given by\n\n\\hat{\\theta}_n = g(X_1, X_2, \\ldots, X_n).\n\nWe are interested in the properties of \\hat{\\theta}_n as n \\to \\infty. Two fundamental criteria are asymptotic unbiasedness and consistency.\n\n\n\n\n\n\n\nDefinition 4.9 (Asymptotic Unbiasedness) We say that \\hat{\\theta}_n is asymptotically unbiased for \\theta if\n\n\\lim_{n \\to \\infty} \\mathrm{E}[\\hat{\\theta}_n] = \\theta.\n\n\n\n\n\nIf an estimator is unbiased for every n, then it is automatically asymptotically unbiased.\nHowever, some biased estimators may still “correct themselves” in the limit and become asymptotically unbiased.\n\n\n\n\n\n\n\nDefinition 4.10 (Consistency) A sequence of estimator \\hat{\\theta}_n is consistent for \\theta if\n\n\\hat{\\theta}_n \\;\\xrightarrow{p}\\; \\theta\n\\quad \\text{as } n \\to \\infty,\n\nthat is, it converges in probability 1.17 to the true parameter value.\n\n\n\n\nIntuitively, a consistent estimator will “home in” on the true parameter as the sample size grows.\nUsing Definition 4.10 directly to prove an estimator is consistent can be difficult. The following gives a sufficient condition that is usually easier to verify in practice.\n\n\n\n\n\n\n\nProposition 4.5 (Sufficient Condition for Consistency) An estimator \\hat{\\theta}_n of \\theta is consistent if both the following hold:\n\n\\hat{\\theta}_n is asymptotically unbiased, i.e.\n\n\\mathrm{Bias}(\\hat{\\theta}_n) \\;\\to\\; 0 \\quad \\text{as } n\\to\\infty,\n\nIts variance shrinks to zero:\n\n\\mathrm{Var}(\\hat{\\theta}_n) \\;\\to\\; 0 \\quad \\text{as } n\\to\\infty.\n\n\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 4.6 (Not Examinable). Suppose \\hat{\\theta}_n satisfies conditions (1) and (2).\nFor any \\varepsilon &gt; 0, by Chebyshev’s inequality 1.1:\n\n\\Pr\\big(|\\hat{\\theta}_n - \\mathrm{E}[\\hat{\\theta}_n]| \\geq \\varepsilon \\big)\n\\;\\leq\\; \\frac{\\mathrm{Var}(\\hat{\\theta}_n)}{\\varepsilon^2}.\n\nAs n \\to \\infty, the variance term tends to 0, so\n\n\\hat{\\theta}_n - \\mathrm{E}[\\hat{\\theta}_n] \\;\\xrightarrow{p}\\; 0.\n\nMeanwhile, \\mathrm{E}[\\hat{\\theta}_n] \\to \\theta by assumption of asymptotic unbiasedness.\nHence,\n\n\\hat{\\theta}_n \\;\\xrightarrow{p}\\; \\theta,\n\nwhich proves consistency.\n\n\n\n\n\n\n\n\n\n\n\nExample 4.6 (Consistency of the Sample Mean) Suppose X_1,\\dots,X_n are i.i.d. with mean \\mu and variance \\sigma^2 &lt; \\infty.\nShow that \\bar{X}_n is a consistent estimator of \\mu.\n\n   Solution \nRecall that \n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\n\nBias:\n\n\\mathrm{E}[\\bar{X}_n] = \\frac{1}{n}\\sum_{i=1}^n \\mathrm{E}[X_i] = \\mu.\n Thus \\bar{X}_n is unbiased for all n, hence asymptotically unbiased.\nVariance:\nSince the X_i are independent, \n\\mathrm{Var}(\\bar{X}_n) = \\frac{1}{n^2}\\sum_{i=1}^n \\mathrm{Var}(X_i)\n= \\frac{\\sigma^2}{n}.\n As n \\to \\infty, this variance tends to 0.\n\nTherefore, \\bar{X}_n is both unbiased and has variance vanishing as n grows.\nBy Proposition 4.5, it is a consistent estimator of \\mu.\n\n\n\n\n\nIn some cases, applying Proposition 4.5 is much harder to do:\n\n\n\n\n\n\n\nProposition 4.6 (Consistency of the Sample Variance) Suppose X_1,\\dots,X_n are i.i.d. with mean \\mu and variance \\sigma^2&lt;\\infty.\nThen \nS_n^2 \\;=\\; \\frac{1}{n-1}\\sum_{i=1}^n \\bigl(X_i-\\bar{X}_n\\bigr)^2\n is a consistent estimator of \\sigma^2.\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 4.7 (Not Examinable). Let’s first try to use the bias-variance approach of Proposition 4.5.\nBias. From Example 4.3, \\mathrm{Bias}(S_n^2)=0 for all n, i.e. \\mathrm{E}[S_n^2]=\\sigma^2.\nVariance. Using Proposition 4.1,\n\nS_n^2 \\;=\\; \\frac{1}{n-1}\\Big(\\sum_{i=1}^n X_i^{2}\\;-\\; n\\,\\bar X_n^{\\,2}\\Big),\n\nso\n\n\\operatorname{Var}(S_n^2)\n= \\mathrm{E}\\big[(S_n^2)^2\\big] - \\sigma^4\n= \\frac{1}{(n-1)^2}\\Big\\{ \\mathrm{E}\\big[\\big(\\textstyle\\sum X_i^2 - n\\bar X_n^{\\,2}\\big)^2\\big] \\Big\\} - \\sigma^4.\n\nExpanding the square gives\n\n\\frac{1}{(n-1)^2}\\!\\left[ \\mathrm{E}\\!\\left(\\sum_{i=1}^n X_i^{2}\\right)^2\n- 2n\\,\\mathrm{E}\\!\\left(\\bar X_n^{\\,2}\\sum_{i=1}^n X_i^{2}\\right)\n+ n^2\\,\\mathrm{E}(\\bar X_n^{\\,4}) \\right] - \\sigma^4\n\\;=\\; \\cdots\n\nThis leads to non-trivial moment algebra (4th moments and many cross-terms). If one carries it through (assuming the 4th central moment \\mu_4=\\mathrm{E}[(X-\\mu)^4] is finite), the result is\n\n\\operatorname{Var}(S_n^2)\n\\;=\\; \\frac{1}{n}\\left(\\mu_4 - \\frac{n-3}{\\,n-1\\,}\\sigma^4\\right),\n\nso in particular \\operatorname{Var}(S_n^2)\\le \\frac{1}{n}(\\mu_4+\\sigma^4)\\to 0.\n\nA Different Approach.\nUsing Proposition 4.1 in centred form,\n\nS_n^2 \\;=\\; \\frac{n}{n-1}\\left(\\frac{1}{n}\\sum_{i=1}^n (X_i-\\mu)^2\\right)\n\\;-\\; \\frac{n}{n-1}\\,(\\bar X_n-\\mu)^2.\n\nBy the Law of Large Numbers, \\frac{1}{n}\\sum_{i=1}^n (X_i-\\mu)^2 \\xrightarrow{p} \\mathrm{E}[(X-\\mu)^2]=\\sigma^2 (finite second moment suffices), and (\\bar X_n-\\mu)^2 \\xrightarrow{p} 0. Since \\frac{n}{n-1}\\to 1,\n\nS_n^2 \\xrightarrow{p} \\sigma^2.\n\nThus S_n^2 is consistent.\n\n\n\n\n\n\n\n\n\n\nTipRemark (Consistency)\n\n\n\n\n\n\nRemark 4.6 (Consistency). \n\nConsistency requires convergence in probability 1.17, not necessarily unbiasedness at every finite n.\n\nIn this course, you can always use the sufficient condition (Proposition 4.5) to prove consistency.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Frequentist Point Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html",
    "href": "content/main/part2/5-likelihood.html",
    "title": "5  Likelihood",
    "section": "",
    "text": "5.1 Likelihoods Under Independence and Dependence\nThe likelihood is simply the joint density (or probability mass function) of the observed data:\nf(\\underline{x} \\mid \\theta),\n\\quad \\underline{x} = (x_1, \\dots, x_n).\nIt plays a central role in both frequentist and Bayesian statistics.\nThe form of the likelihood depends crucially on whether our observations are independent and identically distributed (i.i.d.), merely independent, or dependent. These three cases look similar but lead to different joint densities.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html#likelihoods-under-independence-and-dependence",
    "href": "content/main/part2/5-likelihood.html#likelihoods-under-independence-and-dependence",
    "title": "5  Likelihood",
    "section": "",
    "text": "i.i.d. dataIndependent (not identical) dataDependent data\n\n\nThis is the default case in most of this course.\nSuppose X_1, \\ldots, X_n are independent and identically distributed (i.i.d.) random variables:\n\nX_i \\overset{\\text{i.i.d.}}{\\sim} \\mathrm{Distribution}(\\theta),\n\\quad i = 1, \\ldots, n.\n\nEach X_i has density (or PMF)\n\nf(x \\mid \\theta).\n\nThen the joint density of the full sample is\n\nf(x_1, \\ldots, x_n \\mid \\theta)\n= \\prod_{i=1}^n f(x_i \\mid \\theta).\n\n\n\nIf instead the samples are independent but not identically distributed:\n\nX_i \\sim \\mathrm{Distribution}_i(\\theta),\n\nwith individual densities f_{X_i}(x_i \\mid \\theta), then the joint density becomes\n\nf(x_1, \\ldots, x_n \\mid \\theta)\n= \\prod_{i=1}^n f_{X_i}(x_i \\mid \\theta).\n\n\n\nIn many real-world situations, data are dependent.\nExample: Suppose our data are daily temperatures in Newcastle upon Tyne. Yesterday’s temperature will influence today’s temperature, and today’s temperature will influence tomorrow’s.\nIn such cases, we must model the dependencies explicitly. For instance,\n\nX_{t+1} \\mid X_t = x_t  \\sim \\mathcal{N}(x_t, \\sigma^2).\n\nThe likelihood is still the joint distribution, but expressed as a product of conditional densities:\n\nf(x_1,\\ldots,x_n \\mid \\sigma^2)\n= \\prod_{t=1}^n f(x_t \\mid x_{t-1}, \\sigma^2).\n\nThe example above assumed a Markov property (each observation only depends on the previous one). In general, observations may depend on the entire history, in which case the joint density factorises via the chain rule 1.2: \nf(x_1,\\ldots,x_n \\mid \\theta) = f(x_1\\mid\\theta)\\prod_{t=2}^n f(x_t \\mid x_1,\\ldots,x_{t-1},\\theta)\n\n\n\n\n\n\n\nWarningNon-Examinable Content\n\n\n\nThis course focuses only on the i.i.d. or independent case.\nDependent data will be covered in later modules and is not examinable.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCase\nAssumption\nFactorisation of Joint Density\n\n\n\n\ni.i.d. data\nIndependent and identically distributed; each with density f(x\\mid\\theta)\nf(\\underline{x}\\mid\\theta) = \\prod_{i=1}^n f(x_i\\mid\\theta)\n\n\nIndependent (not identical) data\nIndependent; each X_i may have its own density f_{X_i}(x_i\\mid\\theta)\nf(\\underline{x}\\mid\\theta) = \\prod_{i=1}^n f_{X_i}(x_i\\mid\\theta)\n\n\nDependent data (general)\nDependent; factorise using the chain rule 1.2\nf(\\underline{x}\\mid\\theta) = f(x_1\\mid\\theta)\\prod_{t=2}^n f(x_t \\mid x_1,\\ldots,x_{t-1},\\theta)\n\n\n\n\n\n\n\n\n\nWarningReminder: Non-Examinable Content\n\n\n\nThe dependent case in the above table is shown for completeness.\nThis course focuses only on the i.i.d. or independent case, and the dependent case is not examinable.\n\n\n\n\n\n\n\n\nTipRemark (Why products?)\n\n\n\n\n\n\nRemark 5.1 (Why products?). \n\nIndependence means joint probabilities factorise: \n\\mathrm{Pr}(A \\cap B) = \\mathrm{Pr}(A) \\mathrm{Pr}(B).\n\nBy the same rule 1.8, the joint density of independent random variables is the product of their individual densities.\nThis is a common misconception: without independence, you cannot just multiply.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html#likelihood-function",
    "href": "content/main/part2/5-likelihood.html#likelihood-function",
    "title": "5  Likelihood",
    "section": "5.2 Likelihood Function",
    "text": "5.2 Likelihood Function\nSo far we have described the likelihood informally as “the joint density of the data given the parameter.”\nWe now give a formal definition of the likelihood function and introduce the notation we will use in the frequentist parts of the course.\n\n\n\n\n\n\n\nDefinition 5.1 Likelihood Function. For fixed observed data \\underline{x}, the likelihood function is defined as\n\nL(\\theta ; \\underline{x}) \\coloneqq f(\\,\\underline{x} \\mid \\theta).\n\nHere we treat \\theta as the variable, and the data \\underline{x} as fixed.\n\n\n\n\n\n5.2.1 Illustration (Likelihood with a coin)\nSuppose we toss a possibly biased coin twice, where\n\n\\Pr(\\text{Head})=\\theta,\n\\qquad\n\\Pr(\\text{Tail})=1-\\theta.\n\nLet X be the number of heads in two tosses. Then, since this is a Binomial 1.2 observation:\n\nf(x\\mid\\theta)=\\Pr(X=x\\mid\\theta)\n=\\binom{2}{x}\\theta^x(1-\\theta)^{2-x},\n\\qquad x=0,1,2.\n\nThere are two interpretations of this:\n\nProbability view (before observing data).\nFor fixed \\theta, this is a probability mass function (PMF) in x. It satisfies \n  f(x=0 \\mid \\theta) + f(x=1 \\mid \\theta) + f(x = 2 \\mid \\theta) = 1.\n   It tells us how likely different data values x are under parameter \\theta.\nLikelihood view (after observing data).\nNow suppose we observe x=2. Now, since x=2 is fixed, the same formula becomes \n  L(\\theta; x=2) = f(2\\mid\\theta) = \\theta^2.\n   This function tells us how plausible different values of \\theta are, given the observed data.\n\n\n\nShow Visualisation\n\n// Add custom CSS for the slider styling (without the details.controls-root requirement)\nhtml`&lt;style&gt;\n/* Style all range sliders in the document */\ninput[type=\"range\"] {\n  /* Reset browser defaults */\n  -webkit-appearance: none;\n  appearance: none;\n  \n  /* Layout */\n  width: 100%;\n  height: 18px;\n  background: transparent;\n  vertical-align: middle;\n  \n  /* Brand theming */\n  accent-color: var(--ctrl-brand);\n}\n\n/* Hide the number input box that appears with Inputs.range */\nform:has(input[type=\"range\"]) input[type=\"number\"] {\n  display: none !important;\n}\n\n/* Center the slider container */\nform:has(input[type=\"range\"]) {\n  margin: 0 auto;\n  max-width: 600px; /* Adjust as needed */\n  padding: 10px 0;\n}\n\n/* Slider track - WebKit */\ninput[type=\"range\"]::-webkit-slider-runnable-track {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n\n/* Slider thumb - WebKit */\ninput[type=\"range\"]::-webkit-slider-thumb {\n  -webkit-appearance: none;\n  appearance: none;\n  \n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  border: 0;\n  background: var(--ctrl-brand, #667eea);\n  \n  /* Center thumb over 4px track */\n  margin-top: -4px;\n}\n\n/* Slider track - Firefox */\ninput[type=\"range\"]::-moz-range-track {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n\n/* Slider thumb - Firefox */\ninput[type=\"range\"]::-moz-range-thumb {\n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  border: 0;\n  background: var(--ctrl-brand, #667eea);\n}\n\n/* Firefox progress styling */\ninput[type=\"range\"]::-moz-range-progress {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n&lt;/style&gt;`\n\n\n\n\n\n\n\n// Text readout: Pr(X = 2 | θ) = θ^2\nprobabilityText = {\n  const fmt = d3.format(\".3f\");\n  const val = theta ** 2;\n  return md`${tex`\\Pr(X=2 \\mid \\theta=${fmt(theta)}) = ${fmt(val)}`}`;\n}\n\n\n\n\n\n\n\n// Probability view: PMF of X ~ Binomial(n=2, θ)\npmfPlot = {\n  // Data: x ∈ {0,1,2}, P(X=x | θ) = C(2,x) θ^x (1-θ)^{2-x}\n  const pmf = [\n    {x: 0, p: (1 - theta) ** 2},\n    {x: 1, p: 2 * theta * (1 - theta)},\n    {x: 2, p: theta ** 2}\n  ];\n\n  return Plot.plot({\n    width: dynamicPlotW, height: plotH,\n    marginLeft: marginLeft,\n    marginBottom: marginBottom,\n    style: {\n        fontFamily: bodyFont, \n        fontSize: 14.,\n        background: \"var(--brand-bg)\",\n    }, \n    x: {\n      label: \"x (number of heads)\", \n      domain: [-0.5, 2.5], \n      ticks: [0, 1, 2],\n      tickFormat: d =&gt; d.toFixed(0)\n    },\n    y: {\n      label: \"Probability\", \n      domain: [0, 1],\n      grid: true\n    },\n    marks: [\n      Plot.ruleY([0]),\n      Plot.rectY(pmf, {\n        x: \"x\", \n        y: \"p\", \n        x1: d =&gt; d.x - 0.4,\n        x2: d =&gt; d.x + 0.4,\n        fill: \"var(--brand-teal)\",\n        inset: 0.5\n      }),\n      Plot.dot(pmf, {\n        x: \"x\", \n        y: \"p\", \n        r: 4, \n        fill: \"var(--fg-muted)\",\n        fillOpacity: 0.\n      }),\n      Plot.text(pmf, {\n        x: \"x\",\n        y: \"p\",\n        text: d =&gt; d3.format(\".3f\")(d.p),\n        dy: -10,\n        fontSize: 11\n      })\n    ]\n  });\n}\n\n\n\n\n\n\n\n// Likelihood view: L(θ; x=2) = θ^2 for θ ∈ [0,1]\nlikelihoodPlot = {\n  // Curve samples\n  const T = d3.range(0, 1.001, 0.005).map(t =&gt; ({theta: t, L: t ** 2}));\n  const point = {theta: theta, L: theta ** 2};\n\n  return Plot.plot({\n    width: dynamicPlotW, height: plotH,\n    marginLeft: marginLeft,\n    marginBottom: marginBottom,\n    style: {\n        fontFamily: bodyFont, \n        fontSize: 14.,\n        background: \"var(--brand-bg)\",\n    }, \n    x: {\n      label: \"θ\", \n      domain: [0, 1],\n      grid: true\n    },\n    y: {\n      label: \"Likelihood\", \n      domain: [0, 1],\n      grid: true\n    },\n    marks: [\n      Plot.line(T, {\n        x: \"theta\", \n        y: \"L\",\n        stroke: \"var(--brand-red)\",\n        strokeWidth: 2\n      }),\n      Plot.ruleY([0]),\n      Plot.ruleX([theta], {\n        stroke: \"var(--fg-muted)\",\n        strokeDasharray: \"4 2\"\n      }),\n      Plot.dot([point], {\n        x: \"theta\", \n        y: \"L\",\n        r: 5,\n        fill: \"var(--brand-red)\"\n      }),\n      Plot.text([point], {\n        x: \"theta\",\n        y: \"L\",\n        text: d =&gt; `(${d3.format(\".2f\")(d.theta)}, ${d3.format(\".3f\")(d.L)})`,\n        dy: -10,\n        fontSize: 11,\n        fill: \"var(--brand-fg)\"\n      })\n    ]\n  });\n}\n\n\n\n\n\n\n\ndynamicPlotW = Math.min(400, width * 0.45)  // Each plot takes ~45% of available width\n\n\n\n\n\n\n\n// Combined side-by-side view - responsive, with titles\nhtml`&lt;div style=\"width:100%; box-sizing:border-box;\"&gt;\n  &lt;div style=\"display:flex; gap:${gap}px; align-items:flex-start; flex-wrap:wrap; justify-content:center;\"&gt;\n    \n    &lt;div style=\"flex:0 1 ${dynamicPlotW}px; min-width:300px; text-align:center;\"&gt;\n      &lt;div style=\"margin-bottom:6px; font-weight:600; font-size:15px;\"&gt;Binomial PMF&lt;/div&gt;\n      ${pmfPlot}\n    &lt;/div&gt;\n    \n    &lt;div style=\"flex:0 1 ${dynamicPlotW}px; min-width:300px; text-align:center;\"&gt;\n      &lt;div style=\"margin-bottom:6px; font-weight:600; font-size:15px;\"&gt;Likelihood Function&lt;/div&gt;\n      ${likelihoodPlot}\n    &lt;/div&gt;\n    \n  &lt;/div&gt;\n  &lt;div style=\"margin-top:15px; text-align:center; font-size:14px;\"&gt;\n    ${probabilityText}\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n// Simple slider with tex label, no input box\nviewof theta = Inputs.range([0, 1], {\n  value: 0.5,\n  step: 0.01\n})\n\n\n\n\n\n\n\n\nInterpretation\nConsider two competing values of \\theta for observing x=2 heads in n=2 tosses:\n\nIf \\theta=0.01, the probability of observing X=2 is \n  L(0.01;2)=0.0001.\n   For such a coin, two heads would be highly unusual.\nIf \\theta=0.99, the probability of observing X=2 is \n  L(0.99;2)=0.9801 \\approx 0.98.\n   For such a coin, observing X=2 is exactly what we’d expect.\n\nGiven x=2, values of \\theta close to 1 are much more plausible than values near 0.\n\n\n\n\n\n\nTipRemark (Likelihood vs. Probability)\n\n\n\n\n\n\nRemark 5.2 (Likelihood vs. Probability). It is important to distinguish between the joint density of the data and the likelihood function:\n\nJoint density (PDF/PMF). f(\\underline{x}\\mid \\theta) is viewed as a function of the data \\underline{x}, with the parameter \\theta fixed. This describes the probability distribution of the sample under \\theta.\nLikelihood function. The same expression, written as\n\nL(\\theta;\\underline{x}) = f(\\underline{x}\\mid\\theta),\n\nis instead viewed as a function of the parameter \\theta, with the observed data \\underline{x} held fixed. This is the function we use to make inferences about \\theta.\n\n\nIn short:\n\nJoint density: given \\theta, how likely are different data values \\underline{x}?\nLikelihood: given observed \\underline{x}, how plausible are different values of \\theta?\n\n\n\n\n\n\n\n5.2.2 Computing Likelihood Functions\nThis is a very important skill in the course: you will use it often in the frequentist parts, and it is essential for the Bayesian part.\n\n\nGuide to Computing Likelihood Functions\nThe general strategy is:\n\nCheck the model carefully. Look for:\n\nAre the data i.i.d. or just independent?\nHow many data points are observed?\nWhat notation is used for the data (X_i, Y_i, Z_i, …)?\nWhat notation is used for the parameters (\\mu, \\alpha, \\gamma, \\theta, …)?\n\n(In the examples below we assume n independent data points X_1,\\dots,X_n with parameter \\theta. If there is only one data point, the likelihood is just its PDF/PMF.)\nWrite down the PDF/PMF of one observation.\n\nf_{X_i}(x_i \\mid \\theta)\n\nMultiply to form the joint density, i.e. the likelihood:\n\nL(\\theta ; \\underline{x})\n= f(\\underline{x} \\mid \\theta)\n= \\prod_{i=1}^n f_{X_i}(x_i \\mid \\theta).\n\n\n\nCommon Mistakes\nIt is very easy to slip up when multiplying terms. Watch out for:\n\nForgetting the index. Always use x_i inside the product.\nExample (Exponential model): If X_i \\sim \\mathrm{Exponential}(\\theta) with density\n\nf(x_i \\mid \\theta) = \\theta e^{-\\theta x_i}, \\quad x_i &gt; 0,\n\nthen the likelihood is\n\nf(\\underline{x} \\mid \\theta)\n= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\n= \\theta^n \\exp\\!\\left(-\\theta \\sum_{i=1}^n x_i\\right).\n\nA common mistake is to write\n\n\\prod_{i=1}^n \\theta e^{-\\theta x} = \\theta^n e^{-\\theta n x} \\quad \\text{(wrong!)}\n\nwhich ignores the index on x_i.\nOversimplifying. Many likelihoods look messy — that is normal!\nExample (Gamma model): If X_i \\sim \\mathrm{Gamma}(\\alpha, \\theta) with density\n\nf(x_i \\mid \\alpha, \\theta)\n= \\frac{1}{\\Gamma(\\alpha)\\theta^\\alpha}\\, x_i^{\\alpha - 1} e^{-x_i/\\theta},\n\\quad x_i &gt; 0,\n\nthen the likelihood is\n\nf(\\underline{x} \\mid \\alpha, \\theta)\n= \\left(\\frac{1}{\\Gamma(\\alpha)\\theta^\\alpha}\\right)^n\n  \\left(\\prod_{i=1}^n x_i^{\\alpha - 1}\\right)\n  \\exp\\!\\left(-\\frac{1}{\\theta}\\sum_{i=1}^n x_i\\right).\n\nNotice how the product\n\n\\prod_{i=1}^n x_i^{\\alpha - 1}\n\ncannot be simplified further (unless you introduce the geometric mean1).\n\n\n\nA Safe Strategy\nWhen starting out, it is helpful to expand the product term by term:\n\nf(\\underline{x} \\mid \\theta)\n= f(x_1 \\mid \\theta)\n\\times f(x_2 \\mid \\theta)\n\\times \\cdots\n\\times f(x_n \\mid \\theta).\n\nThen simplify step by step.\nThis is slower, but it reduces errors. With practice, you’ll be able to simplify likelihoods much more quickly.\n\n\n\n\n\n\n\n\n\nExample 5.1 (Bernoulli Likelihood) Suppose we have n i.i.d. data distributed according to the Bernoulli distribution 1.1:\n\n  Y_i \\sim \\textrm{Bernoulli}(p).\n Derive the likelihood function.\n\n   Solution \nBecause the Y_i are i.i.d., the joint PMF factorises:\n\nL(p;\\underline{y}) = f(\\underline{y}\\mid p) = \\prod_{i=1}^n f(y_i \\mid p).\n\nFor the Bernoulli distribution,\n\nf(y_i \\mid p) = p^{y_i}(1-p)^{1-y_i}.\n\nHence,\n\\begin{align*}\nL(p; \\underline{y}) &= \\prod_{i=1}^n p^{y_i}(1 - p)^{1-y_i} \\\\\n&= p^{y_1} (1-p)^{1-y_1} \\times p^{y_2} (1-p)^{1-y_2} \\times \\ldots \\times p^{y_n} (1-p)^{1-y_n} \\\\\n&= p^{y_1 + \\ldots + y_n} (1 - p)^{(1-y_1) + \\ldots + (1-y_n)} \\\\\n&= p^{\\sum_{i=1}^n y_i} (1-p)^{\\sum_{i=1}^n 1 - y_i}.\n\\end{align*}\nWriting \\sum_{i=1}^n y_i = n\\bar{y} gives\n\nL(p;\\underline{y}) = p^{n\\bar{y}}(1-p)^{n(1-\\bar{y})}.\n\n\n\n\n\n\nIn practice, and in assessed questions in this course, it is important to be comfortable with computing likelihood functions for actual observed data. The next example does this:\n\n\n\n\n\n\n\nExample 5.2 (Bernoulli Likelihood with Data) Suppose n=5 i.i.d. observations X_i \\sim \\mathrm{Bernoulli}(p) are observed as \n\\underline{x} = (1,0,1,1,0).\n Derive the likelihood function and evaluate it for a few values of p.\n\n   Solution \nSince \\underline{x}  = (1,0,1,1,0), we have \\sum_i x_i = 3. Therefore: \nL(p ; \\underline{x}) = p^3 (1-p)^2.\n\n\nIf p=0.5, L(0.5) = 0.5^3 \\cdot 0.5^2 = 0.03125.\nIf p=0.7, L(0.7) = 0.7^3 \\cdot 0.3^2 \\approx 0.0309.\nIf p=0.8, L(0.8) = 0.8^3 \\cdot 0.2^2 = 0.0205.\n\nSo the data are slightly more likely under p=0.5 than p=0.8.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.3 (Normal Likelihood) Suppose we have n i.i.d. data distributed according to the Normal distribution 2.5:\n\n  T_i \\sim \\mathcal{N}(\\mu, \\gamma).\n\nDerive the likelihood function.\n\n   Solution \nBecause the T_i are i.i.d., the joint PDF factorises:\n\nL(\\mu, \\gamma ;\\underline{t}) = f(\\underline{t}\\mid \\mu, \\gamma) = \\prod_{i=1}^n f(t_i \\mid \\mu, \\gamma).\n\nFor the Normal distribution (with variance \\gamma = \\sigma^2),\n\nf(t_i \\mid \\mu, \\gamma) = \\frac{1}{\\sqrt{2\\pi \\gamma}} \\exp\\left\\{ -\\frac{1}{2\\gamma} (t_i - \\mu)^2 \\right\\}.\n\nHence,\n\\begin{align*}\nL(\\mu, \\gamma ;\\underline{t}) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\gamma}} \\exp\\left\\{ -\\frac{1}{2\\gamma} (t_i - \\mu)^2 \\right\\} \\\\\n&= (2\\pi \\gamma)^{-\\tfrac{n}{2}} \\exp\\left\\{ \\sum_{i=1}^n -\\frac{1}{2\\gamma} (t_i - \\mu)^2 \\right\\}.\n\\end{align*}\nTherefore,\n\nL(\\mu, \\gamma ;\\underline{t}) = (2\\pi \\gamma)^{-\\tfrac{n}{2}} \\exp\\left\\{ -\\frac{1}{2\\gamma} \\sum_{i=1}^n  (t_i - \\mu)^2 \\right\\}.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.4 (Poisson Likelihood) Suppose we have n i.i.d. data distributed according to the Poisson distribution 1.4:\n\n  V_i \\sim \\mathrm{Poisson}(\\alpha)\n\nDerive the likelihood function.\n\n   Solution \nBecause the V_i are i.i.d., the joint PMF factorises:\n\nL(\\alpha ;\\underline{v}) = f(\\underline{v}\\mid \\alpha) = \\prod_{i=1}^n f(v_i \\mid \\alpha).\n\nFor the Poisson distribution\n\nf(v_i \\mid \\alpha) = \\frac{\\alpha^{v_i} e^{-\\alpha}}{v_i!}\n\nHence,\n\\begin{align*}\nL(\\alpha ;\\underline{v}) &= \\prod_{i=1}^n  \\frac{\\alpha^{v_i} e^{-\\alpha}}{v_i!} \\\\\n&= \\alpha^{n\\bar{v}} e^{-n\\alpha} \\prod_{i=1}^n \\frac{1}{v_i!}\n\\end{align*}\nTherefore,\n\nL(\\alpha ;\\underline{v}) = \\alpha^{n\\bar{v}} e^{-n\\alpha} \\prod_{i=1}^n \\frac{1}{v_i!}.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html#maximum-likelihood-estimation",
    "href": "content/main/part2/5-likelihood.html#maximum-likelihood-estimation",
    "title": "5  Likelihood",
    "section": "5.3 Maximum Likelihood Estimation",
    "text": "5.3 Maximum Likelihood Estimation\n\n\n\n\n\n\n\nDefinition 5.3 (Maximum Likelihood Estimator (MLE)) The maximum likelihood estimator (MLE) is the parameter value that makes the observed data most likely:\n\n\\hat{\\theta}_{\\text{MLE}} = \\argmax_{\\theta \\in \\Theta} \\, L(\\theta ; \\underline{X}),\n\nwhere L(\\theta ; \\underline{X}) is the likelihood function.\n\n\n\n\n\n\n\n\n\n\nImportant 5.2: Terminology: \\argmax vs. \\max\n\n\n\n\n\nThe \\max gives the largest value attained by a function. \n\\max_{\\theta \\in \\Theta} L(\\theta ; \\underline{X})\n means “the maximum likelihood value.”\nThe \\argmax gives the argument (input) where the maximum occurs. \n\\argmax_{\\theta \\in \\Theta} L(\\theta ; \\underline{X})\n means “the parameter value that maximises the likelihood.”\nSo: \\max is the height, \\argmax is the location.\n\n   Show Visualisation \n\nL = θ =&gt; Math.exp(-(θ**4 - θ**2 + 0.3*θ))\n\n// Sample the function on a grid\nθmin = -2.2\nθmax =  2.2\nN = 801\nΘ = Array.from({length: N}, (_, i) =&gt; θmin + i*(θmax - θmin)/(N - 1))\nY = Θ.map(L)\n\n// Find max (height) and argmax (location)\nimax = Y.reduce((best, y, i) =&gt; (y &gt; Y[best] ? i : best), 0)\nθhat = Θ[imax]\nLmax = Y[imax]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Create the base plot without LaTeX labels\nargmaxPlot = Plot.plot({\n  width: Math.min(720, Math.max(380, width - 40)),\n  height: 340,\n  style: {\n    background: \"var(--brand-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont,\n    fontSize: 14\n  },\n  marginLeft: 65,\n  marginBottom: 50,\n  marginTop: 20,\n  marginRight: 20,\n  x: {label: \"\", domain: [θmin, θmax]},  \n  y: {label: \"\", nice: true},       \n  marks: [\n    // Likelihood curve\n    Plot.line(\n      Θ.map((t,i) =&gt; ({θ: t, L: Y[i]})), \n      {x: \"θ\", y: \"L\", stroke: \"var(--brand-red)\", strokeWidth: 2}\n    ),\n    \n    // Vertical line at argmax (location)\n    Plot.ruleX([θhat], {strokeDasharray: \"4,3\", stroke: \"var(--brand-fg)\", ariaLabel: \"argmax\", strokeOpacity: 0.8}),\n    \n    // Horizontal line at max (height)\n    Plot.ruleY([Lmax], {strokeDasharray: \"4,3\", stroke: \"var(--brand-fg)\", ariaLabel: \"max\", strokeOpacity: 0.8}),\n\n    // Axes at baseline\n    Plot.ruleX([θmin], {stroke: \"var(--brand-fg)\"}),\n    Plot.ruleY([0], {stroke: \"var(--brand-fg)\"}),\n\n    // Point at the maximiser\n    Plot.dot(\n      [{θ: θhat, L: Lmax}], \n      {x: \"θ\", y: \"L\", r: 5, fill: \"var(--brand-teal)\"}\n    )\n  ]\n})\n\n\n\n\n\n\n\n// Add LaTeX overlays after plot renders\nplotWithLatex = {\n  // Create container\n  const container = html`&lt;div style=\"position: relative; display: inline-block;\"&gt;&lt;/div&gt;`;\n  \n  // Add the plot\n  container.append(argmaxPlot);\n  \n  // Function to add labels after render\n  const addLabels = () =&gt; {\n    // Get the SVG element\n    const svg = container.querySelector(\"svg\");\n    if (!svg) {\n      requestAnimationFrame(addLabels);\n      return;\n    }\n    \n    // Get dimensions from the SVG\n    const svgRect = svg.getBoundingClientRect();\n    const plotWidth = svgRect.width;\n    const plotHeight = svgRect.height;\n    \n    // Approximate margins from plot config\n    const marginLeft = 74;\n    const marginBottom = 30;\n    const marginTop = 30;\n    const marginRight = 20;\n    \n    // Calculate plot area dimensions\n    const plotAreaWidth = plotWidth - marginLeft - marginRight;\n    const plotAreaHeight = plotHeight - marginTop - marginBottom;\n    \n    // Linear mapping functions for data to pixel coordinates\n    const xToPixel = (x) =&gt; marginLeft + ((x - θmin) / (θmax - θmin)) * plotAreaWidth;\n    const yToPixel = (y) =&gt; marginTop + (1 - (y / (Math.max(...Y) * 1.05))) * plotAreaHeight;\n    \n    // Calculate positions\n    const θhatPixel = xToPixel(θhat);\n    const LmaxPixel = yToPixel(Lmax);\n    \n    // Create and add LaTeX labels with boxes\n    const labels = [\n      // X-axis label\n      {\n        element: tex`\\theta`,\n        style: `\n          position: absolute;\n          bottom: 8px;\n          left: ${plotWidth / 2}px;\n          transform: translateX(-50%);\n          pointer-events: none;\n        `\n      },\n      // Y-axis label  \n      {\n        element: tex`L(\\theta;\\,\\underline{x})`,\n        style: `\n          position: absolute;\n          left: 8px;\n          top: ${(plotHeight - marginBottom) / 2}px;\n          transform: rotate(-90deg) translateY(5px);\n          transform-origin: left center;\n          pointer-events: none;\n        `\n      },\n      // Argmax label at bottom - positioned on x-axis\n      {\n        element: tex`\\arg\\max\\, L(\\theta;\\,\\underline{x})`,\n        style: `\n          position: absolute;\n          top: ${plotHeight - marginBottom}px;\n          left: ${θhatPixel}px;\n          transform: translate(-50%, -50%);\n          font-size: 13px;\n          pointer-events: none;\n          color: var(--brand-fg);\n          background: var(--plot-panel-bg, white);\n          padding: 3px 6px;\n          border: 1px solid var(--border, #ddd);\n          border-radius: 4px;\n          box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n        `\n      },\n      // Max value label on left - positioned on y-axis\n      {\n        element: tex`\\max\\, L(\\theta;\\,\\underline{x})`,\n        style: `\n          position: absolute;\n          top: ${LmaxPixel}px;\n          left: ${marginLeft}px;\n          transform: translate(-50%, -50%);\n          font-size: 13px;\n          pointer-events: none;\n          color: var(--brand-fg);\n          background: var(--plot-panel-bg, white);\n          padding: 3px 6px;\n          border: 1px solid var(--border, #ddd);\n          border-radius: 4px;\n          box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n        `\n      }\n    ];\n    \n    // Add each label to the container\n    labels.forEach(({element, style}) =&gt; {\n      const div = html`&lt;div style=\"${style}\"&gt;&lt;/div&gt;`;\n      div.append(element);\n      container.append(div);\n    });\n    \n    // Hide the original axis labels\n    // X-axis label\n    const xAxisLabel = svg.querySelector('g[aria-label=\"x-axis label\"]');\n    if (xAxisLabel) xAxisLabel.style.display = \"none\";\n    \n    // Y-axis label\n    const yAxisLabel = svg.querySelector('g[aria-label=\"y-axis label\"]');\n    if (yAxisLabel) yAxisLabel.style.display = \"none\";\n    \n    // Alternative: hide any text elements that contain θ or L(θ\n    svg.querySelectorAll('text').forEach(text =&gt; {\n      if (text.textContent === 'θ' || text.textContent.includes('L(θ')) {\n        text.style.display = 'none';\n      }\n    });\n  };\n  \n  // Schedule label addition\n  requestAnimationFrame(addLabels);\n  \n  return container;\n}\n\n\n\n\n\n\n\n\nFigure 5.1: Illustration of the difference between \\argmax and \\max. The red curve shows a likelihood function L(\\theta;\\underline{x}). The vertical dashed line marks the \\argmax (the parameter value \\hat\\theta where the maximum occurs), while the horizontal dashed line marks the \\max (the maximum likelihood value itself).\n\n\n\n\n\n\n\n\nBecause the logarithm is a monotonically increasing function, the value of \\theta that maximises the likelihood will also maximise the log-likelihood.\nIn practice, we almost always work with the log-likelihood because it is simpler to handle mathematically: it turns products into sums, and derivatives are easier to compute.\n\n\n\n\n\n\n\nDefinition 5.4 (Log-Likelihood) The log-likelihood is defined as\n\n\\ell(\\theta ; \\underline{x}) = \\log L(\\theta ; \\underline{x}).\n\n\nThis is literally just the logarithm of the likelihood.\n\nBecause \\log is increasing, maximising \\ell(\\theta;\\underline{x}) gives the same \\hat{\\theta} as maximising L(\\theta;\\underline{x}).\n\n\n\n\n\n\n\n   Show Visualisation \n\nhtml`&lt;style&gt;\n.plot--large-axis .x-axis .label,\n.plot--large-axis .y-axis .label {\nfont-size: 24px; font-weight: 600;\n}\n.plot--large-axis .x-axis text,\n.plot--large-axis .y-axis text {\nfont-size: 12px; /* tick labels (optional) */\n}\n&lt;/style&gt;`\n\n\n\n\n\n\n\nX = {\n  // Trigger on: resim button, n, trueMu, or trueSigma changes\n  resim; n; trueMu; trueSigma;\n  \n  const m = trueMu, s = trueSigma;\n  const out = new Array(n);\n  for (let i = 0; i &lt; n; i += 2) {\n    const u = Math.random(), v = Math.random();\n    const R = Math.sqrt(-2 * Math.log(u)), T = 2 * Math.PI * v;\n    const z0 = R * Math.cos(T), z1 = R * Math.sin(T);\n    out[i] = m + s * z0;\n    if (i + 1 &lt; n) out[i + 1] = m + s * z1;\n  }\n  return out;\n};\n\nxbar = d3.mean(X);\nS = d3.sum(X, x =&gt; (x - xbar) ** 2);\n\nlogLik = (mu, sigma2) =&gt; {\n  const ss = d3.sum(X, x =&gt; (x - mu) ** 2);\n  return -0.5 * n * Math.log(2 * Math.PI * sigma2) - 0.5 * ss / sigma2;\n};\n\nmuhat = xbar;\nsigma2hat = S / n;\n\n// --- Grid for contours (axes ticks) ---\n// These only need to update when display parameters change\nmuGrid = d3.ticks(muhat - muHalfWidth, muhat + muHalfWidth, gridN)\nsig2Grid = d3.ticks(Math.max(0.05, sigma2hat / 20), sig2Max, gridN).filter(s =&gt; s &gt; 0)\n\n// --- Build a row-major grid for Plot.raster / Plot.contour ---\nnx = muGrid.length\nny = sig2Grid.length\n\n// Memoize the expensive log-likelihood computation\nllValues = {\n  const z = new Float64Array(nx * ny);\n  for (let j = 0; j &lt; ny; ++j) {\n    for (let i = 0; i &lt; nx; ++i) {\n      const s2 = Math.max(1e-6, sig2Grid[j]);\n      z[j * nx + i] = logLik(muGrid[i], s2);\n    }\n  }\n  return z;\n}\n\n\n// ---- Geometry / domains (responsive) ----\n\nmuDomain = [muGrid[0], muGrid[muGrid.length - 1]]\nsig2Domain = [sig2Grid[0], sig2Grid[sig2Grid.length - 1]]\n\n// ---- Colour scaling (robust & reactive) ----\nllMax = d3.max(llValues)\nllRel = Float64Array.from(llValues, v =&gt; v - llMax)\n\n// Use more efficient quantile computation\nllRelFinite = Array.from(llRel).filter(Number.isFinite)\nllRelSorted = llRelFinite.slice().sort(d3.ascending)\nq05 = d3.quantileSorted(llRelSorted, 0.05) ?? d3.min(llRelFinite)\n\ncolorDomain = [q05, 0]\nllRelClipped = Float64Array.from(llRel, v =&gt; Math.max(q05, v))\ncontourThresholds = d3.ticks(q05, 0, 10)\n\n// ---- Left panel: raster (clipped) + contour (same grid) ----\nviewof leftPanel = {\n  const wrap = html`&lt;div style=\"\n    position: relative;\n    width: ${plotW}px;\n    height: ${plotH}px;\n    flex: 0 0 ${plotW}px;\n    line-height: 0;\n  \"&gt;&lt;/div&gt;`;\n\n  const base = Plot.plot({\n    width: plotW, height: plotH,\n    marginLeft, marginRight, marginTop, marginBottom,\n    style: {\n      background: \"var(--brand-bg)\",\n      color: \"var(--brand-fg)\",\n      fontFamily: bodyFont, \n      fontSize: 14\n    },\n    x: { label: \"μ\", domain: muDomain },\n    y: { label: \"σ²\", domain: sig2Domain },\n    color: {\n      type: \"symlog\",\n      domain: colorDomain,\n      clamp: true,\n      scheme: \"turbo\",\n      legend: false\n    },\n    marks: [\n      Plot.raster(llRelClipped, {\n        width: nx, height: ny,\n        x1: muDomain[0], x2: muDomain[1],\n        y1: sig2Domain[0], y2: sig2Domain[1],\n        interpolate: \"nearest\"\n      }),\n      Plot.dot([{ mu: muhat, sig2: sigma2hat }], {\n        x: \"mu\", y: \"sig2\", r: 5, stroke: \"currentColor\", fill: \"var(--brand-bg)\"\n      })\n    ]\n  });\n\n  base.classList.add(\"plot--large-axis\");\n  base.style.display = \"block\";\n  wrap.append(base);\n\n\n  // Crosshair overlay fills wrapper\n  const svg = d3.create(\"svg\")\n    .attr(\"width\", plotW).attr(\"height\", plotH)\n    .style(\"position\", \"absolute\").style(\"left\", \"0\").style(\"top\", \"0\")\n    .style(\"width\", \"100%\").style(\"height\", \"100%\")\n    .style(\"pointer-events\", \"none\");\n\n\n\n  const xScale = d3.scaleLinear().domain(muDomain).range([marginLeft, marginLeft + innerW]);\n  const yScale = d3.scaleLinear().domain(sig2Domain).range([marginTop + innerH, marginTop]);\n\n  const vline = svg.append(\"line\")\n  .attr(\"x1\", xScale(muhat)).attr(\"x2\", xScale(muhat))\n  .attr(\"y1\", marginTop).attr(\"y2\", marginTop + innerH)\n  .attr(\"stroke\", \"currentColor\");\n\n  const hline = svg.append(\"line\")\n  .attr(\"x1\", marginLeft).attr(\"x2\", marginLeft + innerW)\n  .attr(\"y1\", yScale(sigma2hat)).attr(\"y2\", yScale(sigma2hat))\n  .attr(\"stroke\", \"currentColor\");\n\n  wrap.append(svg.node());\n\n  // Hitbox fills wrapper; subtract margins in code\n  const hit = html`&lt;div style=\"\n    position:absolute; left:0; top:0; width:100%; height:100%;\n    cursor:crosshair; background:transparent; touch-action:none;\n  \"&gt;&lt;/div&gt;`;\n  wrap.append(hit);\n\n  const state = { x: muhat, y: sigma2hat, dragging: false };\n  wrap.value = { ...state };            // &lt;-- expose full state via the view's value\n\n  function emit() {\n    wrap.value = { ...state };          // &lt;-- assign a fresh object so equality changes\n    wrap.dispatchEvent(new CustomEvent(\"input\", { bubbles: true }));\n  }\n\n  function setFromEvent(evt) {\n    const r = hit.getBoundingClientRect();\n    let px = evt.clientX - r.left, py = evt.clientY - r.top;\n    px = Math.min(Math.max(0, px - marginLeft), innerW);\n    py = Math.min(Math.max(0, py - marginTop), innerH);\n    state.x = muDomain[0] + (px / innerW) * (muDomain[1] - muDomain[0]);\n    state.y = sig2Domain[1] - (py / innerH) * (sig2Domain[1] - sig2Domain[0]);\n    vline.attr(\"x1\", xScale(state.x)).attr(\"x2\", xScale(state.x));\n    hline.attr(\"y1\", yScale(state.y)).attr(\"y2\", yScale(state.y));\n    emit();                              // &lt;-- notify dependents\n  }\n\n  // RAF throttle for move\n  let raf = 0;\n  function scheduleUpdate(e) {\n    if (raf) return;\n    raf = requestAnimationFrame(() =&gt; { raf = 0; setFromEvent(e); });\n  }\n\n  function setDragging(on) {\n    if (state.dragging === on) return;\n    state.dragging = on;\n    emit();                              // &lt;-- notify on drag state changes too\n  }\n\n  hit.addEventListener(\"pointerdown\", (e) =&gt; {\n    setDragging(true);\n    setFromEvent(e);\n    hit.setPointerCapture(e.pointerId);\n  });\n\n  hit.addEventListener(\"pointermove\", (e) =&gt; {\n    if (state.dragging) scheduleUpdate(e);\n  });\n\n  const endDrag = () =&gt; setDragging(false);\n  hit.addEventListener(\"pointerup\", endDrag);\n  hit.addEventListener(\"pointercancel\", endDrag);\n  hit.addEventListener(\"pointerleave\", endDrag);\n\n  // initial notify\n  queueMicrotask(emit);\n\n  return wrap;                           // &lt;-- the view element\n}\n\n// leftPanel is now { x, y, dragging }\nisDragging = leftPanel.dragging\nnumPts     = isDragging ? 100 : 200\npdfStroke  = isDragging ? 1   : 2\n\n// if you want the probe to follow the crosshair:\nprobeMu   = leftPanel.x\nprobeSig2 = leftPanel.y\nprobeLL = logLik(probeMu, probeSig2);\n\n\n// --- Right panel ---\nnormalPdf = (x, mu, sig2) =&gt; (1 / Math.sqrt(2 * Math.PI * sig2)) * Math.exp(-((x - mu) ** 2) / (2 * sig2))\n\nxExtent = d3.extent(X)\nxPad = 3 * Math.sqrt(probeSig2)\nxMin = Math.min(xExtent[0], probeMu - xPad)\nxMax = Math.max(xExtent[1], probeMu + xPad)\n\n// PDF curve\nxs = d3.range(numPts).map(i =&gt; xMin + (i / (numPts - 1)) * (xMax - xMin))\npdfYs = xs.map(x =&gt; normalPdf(x, probeMu, probeSig2))\n\n// Density reducer\ndensityReducer = (values, extent) =&gt; values.length / n / (extent.x2 - extent.x1)\n\n// Compute yMax\nbins_ = d3.bin().domain([xMin, xMax]).thresholds(bins)(X);\ndensities = bins_.map(b =&gt;\n  (b.length / Math.max(1, n)) / Math.max(1e-9, (b.x1 - b.x0))\n);\nyMax = d3.max(densities);\n\nrightPanel = Plot.plot({\n  width: plotW, height: plotH,\n  marginLeft, marginBottom,\n  x: { label: \"Data\", domain: [xMin, xMax] },\n  y: { label: \"Density\" },\n  style: {\n      fontFamily: bodyFont, \n      fontSize: 14.\n  }, \n  marks: [\n    Plot.rectY(\n      X,\n      Plot.binX(\n        { y: densityReducer },\n        {\n          x: d =&gt; d,\n          thresholds: bins,\n          inset: 0,\n          fill: \"var(--brand-red)\",\n          fillOpacity: 0.2\n        }\n      )\n    ),\n    Plot.line(xs.map((x, i) =&gt; ({ x, y: pdfYs[i] })), {\n      x: \"x\", y: \"y\",\n      stroke: \"var(--brand-red)\",\n      strokeWidth: pdfStroke\n    }),\n    Plot.ruleX(X, {\n      y1: 0,\n      y2: yMax * 0.05,\n      stroke: \"var(--brand-red)\",\n      strokeWidth: 2,\n      strokeOpacity: 0.8\n    }),\n    Plot.ruleY([0]),\n    Plot.ruleX([probeMu], { stroke: \"currentColor\", strokeDasharray: \"4,3\" })\n  ]\n})\n\nprobeInfo = md`**Probe:** ${tex`\\mu=${probeMu.toFixed(2)},\\ \\sigma^2=${probeSig2.toFixed(3)}\\ \\Rightarrow\\ \\log f(\\underline{x} \\mid \\mu, \\sigma^2)=${probeLL.toFixed(2)}`}`\n\nhtml`&lt;div style=\"max-width:100%;\"&gt;\n&lt;div style=\"display:flex; gap:${gap}px; align-items:flex-start; flex-wrap:nowrap; overflow-x:auto;\"&gt;\n&lt;div style=\"flex:0 0 ${plotW}px;\"&gt;${viewof leftPanel}&lt;/div&gt;\n&lt;div style=\"flex:0 0 ${plotW}px;\"&gt;${rightPanel}&lt;/div&gt;\n&lt;/div&gt;\n&lt;div style=\"margin-top:10px; margin-bottom:-10px\"&gt;${probeInfo}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;style&gt;\n  /* ---------- Scope all styles to this controls box ---------- */\n  details.controls-root { \n    --ctrl-font: 12px;\n    font-size: var(--ctrl-font);\n  }\n\n  /* Dropdown header */\n  details.controls-root &gt; summary {\n    list-style: none; cursor: pointer; user-select: none;\n    background: var(--surface, #f1f5f9);\n    border: 1px solid var(--border, #e5e7eb);\n    border-radius: 10px;\n    padding: 8px 10px;\n    font-weight: 600; font-size: calc(var(--ctrl-font) + 1px);\n    color: var(--fg-strong, #334155);\n    display: flex; align-items: center; gap: 8px;\n  }\n  details.controls-root &gt; summary::-webkit-details-marker { display: none; }\n  details.controls-root[open] &gt; summary { border-bottom-left-radius: 0; border-bottom-right-radius: 0; }\n\n  /* Two-column grid (side-by-side) */\n  details.controls-root .controls-grid {\n    display: grid;\n    grid-template-columns: minmax(260px, 1fr) minmax(260px, 1fr);\n    gap: 12px;\n    border: 1px solid var(--border, #e5e7eb); border-top: none;\n    border-bottom-left-radius: 10px; border-bottom-right-radius: 10px;\n    padding: 10px;\n    background: var(--surface-weak, #fafafa);\n    overflow-x: auto;\n  }\n  details.controls-root .controls-col { min-width: 260px; }\n  details.controls-root .controls-col h4 {\n    margin: 0 0 6px 0;\n    font-size: var(--ctrl-font); font-weight: 700;\n    color: var(--fg-muted, #475569);\n  }\n\n  /* ---- Align label & slider (form-level grid) ---- */\n  details.controls-root .controls-col form {\n    display: grid !important;\n    grid-template-columns: minmax(150px, auto) 1fr; /* label | inputs */\n    align-items: center;         /* vertical centring */\n    column-gap: 10px;\n    font-size: var(--ctrl-font) !important;\n    line-height: 1.25;\n    margin: 6px 0;\n  }\n\n  /* Label: kill default &lt;p&gt; margin; align KaTeX + text */\n  details.controls-root .controls-col form &gt; label {\n    margin: 0 !important;\n    display: flex; align-items: center; gap: 8px;\n    font-size: var(--ctrl-font) !important;\n    color: var(--fg-muted, #475569);\n    font-weight: 600;\n  }\n  details.controls-root .controls-col form &gt; label p { margin: 0 !important; }\n\n  /* Inputs wrapper (auto-generated, e.g. .oi-*-input): align number + slider */\n  details.controls-root .controls-col form &gt; [class$=\"-input\"],\n  details.controls-root .controls-col form &gt; [class*=\"-input\"] {\n    display: flex; align-items: center; gap: 8px;\n    min-height: 22px;\n  }\n\n  /* Number input normalisation */\n  details.controls-root .controls-col input[type=\"number\"] {\n    height: 24px; padding: 2px 6px;\n    font-size: var(--ctrl-font);\n    border: 1px solid var(--border, #e5e7eb); border-radius: 6px;\n    background: var(--surface, #f1f5f9); color: var(--fg-strong, #334155);\n  }\n\n  /* Slider styling */\n  details.controls-root .controls-col input[type=\"range\"] {\n    -webkit-appearance: none; appearance: none;\n    width: 100%; height: 18px; background: transparent;\n    vertical-align: middle;\n    accent-color: var(--brand-teal, #55C3CB);\n  }\n  details.controls-root .controls-col input[type=\"range\"]::-webkit-slider-runnable-track {\n    height: 4px; border-radius: 999px;\n    background: color-mix(in srgb, var(--brand-teal, #55C3CB) 35%, transparent);\n  }\n  details.controls-root .controls-col input[type=\"range\"]::-webkit-slider-thumb {\n    -webkit-appearance: none; appearance: none;\n    width: 12px; height: 12px; border-radius: 50%;\n    background: var(--brand-teal, #55C3CB); border: 0; margin-top: -4px; /* centre thumb over 4px track */\n  }\n  details.controls-root .controls-col input[type=\"range\"]::-moz-range-track {\n    height: 4px; border-radius: 999px;\n    background: color-mix(in srgb, var(--brand-teal, #55C3CB) 35%, transparent);\n  }\n  details.controls-root .controls-col input[type=\"range\"]::-moz-range-thumb {\n    width: 12px; height: 12px; border-radius: 50%;\n    background: var(--brand-teal, #55C3CB); border: 0;\n  }\n\n  /* Button */\n  details.controls-root .btn-resim button {\n    background: var(--brand-teal, #55C3CB); color: #fff;\n    border: none; border-radius: 6px; padding: 6px 12px;\n    font-weight: 600; font-size: var(--ctrl-font); cursor: pointer;\n    transition: filter 120ms ease, background-color 120ms ease;\n  }\n  details.controls-root .btn-resim button:hover {\n    background: color-mix(in srgb, var(--brand-teal, #55C3CB) 88%, black);\n  }\n\n  /* Chevron */\n  details.controls-root &gt; summary::before {\n    content: \"\"; display: inline-block; margin-right: 8px; width: 0; height: 0;\n    border-style: solid; border-width: 3px 0 3px 6px;\n    border-color: transparent transparent transparent var(--fg-strong);\n    transform: rotate(0deg); transform-origin: 3px 50%; transition: transform 50ms ease;\n  }\n  details.controls-root[open] &gt; summary::before { transform: rotate(90deg); }\n`\n\n\n\n\n\n\n\nviewof controls = {\n  const resimBtn = Inputs.button(\"Resimulate data\");\n  resimBtn.classList.add(\"btn-resim\");\n\n  const leftForm = Inputs.form({\n    n: Inputs.range([1, 400], { value: 10, step: 1, label: md`${tex`n`}` }),\n    trueMu: Inputs.range([-3, 3], { value: 0.5, step: 0.05, label: md`${tex`\\mu_{\\text{true}}`}` }),\n    trueSigma: Inputs.range([0.3, 3], { value: 1.2, step: 0.05, label: md`${tex`\\sigma_{\\text{true}}`}` })\n  }, { submit: false });\n\n  const rightForm = Inputs.form({\n    muHalfWidth: Inputs.range([1, 5], { value: 2.5, step: 0.05, label: md`${tex`\\mu\\text{-range}`}` }),\n    sig2Max: Inputs.range([0.2, 6], { value: 3, step: 0.05, label: md`${tex`\\sigma^2\\text{ max}`}` }),\n    gridN: Inputs.range([25, 121], { value: 81, step: 4, label: \"Grid size\" }),\n    bins: Inputs.range([10, 60], { value: 24, step: 1, label: \"Histogram bins\" })\n  }, { submit: false });\n\n  const root = html`&lt;details class=\"controls-root\" open&gt;\n    &lt;summary&gt;Simulation controls&lt;/summary&gt;\n    &lt;div class=\"controls-grid\"&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Data & truth&lt;/h4&gt;&lt;/div&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Grid & display&lt;/h4&gt;&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/details&gt;`;\n\n  const grid = root.querySelector(\".controls-grid\");\n  const leftCol = grid.children[0];\n  const rightCol = grid.children[1];\n\n  leftCol.append(leftForm);\n\n  rightCol.append(rightForm);\n  const btnWrap = html`&lt;div style=\"display:flex; justify-content:flex-start; margin-top:6px;\"&gt;&lt;/div&gt;`;\n  btnWrap.append(resimBtn);\n  rightCol.append(btnWrap);\n\n  // --- Merge values\n  const getValue = () =&gt; ({ ...leftForm.value, ...rightForm.value, resim: resimBtn.value });\n  const update = () =&gt; {\n    root.value = getValue();\n    root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true }));\n  };\n\n  // ONE listener for all children (sliders + button)\n  grid.addEventListener(\"input\", update);\n\n  queueMicrotask(update);\n  return root;\n}\n\n// --- Expose reactive vars\nn = controls.n\ntrueMu = controls.trueMu\ntrueSigma = controls.trueSigma\nmuHalfWidth = controls.muHalfWidth\nsig2Max = controls.sig2Max\ngridN = controls.gridN\nbins = controls.bins\nresim = controls.resim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip✨ Big picture:\n\n\n\n\nThe likelihood function 5.1 tells us how plausible each parameter value is, given the data.\nThe MLE 5.3 chooses the parameter value that makes the observed data most likely.\nLater, in Bayesian inference, we will combine the likelihood with a prior distribution on \\theta to obtain a posterior distribution.\n\n\n\n\n5.3.1 Computing Univariate MLEs\n\n\n\n\n\n\n\nExample 5.8 (Bernoulli MLE) From Example 5.1, we saw that the likelihood function for n i.i.d. Y_i \\sim \\mathrm{Bernoulli}(p) observations was\n\nL(p;\\underline{y}) = p^{n\\bar{y}}(1-p)^{n(1-\\bar{y})}.\n\nCompute the MLE of p.\n\n   Solution \nFrom the provided likelihood, we first compute the log-likelihood:\n\n\\ell(p \\mid \\underline{x})\n= \\Big(\\sum_i x_i \\Big)\\log p + \\Big(n-\\sum_i x_i\\Big)\\log(1-p).\n Differentiate and solve: \n\\frac{\\partial}{\\partial p}\\ell(p \\mid \\underline{x})\n= \\frac{\\sum_i x_i}{p} - \\frac{n - \\sum_i x_i}{1-p} = 0.\n This gives \n\\hat{p}_{\\text{MLE}} = \\frac{1}{n}\\sum_{i=1}^n x_i,\n\nthe sample proportion of successes.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.9 (Binomial MLE) Suppose we have a single Binomial 1.2 observation \nX \\sim \\textrm{Bin}(n, \\theta).\n Derive the maximum likelihood estimator of \\theta.\n\n   Solution \nSince we only have one observation, the likelihood function is just the distribution of the observation:\n\nL(\\theta ; x) = f(x \\mid \\theta) = \\binom{n}{x} \\theta^x(1-\\theta)^{n-x}.\n\nThe log-likelihood is thus\n\n\\ell(\\theta; x) = \\log f(x \\mid \\theta) = \\log\\left(\\binom{n}{x}\\right) + x\\log\\theta + (n-x)\\log(1-\\theta).\n\nDifferentiating, we obtain\n\n\\frac{\\partial}{\\partial \\theta}\\,\\ell(\\theta;x)\n= \\frac{x}{\\theta} - \\frac{n-x}{1-\\theta}.\n\nSetting the derivative to zero and solving,\n\n\\frac{x}{\\theta} = \\frac{n-x}{1-\\theta}\n\\;\\Longrightarrow\\;\nx(1-\\theta) = (n-x)\\theta\n\\;\\Longrightarrow\\;\nx = n\\theta\n\\;\\Longrightarrow\\;\n\\hat\\theta = \\frac{x}{n}.\n\nTo confirm it is a maximum, the second derivative is\n\n\\frac{\\partial^2}{\\partial \\theta^2}\\,\\ell(\\theta;x)\n= -\\frac{x}{\\theta^2} - \\frac{n-x}{(1-\\theta)^2} &lt; 0\n\\quad \\text{for } \\theta\\in(0,1),\n\nso \\hat\\theta=x/n maximises the likelihood. (At the boundaries, if x=0 then \\hat\\theta=0; if x=n then \\hat\\theta=1.)\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.10 (Another Binomial MLE) Suppose we have n independent Binomial data: \nX_i \\sim \\textrm{Bin}(k_i, \\theta).\n Note here that each Binomial data has a different number of Bernoulli trials k_i, which are known.\nDerive the maximum likelihood estimator of \\theta.\n\n   Solution \nThe likelihood function is the joint distribution of the n observations\n\nf(\\underline{x} \\mid \\theta) = \\prod_{i=1}^n \\binom{k_i}{x_i} \\theta^{x_i}(1-\\theta)^{k_i - x_i}.\n\nThe log-likelihood is\n\n\\ell(\\theta;\\underline{x})\n= \\sum_{i=1}^n \\log\\binom{k_i}{x_i}\n+ \\Big(\\sum_{i=1}^n x_i\\Big)\\log\\theta\n+ \\Big(\\sum_{i=1}^n (k_i-x_i)\\Big)\\log(1-\\theta).\n\nLet S=\\sum_{i=1}^n x_i (total successes) and K=\\sum_{i=1}^n k_i (total trials). Then\n\n\\frac{\\partial}{\\partial\\theta}\\ell(\\theta;\\underline{x})\n= \\frac{S}{\\theta} - \\frac{K-S}{1-\\theta}.\n\nSetting to zero and solving:\n\n\\frac{S}{\\theta} = \\frac{K-S}{1-\\theta}\n\\;\\Longrightarrow\\;\nS(1-\\theta)=(K-S)\\theta\n\\;\\Longrightarrow\\;\nS=K\\theta\n\\;\\Longrightarrow\\;\n\\hat\\theta = \\frac{S}{K}=\\frac{\\sum_{i=1}^n x_i}{\\sum_{i=1}^n k_i}.\n\nThe second derivative is\n\n\\frac{\\partial^2}{\\partial\\theta^2}\\ell(\\theta;\\underline{x})\n= -\\frac{S}{\\theta^2}-\\frac{K-S}{(1-\\theta)^2}&lt;0\n\\quad \\text{for } \\theta\\in(0,1),\n\nso this is a (strict) maximum. Boundary cases: if S=0 then \\hat\\theta=0; if S=K then \\hat\\theta=1.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.11 (Poisson MLE) From Example 5.4, we saw that the likelihood function for n i.i.d. V_i \\sim \\mathrm{Poisson}(\\alpha) observations was \nL(\\alpha ;\\underline{v}) = \\alpha^{n\\bar{v}} e^{-n\\alpha} \\prod_{i=1}^n \\frac{1}{v_i!}.\n\nDerive the maximum likelihood estimator of \\alpha and determine its expected value and variance.\n\n   Solution \nStep 1: Computing MLE\nThe log-likelihood is\n\n\\ell(\\alpha;\\underline{v})\n= n\\bar v \\log \\alpha - n\\alpha - \\sum_{i=1}^n \\log(v_i!),\n\\qquad \\alpha \\ge 0.\n\nDifferentiate w.r.t. \\alpha:\n\n\\frac{\\partial}{\\partial \\alpha}\\,\\ell(\\alpha;\\underline{v})\n= \\frac{n\\bar v}{\\alpha} - n.\n\nSet to zero and solve:\n\n\\frac{n\\bar v}{\\alpha} - n = 0\n\\;\\Longrightarrow\\;\n\\hat\\alpha = \\bar v = \\frac{1}{n}\\sum_{i=1}^n v_i.\n\nSecond derivative:\n\n\\frac{\\partial^2}{\\partial \\alpha^2}\\,\\ell(\\alpha;\\underline{v})\n= -\\frac{n\\bar v}{\\alpha^2} &lt; 0 \\quad (\\alpha&gt;0),\n\nso this is a maximum. Boundary case: if all v_i=0 (so \\bar v=0), the likelihood L(\\alpha)=e^{-n\\alpha} is maximised at \\hat\\alpha=0.\nTherefore, the maximum likelihood estimator is:\n\n\\hat\\alpha = \\bar{V}\n\n\nStep 2: Mean and Variance of \\hat\\alpha\nRecall \\hat\\alpha=\\bar V=\\frac{1}{n}\\sum_{i=1}^n V_i with V_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathrm{Poisson}(\\alpha).\nMean: \n\\mathrm{E}[\\hat\\alpha]\n= \\frac{1}{n}\\sum_{i=1}^n \\mathrm{E}[V_i]\n= \\frac{1}{n}\\cdot n\\alpha\n= \\alpha.\n\nVariance (using independence): \n\\operatorname{Var}[\\hat\\alpha]\n= \\operatorname{Var}\\!\\left(\\frac{1}{n}\\sum_{i=1}^n V_i\\right)\n= \\frac{1}{n^2}\\sum_{i=1}^n \\operatorname{Var}(V_i)\n= \\frac{1}{n^2}\\cdot n\\alpha\n= \\frac{\\alpha}{n}.\n\nHere we used \\operatorname{Var}(V_i)=\\mathrm{E}[V_i]=\\alpha for the \\mathrm{Poisson}(\\alpha) distribution.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.12 (Normal MLE for \\mu) From Example 5.3, we saw that the likelihood function for n i.i.d. T_i \\sim \\mathcal{N}(\\mu, \\gamma) observations was \n  L(\\mu, \\gamma ;\\underline{t}) = (2\\pi \\gamma)^{-\\tfrac{n}{2}} \\exp\\left\\{ -\\frac{1}{2\\gamma} \\sum_{i=1}^n  (t_i - \\mu)^2 \\right\\}.\n\nSuppose that the variance \\gamma is known. Determine the MLE of \\mu.\n\n   Solution \nThe log-likelihood (as a function of \\mu) is\n\n\\ell(\\mu;\\underline{t})\n= -\\frac{n}{2}\\log(2\\pi\\gamma) - \\frac{1}{2\\gamma}\\sum_{i=1}^n (t_i-\\mu)^2.\n\nDifferentiating w.r.t. \\mu,\n\n\\frac{\\partial}{\\partial\\mu}\\,\\ell(\\mu;\\underline{t})\n= -\\frac{1}{2\\gamma}\\cdot 2\\sum_{i=1}^n (t_i-\\mu)(-1)\n= \\frac{1}{\\gamma}\\sum_{i=1}^n (t_i-\\mu).\n\nSetting equal to 0 and solve:\n\n\\sum_{i=1}^n (t_i-\\mu)=0\n\\;\\Longrightarrow\\;\nn\\mu=\\sum_{i=1}^n t_i\n\\;\\Longrightarrow\\;\n\\hat\\mu=\\bar{t}=\\frac{1}{n}\\sum_{i=1}^n t_i.\n\nThe second derivative is\n\n\\frac{\\partial^2}{\\partial\\mu^2}\\,\\ell(\\mu;\\underline{t})\n= -\\frac{n}{\\gamma}&lt;0,\n\nso \\hat\\mu=\\bar{t} maximises the likelihood.\n\n\n\n\n\n\n\n5.3.2 Computing Multivariate MLEs\nIn many practical problems, the statistical model involves more than a single parameter \\theta. In this case, we work with a vector of parameters\n\n\\underline{\\theta} = (\\theta_1, \\ldots, \\theta_p).\n\nThe definitions of the likelihood function and the MLE extend in a natural way. The main difference is that the optimisation problem now requires solving simultaneous equations for each parameter.\n\n\n\n\n\n\n\nDefinition 5.5 (Multivariate MLE) Let L(\\underline{\\theta}; \\underline{x}) and \\ell(\\underline{\\theta}; \\underline{x}) denote the likelihood and log-likelihood functions respectively, based on observations \\underline{x} = (x_1,\\ldots,x_n) from a model with parameters \\underline{\\theta} = (\\theta_1,\\ldots,\\theta_p).\nThe maximum likelihood estimator \\hat{\\underline{\\theta}} is obtained by solving the system\n\n\\nabla_{\\underline{\\theta}} \\,\\ell(\\underline{\\theta}; \\underline{x})\n\\;=\\;\n\\begin{pmatrix}\n\\dfrac{\\partial}{\\partial \\theta_1}\\,\\ell(\\underline{\\theta}; \\underline{x}) \\\\\n\\dfrac{\\partial}{\\partial \\theta_2}\\,\\ell(\\underline{\\theta}; \\underline{x}) \\\\\n\\vdots \\\\\n\\dfrac{\\partial}{\\partial \\theta_p}\\,\\ell(\\underline{\\theta}; \\underline{x})\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\ 0 \\\\ \\vdots \\\\ 0\n\\end{pmatrix}.\n\n\n\n\n\nIn general, solving this system of equations cannot be done in closed form, so in practice we usually rely on numerical optimisation methods to approximate the MLE. We will not cover these methods in this course. Instead, we will focus on a few important cases where the MLE can be worked out explicitly.\n\n\n\n\n\n\n\nExample 5.13 (Normal MLE for \\mu and \\gamma) Suppose we have n i.i.d. observations X_i \\sim \\mathcal{N}(\\mu, \\gamma).\nDetermine the maximum likelihood estimators for \\mu and \\gamma.\n\n   Solution \nStep 1. Compute log-likelihood:\nThe likelihood function is a relabelling of the data terms in Example 5.3:\n\\begin{align*}\nL(\\mu, \\gamma ;\\underline{x}) &= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\gamma}} \\exp\\left\\{ -\\frac{1}{2\\gamma} (x_i - \\mu)^2 \\right\\} \\\\\n&= (2\\pi \\gamma)^{-\\tfrac{n}{2}} \\exp\\left\\{ \\sum_{i=1}^n -\\frac{1}{2\\gamma} (x_i - \\mu)^2 \\right\\}.\n\\end{align*}\nThe log-likelihood is thus\n\n\\ell(\\mu,\\sigma^2;\\underline{x})\n= -\\frac{n}{2}\\log(2\\pi\\sigma^2)\n- \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - \\mu)^2.\n\nStep 2. Differentiate w.r.t. \\mu:\n\n\\frac{\\partial \\ell}{\\partial \\mu}\n= \\frac{1}{\\sigma^2}\\sum_{i=1}^n (x_i - \\mu).\n\nSetting this equal to 0 gives\n\n\\hat{\\mu} = \\bar{x}.\n\nStep 2. Differentiate w.r.t. \\sigma^2:\n\n\\frac{\\partial \\ell}{\\partial \\sigma^2}\n= -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2}\\sum_{i=1}^n (x_i - \\mu)^2.\n\nSetting this equal to 0 and substituting \\mu = \\hat{\\mu} gives\n\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2.\n\nFinal Answer: The MLEs are\n\n\\hat{\\mu} = \\bar{X},\n\\qquad\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (X_i - \\bar{X})^2.\n\nNote: \\hat{\\sigma}^2 is biased (its expectation is \\tfrac{n-1}{n}\\sigma^2), but it is the maximum likelihood estimate.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html#information-and-efficiency-of-estimators",
    "href": "content/main/part2/5-likelihood.html#information-and-efficiency-of-estimators",
    "title": "5  Likelihood",
    "section": "5.4 Information and Efficiency of Estimators",
    "text": "5.4 Information and Efficiency of Estimators\nIn the previous chapter we studied two kinds of properties of estimators:\n\nIn Properties of Estimators 4.2, we introduced: bias 4.4, variance 4.5, and MSE 4.8.\n\nIn Asymptotic Properties of Estimators 4.4, we introduced: asymptotic unbiasedness 4.9 and consistency 4.10.\n\nNow that we have the likelihood function, we can go further and introduce two powerful ideas:\n\nCramér–Rao Lower Bound (CRLB): a universal lower bound on the variance of any unbiased estimator.\nEfficiency: whether an estimator actually attains this bound (at least asymptotically).\n\n\n\n\n\n\n\nImportant 5.3: Motivation\n\n\n\n\n\nOur central measure of estimator quality was the mean squared error (MSE). From the bias-variance decomposition 4.4 of the MSE, we know:\n\n\\mathrm{MSE}(\\hat{\\theta}) = \\mathrm{Bias}(\\hat{\\theta})^2 + \\mathrm{Var}(\\hat{\\theta}).\n\nFor unbiased estimators (\\mathrm{Bias}(\\hat{\\theta})=0), this reduces to\n\n\\mathrm{MSE}(\\hat{\\theta}) = \\mathrm{Var}(\\hat{\\theta}).\n\nSo if we restrict attention to unbiased estimators, the question of “how good” becomes:\n\nWhich unbiased estimator has the smallest possible variance?\n\nThe Cramér–Rao Lower Bound (CRLB) answers this: it gives a universal benchmark for how small the variance can ever be.\n\n\n\nBefore introducing the CRLB and efficiency, we first need two key definitions derived from the likelihood function.\n\n5.4.1 Score and Fisher Information\n\n\n\n\n\n\n\nDefinition 5.6 (Score Statistic) The score is the derivative of the log-likelihood with respect to the parameter:\n\nU(\\theta;\\underline{X}) \\;=\\; \\frac{\\partial}{\\partial \\theta}\\,\\ell(\\theta;\\underline{X})\n= \\frac{\\partial}{\\partial \\theta}\\,\\log f(\\underline{X}\\mid \\theta).\n\nIt is a random quantity.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 5.7 (Fisher Information) The Fisher Information (or expected information) for data \\underline{X} with log-likelihood \\ell(\\theta;\\underline{X}) is\n\n\\mathcal{I}(\\theta;\\underline{X}) \\;=\\; -\\,\\mathrm{E}\\!\\left[ \\frac{\\partial^2}{\\partial \\theta^2}\\,\\ell(\\theta;\\underline{X}) \\right].\n\n\n\n\n\nIntuition: Fisher information measures how much the data tell us about \\theta.\n\nA sharply peaked log-likelihood \\Rightarrow high information (data strongly constrain \\theta).\nA flat log-likelihood \\Rightarrow low information (many \\theta’s are plausible). The curvature (second derivative) captures this “peakedness.”\n\n\n\n\n\n\n\n\nProposition 5.1 (Fisher Information for i.i.d. Data) Suppose we have an i.i.d. sample \\underline{X}^{(n)} = (X_1,\\ldots,X_n) drawn from the same distribution with PDF/PMF f(x \\mid \\theta). Define:\n\nThe Fisher information from one observation: \n\\mathcal{I}_1(\\theta) = -\\mathrm{E}\\left [\\tfrac{\\partial^2}{\\partial \\theta^2}\\log f(X\\mid \\theta)\\right]\n\nThe Fisher information from the whole sample (i.e. Definition 5.7): \n\\mathcal{I}_n(\\theta) = \\mathcal{I}(\\theta; \\underline{X}^{(n)}) = -\\mathrm{E}\\left [\\tfrac{\\partial^2}{\\partial \\theta^2}\\ell(\\theta;\\underline{X}^{(n)})\\right]\n\n\nThen\n\n\\mathcal{I}_n(\\theta) = n\\,\\mathcal{I}_1(\\theta).\n\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 5.1. For n i.i.d. observations, the log-likelihood is\n\n\\ell(\\theta;\\underline{X}) \\;=\\; \\sum_{i=1}^n \\log f(X_i \\mid \\theta).\n\nDifferentiating twice,\n\n\\frac{\\partial^2}{\\partial \\theta^2}\\ell(\\theta;\\underline{X}^{(n)})\n\\;=\\; \\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2}\\log f(X_i \\mid \\theta).\n\nNow take expectations:\n\n\\mathcal{I}_n(\\theta)\n\\;=\\; -\\,\\mathrm{E}\\!\\left[ \\frac{\\partial^2}{\\partial \\theta^2}\\ell(\\theta;\\underline{X}^{(n)}) \\right]\n\\;=\\; -\\,\\mathrm{E}\\!\\left[\\sum_{i=1}^n \\frac{\\partial^2}{\\partial \\theta^2}\\log f(X_i \\mid \\theta)\\right].\n\nBy linearity of expectation,\n\n\\mathcal{I}_n(\\theta)\n\\;=\\; \\sum_{i=1}^n \\left( -\\,\\mathrm{E}\\!\\left[ \\frac{\\partial^2}{\\partial \\theta^2}\\log f(X_i \\mid \\theta)\\right]\\right).\n\nSince the X_i are IID, each term in the sum is the same:\n\n\\mathcal{I}_n(\\theta) = n\\,\\mathcal{I}(\\theta).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.14 (Fisher Information for the Poisson Model) Suppose we have n i.i.d. observations X_i\\sim \\mathrm{Poisson}(\\alpha). From Example 5.4, we saw the likelihood took the form\n\nL(\\alpha; \\underline{x}) = \\frac{ e^{-\\alpha n} \\alpha^{n\\bar{x}} }{\\prod_{i=1}^n x_i!}\n\nDetermine the Fisher information 5.1 for:\n\nThe whole sample\nA single observation\n\n\nSolution\na. Whole sample\nWe have\n\n\\ell(\\alpha; \\underline{x}) = -n\\alpha + \\bigg(\\sum_{i=1}^n x_i\\bigg)\\log \\alpha - \\sum_{i=1}^n \\log x_i!,\n\\qquad \\alpha&gt;0.\n\nDifferentiate:\n\n\\frac{\\partial \\ell}{\\partial \\alpha}\n= -n + \\frac{\\sum_{i=1}^n x_i}{\\alpha},\n\\qquad\n\\frac{\\partial^2 \\ell}{\\partial \\alpha^2}\n= -\\frac{\\sum_{i=1}^n x_i}{\\alpha^2}.\n\nHence the Fisher information is\n\n\\mathcal{I}_n(\\alpha)\n= -\\,\\mathrm{E}\\!\\left[\\frac{\\partial^2 \\ell}{\\partial \\alpha^2}\\right]\n= -\\,\\mathrm{E}\\!\\left[-\\frac{\\sum_{i=1}^n X_i}{\\alpha^2}\\right]\n= \\frac{n\\alpha}{\\alpha^2}\n= \\frac{n}{\\alpha}.\n\n\nb. Single observation\nFor one X\\sim\\mathrm{Poisson}(\\alpha),\n\n\\ell_1(\\alpha;x)=-\\alpha + x\\log\\alpha - \\log x!,\n\\quad\n\\frac{\\partial^2 \\ell_1}{\\partial \\alpha^2}\n= -\\frac{x}{\\alpha^2}.\n\nTherefore\n\n\\mathcal{I}_1(\\alpha)\n= -\\,\\mathrm{E}\\!\\left[\\frac{\\partial^2 \\ell_1}{\\partial \\alpha^2}\\right]\n= -\\,\\mathrm{E}\\!\\left[-\\frac{X}{\\alpha^2}\\right]\n= \\frac{\\alpha}{\\alpha^2}\n= \\frac{1}{\\alpha}.\n\n\n\n\n\n\n\n5.4.2 Cramér–Rao Lower Bound and Efficiency\nWe can now state one of the most important results in statistical inference: the Cramér–Rao inequality. It tells us how small the variance of an unbiased estimator can ever be.\n\n\n\n\n\n\n\nTheorem 5.2 (The Cramér–Rao Inequality and the CRLB) Let X_1,\\dots,X_n be i.i.d. random variables with likelihood function L(\\theta;\\underline{x}), and let \\hat{\\theta} be an unbiased estimator of \\theta.\nThen, under regularity conditions,\n\n\\mathrm{Var}(\\hat{\\theta}) \\;\\geq\\; \\frac{1}{\\mathcal{I}_n(\\theta)},\n where \\mathcal{I}_n(\\theta) is the Fisher information 5.1 for the whole sample.\nThe quantity \\tfrac{1}{\\mathcal{I}_n(\\theta)} is called the Cramér–Rao Lower Bound (CRLB). It represents the smallest possible variance achievable by any unbiased estimator of \\theta.\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 5.2 (Not Examinable). The proof of the Cramér–Rao inequality follows from the covariance inequality:\n\n\\mathrm{Cov}(X,Y)^2 \\leq \\mathrm{Var}(X)\\,\\mathrm{Var}(Y),\n\napplied to the score random variable X = U(\\theta; \\underline{X}) and the estimator Y = \\hat{\\theta}(\\underline{X}). Substituting these in and rearranging for the variance of \\hat{\\theta} gives\n\n\\mathrm{Var}(\\hat{\\theta}) \\;\\geq\\; \\frac{\\mathrm{Cov}(\\hat{\\theta},U)^2}{\\mathrm{Var}(U)}.\n\nThen, under regularity conditions, one can show that the variance of U is the Fisher information, and the covariance term equals 1.\nThus, the proof can be broken into steps:\n\nProve the Covariance Inequality\nShow: \\mathrm{E}[U] = 0\nShow: \\mathrm{Var}(U) = \\mathcal{I}(\\theta)\nShow: \\mathrm{Cov}(\\hat{\\theta}, U) = 1\n\nAlong the way, we will present the regularity conditions.\n\nStep 1 (Proving Covariance Inequality):\nThe covariance inequality follows from the Cauchy-Schwarz inequality for random variables:\n\n\n\n\n\n\nTipCauchy-Schwarz Inequality for Random Variables\n\n\n\nFor any random variables X and Y of finite variance, \n\\mathrm{E}[XY]^2 \\leq \\mathrm{E}[X^2] \\mathrm{E}[Y^2].\n\n\n\nProof of Cauchy-Schwarz Inequality\n\nConsider \\mathrm{E}\\left[ (aX+Y)^2 \\right], which is clearly non-negative for real a.\nMultiplying out gives: \na^2 \\mathrm{E}[X^2] + 2a \\mathrm{E}[XY] + \\mathrm{E}[Y^2] \\geq 0.\n Consider the left hand side as a quadratic in a. Since it is always non-negative it cannot have two real roots. Using the quadratic formula the roots satisfy: \na = \\frac{-2\\mathrm{E}[XY] \\pm \\sqrt{4 \\mathrm{E}[XY]^2 - 4 \\mathrm{E}[X^2] \\mathrm{E}[Y^2]}}{2 \\mathrm{E}[X^2]}\n For there to be zero or one real roots, the square root term must be non-positive i.e. \n\\mathrm{E}[XY]^2 - \\mathrm{E}[X^2] \\mathrm{E}[Y^2] \\leq 0.\n which gives the required result.\n\n\n\nApplying Cauchy-Schwarz, to the mean-zero shifted random variables, X - \\mathrm{E}[X] and Y-\\mathrm{E}[Y], we obtain\n\\begin{align*}\n\\mathrm{Cov}(X,Y)^2 &= \\mathrm{E}\\left[(X-\\mathrm{E}[X])(Y-\\mathrm{E}[Y])\\right]^2 \\\\\n&\\leq \\mathrm{E}\\left[ (X-\\mathrm{E}[X])^2 \\right] \\mathrm{E}\\left[(Y-\\mathrm{E}[Y])^2\\right]  = \\mathrm{Var}(X)\\mathrm{Var}(Y).\n\\end{align*}\n\nAside: You may recall that the correlation between two random variables is defined as \n\\mathrm{Cor}(X,Y) = \\frac{\\mathrm{Cov}(X,Y)}{\\mathrm{Var}(X)^{1/2} \\mathrm{Var}(Y)^{1/2}}\n and satisfies -1\\leq \\mathrm{Cor}(X,Y) \\leq 1. This inequality is derived from the covariance inequality.\n\nStep 2 (Proving \\mathrm{E}[U] = 0):\nBy the definition of the log-likelihood: \n\\tfrac{\\partial}{\\partial\\theta} \\ell(\\theta;\\underline{x}) = \\frac{\\partial}{\\partial\\theta} \\log f(\\underline{x} \\mid \\theta).\n\nUsing the chain rule, we have \n\\frac{\\partial}{\\partial\\theta} \\ell(\\theta;\\underline{x}) = \\frac{\\partial}{\\partial\\theta} \\log f(\\underline{x} \\mid \\theta) = \\frac{\\frac{\\partial}{\\partial\\theta} f(\\underline{x}\\mid \\theta)}{f(\\underline{x}\\mid \\theta)}.\n\nSince U(\\theta; \\underline{x}) = \\tfrac{\\partial}{\\partial\\theta} \\ell(\\theta;\\underline{x}), we can compute its expectation as follows\n\\begin{align*}\n\\mathrm{E}[U(\\theta; \\underline{X})] &= \\int U(\\theta;\\underline{x}) f(\\underline{x}\\mid\\theta) \\,\\mathrm{d}\\underline{x} \\\\\n&= \\int \\frac{\\frac{\\partial}{\\partial\\theta} f(\\underline{x}\\mid \\theta)}{f(\\underline{x}\\mid \\theta)} f(\\underline{x}\\mid\\theta)\\,\\mathrm{d}\\underline{x} \\\\\n&= \\int \\frac{\\partial}{\\partial\\theta} f(\\underline{x}\\mid \\theta) \\,\\mathrm{d}\\underline{x} \\\\\n&= \\frac{\\partial}{\\partial \\theta} \\int f(\\underline{x}\\mid \\theta) \\,\\mathrm{d}\\underline{x} \\\\\n&=  \\frac{\\partial}{\\partial \\theta} 1 \\\\\n&= 0.\n\\end{align*}\nHere, we assumed the first regularity condition:\n\nRegularity Condition 1: We assumed we can interchange the integral and derivative in the step \n\\int \\frac{\\partial}{\\partial \\theta}  f(\\underline{x}\\mid \\theta) \\,\\mathrm{d}\\underline{x} = \\frac{\\partial}{\\partial \\theta} \\int f(\\underline{x}\\mid \\theta) \\,\\mathrm{d}\\underline{x}\n\n\n\nStep 3 (Proving \\mathrm{Var}(U) = \\mathcal{I}_n(\\theta)):\nBy definition,\n\n\\mathrm{Var}(U) = \\mathrm{E}[U^2] - \\big(\\mathrm{E}[U]\\big)^2.\n\nFrom Step 2 we know \\mathrm{E}[U] = 0, so\n\n\\mathrm{Var}(U) = \\mathrm{E}[U^2] = \\mathrm{E}\\!\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\,\\ell(\\theta;\\underline{X})\\right)^2\\right].\n\nRecall the identity derived in Step 2: \n\\frac{\\partial}{\\partial \\theta} \\ell(\\theta ; \\underline{x})\n= \\frac{\\frac{\\partial}{\\partial \\theta} f(\\underline{x}\\mid \\theta) }{f(\\underline{x}\\mid \\theta)}.\n Differentiating again, using the product and chain rules, yields:\n\n\\frac{\\partial^2}{\\partial \\theta^2} \\ell(\\theta ; \\underline{x})\n= -\\frac{ \\left( \\frac{\\partial}{\\partial \\theta} f(\\underline{x}\\mid \\theta) \\right)^2}{f(\\underline{x}\\mid \\theta)^2} + \\frac{\\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{x}\\mid \\theta)}{f(\\underline{x}\\mid \\theta)} .\n Therefore, \n\\frac{\\partial^2}{\\partial \\theta^2} \\ell(\\theta ; \\underline{x})\n= -\\left(\\frac{\\partial}{\\partial \\theta} \\ell(\\theta;\\underline{x})\\right)^2 + \\frac{\\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{x}\\mid \\theta)}{f(\\underline{x}\\mid \\theta)} .\n Rearranging for \\left(\\frac{\\partial}{\\partial \\theta} \\ell(\\theta;\\underline{x})\\right)^2 yields: \n\\left(\\frac{\\partial}{\\partial \\theta} \\ell(\\theta;\\underline{x})\\right)^2 = \\frac{\\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{x}\\mid \\theta)}{f(\\underline{x}\\mid \\theta)} - \\frac{\\partial^2}{\\partial \\theta^2} \\ell(\\theta ; \\underline{x}).\n\nComputing the expectation, we have\n\\begin{align*}\n\\mathrm{Var}(U) &= \\mathrm{E}\\left[\\frac{\\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{X}\\mid \\theta)}{f(\\underline{X}\\mid \\theta)} - \\frac{\\partial^2}{\\partial \\theta^2} \\ell(\\theta ; \\underline{X})\\right] \\\\\n&= \\mathrm{E}\\left[\\frac{\\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{X}\\mid \\theta)}{f(\\underline{X}\\mid \\theta)}\\right] + \\underbrace{\\mathrm{E}\\left[-\\frac{\\partial^2}{\\partial \\theta^2} \\ell(\\theta ; \\underline{X})\\right]}_{= \\mathcal{I}_n(\\theta)}.\n\\end{align*}\nConcentrating on the remaining expectation:\n\\begin{align*}\n\\mathrm{E}\\left[\\frac{\\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{X}\\mid \\theta)}{f(\\underline{X}\\mid \\theta)}\\right] &= \\int \\frac{\\partial^2}{\\partial \\theta^2} f(\\underline{x}\\mid \\theta) \\, \\mathrm{d}\\underline{x} \\\\\n&= \\frac{\\partial^2}{\\partial \\theta^2} \\int f(\\underline{x}\\mid \\theta) \\, \\mathrm{d}\\underline{x} \\\\\n&= \\frac{\\partial^2}{\\partial \\theta^2} 1 \\\\\n&= 0.\n\\end{align*}\nHere, we assumed the second regularity condition:\n\nRegularity Condition 2: We assumed we can interchange the integral and second derivative in the step \n\\int \\frac{\\partial^2}{\\partial \\theta^2}  f(\\underline{x}\\mid \\theta) \\,\\mathrm{d}\\underline{x} = \\frac{\\partial^2}{\\partial \\theta^2} \\int f(\\underline{x}\\mid \\theta) \\,\\mathrm{d}\\underline{x}\n\n\nTherefore, we can conclude Step 3 with the final result:\n\n\\mathrm{Var}(U) = \\mathcal{I}_n(\\theta).\n\n\nStep 4 (Proving \\mathrm{Cov}(\\hat{\\theta}, U) = 1):\nBy definition,\n\n\\mathrm{Cov}(\\hat{\\theta}, U) = \\mathrm{E}\\big[(\\hat{\\theta}-\\theta)\\,U\\big].\n\nUsing the same result used in steps 2 and 3: \nU(\\theta;\\underline{x}) = \\frac{\\partial}{\\partial \\theta} \\log f(\\underline{x}\\mid \\theta) = \\frac{\\frac{\\partial}{\\partial \\theta} f(\\underline{x}\\mid \\theta)}{f(\\underline{x}\\mid \\theta)},\n\nwe have \n\\mathrm{E}[\\hat{\\theta} U]\n= \\int \\hat{\\theta}(\\underline{x}) \\,\\frac{\\partial}{\\partial \\theta} f(\\underline{x}\\mid\\theta) \\,\\mathrm{d}\\underline{x}.\n\nSince \\hat{\\theta} is constant in \\theta and assuming we can interchange the derivative and integral, we arrive at:\n\n\\mathrm{E}[\\hat{\\theta} U]\n= \\frac{\\partial}{\\partial \\theta} \\int \\hat{\\theta}(\\underline{x}) f(\\underline{x}\\mid \\theta)\\,\\mathrm{d}\\underline{x}.\n\nThis assumption forms our third regularity condition:\n\nRegularity Condition 3: We assumed we can interchange the integral and derivative in the step \n\\int \\frac{\\partial}{\\partial \\theta}\\left(\\hat{\\theta}(\\underline{x}) f(\\underline{x}\\mid \\theta)\\right)\\,\\mathrm{d}\\underline{x} = \\frac{\\partial}{\\partial \\theta} \\int \\hat{\\theta}(\\underline{x}) f(\\underline{x}\\mid \\theta)\\,\\mathrm{d}\\underline{x}\n\n\nNote now that \\int \\hat{\\theta}(\\underline{x}) f(\\underline{x}\\mid \\theta)\\,\\mathrm{d}\\underline{x} = \\mathrm{E}[\\hat{\\theta}] and, since we assumed \\hat{\\theta} is unbiased, we have \n\\int \\hat{\\theta}(\\underline{x}) f(\\underline{x}\\mid \\theta)\\,\\mathrm{d}\\underline{x} = \\mathrm{E}[\\hat{\\theta}] = \\theta.\n Hence, \n\\mathrm{E}[\\hat{\\theta} U] = \\frac{\\partial}{\\partial \\theta}\\,\\theta = 1.\n\nAlso, from Step 2, \\mathrm{E}[U]=0. Therefore,\n\n\\mathrm{Cov}(\\hat{\\theta}, U) = \\mathrm{E}[\\hat{\\theta} U] - \\mathrm{E}[\\hat{\\theta}]\\,\\mathrm{E}[U] = 1 - \\theta \\cdot 0 = 1.\n\n\nConclusion:\nPutting Steps 1–4 together:\n\n\\mathrm{Var}(\\hat{\\theta}) \\;\\geq\\; \\frac{\\mathrm{Cov}(\\hat{\\theta},U)^2}{\\mathrm{Var}(U)} \\;=\\; \\frac{1^2}{\\mathcal{I}_n(\\theta)} \\;=\\; \\frac{1}{\\mathcal{I}_n(\\theta)}.\n\nThis completes the proof of the Cramér–Rao inequality.\n\n\n\n\n\n\n\n\n\n\nWarningNon-Examinable Content\n\n\n\nThe regularity conditions required for the CRLB are not examinable.\nInformally, these conditions rule out “badly behaved” cases; for example, densities f(x\\mid\\theta) with infinite variance, infinite expectation, or parameter-dependent support. They also justify steps such as interchanging derivatives and integrals in the proof.\nIf you are curious, see the non-examinable proof in Proof 5.2.\n\n\n\n\n\n\n\n\n\nDefinition 5.8 (Efficiency of an Estimator)  \n\nAn unbiased estimator is called efficient if its variance achieves the CRLB exactly:\n\n\\mathrm{Var}(\\hat{\\theta}) = \\frac{1}{\\mathcal{I}_n(\\theta)}.\n\nA sequence of estimators \\hat{\\theta}_n is asymptotically efficient if, as the sample size grows, its variance approaches the CRLB2: \n\\lim_{n \\to \\infty} \\frac{\\mathrm{Var}(\\hat{\\theta}_n)}{1/\\mathcal{I}_n(\\theta)} \\;=\\; 1,\n where \\mathcal{I}_n(\\theta) is the Fisher information 5.1 for the whole sample of size n.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nCorollary 5.1 By the CRLB and Fisher Information for IID Data 5.1, the variance of an efficient estimator decreases at rate 1/n as the sample size increases.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html#the-asymptotic-distribution-of-the-mle",
    "href": "content/main/part2/5-likelihood.html#the-asymptotic-distribution-of-the-mle",
    "title": "5  Likelihood",
    "section": "5.5 The Asymptotic Distribution of the MLE",
    "text": "5.5 The Asymptotic Distribution of the MLE\nPreviously, we introduced asymptotic 4.2 properties of estimators.\nIn particular, we saw that we can determine the asymptotic sampling distribution 4.3 of an estimator:\n\nThe Central Limit Theorem 4.1 told us that the sampling distribution of the sample mean 4.1 is approximately Normal for large n.\n\nThis gave us a first example of the principle: with enough data, many estimators behave like a Normal random variable around the true parameter.\nA much more general and powerful result is that maximum likelihood estimators also satisfy this property.\n\n\n\n\n\n\n\nTheorem 5.3 (Asymptotic Distribution of the MLE) Let \\hat{\\theta}_n denote the maximum likelihood estimator 5.3 based on n i.i.d. samples X_1,\\ldots, X_n drawn from the same distribution with PDF/PMF f(x \\mid \\theta).\nUnder regularity conditions, the MLE has the following asymptotic distribution: \n\\sqrt{n}\\,(\\hat{\\theta}_n - \\theta) \\;\\xrightarrow{\\,d\\,}\\; \\mathcal{N} \\big(0, \\mathcal{I}_1(\\theta)^{-1}\\big),\n\nwhere \\mathcal{I}_1(\\theta) \\;=\\; -\\,\\mathrm{E}\\!\\left[ \\frac{\\partial^2}{\\partial \\theta^2} \\log f(X \\mid \\theta) \\right] is the Fisher Information 5.1 for a single observation.\n\n\n\n\n\n\n\n\n\n\nNoteProof (Not Examinable)\n\n\n\n\n\n\nProof 5.3 (Not Examinable). The full proof uses tools such as Taylor expansions of the score function and the Central Limit Theorem for sums of random variables.\n\n\n\n\n\n\n\n\n\n\nWarningNon-Examinable Content\n\n\n\nThe regularity conditions required for the Asymptotic Distribution of the MLE are not examinable.\n\n\nIn this course, the main use of the Theorem 5.3 will be to approximate the MLE distribution using the normal distribution for sufficienty large n:\n\n\n\n\n\n\n\nDefinition 5.9 (Approximate Sampling Distribution of the MLE) From the asymptotic distribution of the MLE 5.3, we obtain the following approximation: \n\\hat{\\theta}_n \\;\\overset{\\text{approx.}}{\\sim}\\;\n\\mathcal N\\!\\left(\\theta,\\; \\tfrac{1}{n}\\,\\mathcal{I}_1(\\theta)^{-1}\\right),\n\\qquad \\text{for large } n.\n Equivalently, using the Fisher Information 5.1 for the whole sample \\mathcal{I}_n(\\theta), and using \\mathcal{I}_n(\\theta) = n\\mathcal{I}_1(\\theta), we have the approximation \n\\hat{\\theta}_n \\;\\overset{\\text{approx.}}{\\sim}\\;\n\\mathcal N\\!\\left(\\theta,\\; \\mathcal{I}_n(\\theta)^{-1}\\right),\n\\qquad \\text{for large } n.\n In practice, since the true parameter \\theta is unknown, we replace \\theta by the observed MLE \\hat{\\theta}_{\\text{obs}}. This gives the practical approximation \n\\hat{\\theta}_n \\;\\overset{\\text{approx.}}{\\sim}\\;\n\\mathcal N \\left(\\theta,\\; \\mathcal{I}_n(\\hat{\\theta}_{\\text{obs}})^{-1}\\right).\n\nThis Normal distribution serves as an approximate sampling distribution of the MLE and underpins methods such as constructing confidence intervals and hypothesis tests.\n\n\n\n\nThe quantity \\mathcal{I}_n(\\hat{\\theta}_{\\text{obs}}) is called the observed Fisher information.\n\n\n\n\n\n\n\nDefinition 5.10 (Observed Fisher Information) Let \\hat{\\theta} denote the maximum likelihood estimator 5.3 based on n i.i.d. samples X_1, \\ldots, X_n drawn from a distribution with density or mass function f(x \\mid \\theta).\nThe observed Fisher information is the Fisher information 5.7 evaluated at the observed value of the MLE, \\hat{\\theta}_{\\text{obs}}, obtained from the observed data x_1, \\ldots, x_n: \n\\mathcal{I}_n(\\hat{\\theta}_{\\text{obs}}) = \\mathcal{I}(\\hat{\\theta}_{\\text{obs}}; \\underline{X}).\n Similarly, the observed Fisher information for a single observation is the quantity \n\\mathcal{I}_1(\\hat{\\theta}_{\\text{obs}}).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5.15 (Asymptotic Distribution of the Poisson MLE) Suppose X_1, X_2, \\dots, X_n is an i.i.d. random sample from a \\text{Poisson}(\\lambda) distribution.\nWe know that the maximum likelihood estimator for \\lambda is\n\n\\hat{\\lambda} = \\bar{X}.\n\nWhat is the asymptotic distribution of \\hat{\\lambda} = \\bar{X} as n \\to \\infty?\n\nSolution\nIn Example 5.14, we saw the Fisher information for one Poisson observation is\n\n\\mathcal{I}_1(\\lambda) = \\frac{1}{\\lambda}.\n\nFor n independent observations this scales to\n\n\\mathcal{I}_n(\\lambda) = \\frac{n}{\\lambda}.\n\nTherefore, \n\\frac{1}{\\mathcal{I}_n(\\lambda)} = \\frac{\\lambda}{n}.\n\nIt follows immediately from Theorem 5.3 that\n\n\\hat{\\lambda} \\;\\;\\stackrel{\\text{approx.}}{\\sim}\\;\\; \\mathcal{N}\\!\\left(\\lambda,\\; \\tfrac{\\lambda}{n}\\right),\n\\quad \\text{as } n \\to \\infty.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/5-likelihood.html#footnotes",
    "href": "content/main/part2/5-likelihood.html#footnotes",
    "title": "5  Likelihood",
    "section": "",
    "text": "Geometric mean. One can write \\prod_{i=1}^n x_i = \\bar{x}_g^n where \\bar{x}_g = \\left(\\prod_{i=1}^n x_i \\right)^{1/n} is the geometric mean. This reformulation is rarely useful in practice, so it’s usually best to leave the product as it is.↩︎\nAsymptotic Equivalence. Equivalently, we could say \\mathrm{Var}(\\hat{\\theta}_n) \\sim \\tfrac{1}{\\mathcal{I}_n(\\theta)}, where “\\sim” here means asymptotically equivalent.↩︎",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Likelihood</span>"
    ]
  },
  {
    "objectID": "content/main/part2/6-bayes-inference.html",
    "href": "content/main/part2/6-bayes-inference.html",
    "title": "6  Bayesian Inference",
    "section": "",
    "text": "6.1 Introduction to the Bayesian Approach\nSo far we have taken a frequentist perspective: parameters such as \\theta are fixed but unknown, and all randomness comes from the sample.\nBayesian inference takes a different view:\nThe word random here does not mean that the parameter is physically fluctuating. Instead, it represents our uncertainty about its true value.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part2/6-bayes-inference.html#introduction-to-the-bayesian-approach",
    "href": "content/main/part2/6-bayes-inference.html#introduction-to-the-bayesian-approach",
    "title": "6  Bayesian Inference",
    "section": "",
    "text": "Frequentist: the parameter \\theta is fixed but unknown.\nBayesian: the parameter \\theta is treated as a random variable.\n\n\n\n6.1.1 Probability as Uncertainty\nIn the Bayesian framework, probability is interpreted as a way of quantifying uncertainty about unknown quantities.\nRather than saying “the parameter is a fixed number we don’t know”, we describe how plausible different values are using a probability distribution.\n\n\n\n\n\n\n\nExample 6.1 (Umbrella Decisions) Imagine the weather forecast says there is a 70\\% chance of rain tomorrow.\n\nThe sky doesn’t “rain in 70\\% of parallel universes.”\nInstead, the number 70\\% reflects our uncertainty given current information (satellite data, forecasts, etc.).\n\n\n   Show Plot \n\nrainP = 0.7\nnoRainP = 1 - rainP\n\numbrellaSegments = [\n  { label: \"Rain (70%)\",    x1: 0,     x2: rainP,  which: \"Rain\" },\n  { label: \"No rain (30%)\", x1: rainP, x2: 1,      which: \"No rain\" }\n]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot.plot({\n  height: 120,\n  marginLeft: 50,\n  marginRight: 20,\n  marginBottom: 45,\n  x: { label: \"Probability\", domain: [0, 1], nice: false },\n  y: { axis: null },\n    style: {\n      width: \"100%\",\n      display: \"block\", \n      margin: \"0 auto\", \n      maxWidth: \"960px\",\n      background: \"var(--brand-bg)\",\n      color: \"var(--brand-fg)\",\n      fontFamily: bodyFont, \n      fontSize: 12\n    },\n  marks: [\n    Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n    // two stacked rectangles forming one bar\n    Plot.rectX(umbrellaSegments, {\n      x1: \"x1\",\n      x2: \"x2\",\n      y: 0,\n      height: 24,\n      fill: d =&gt; d.which === \"Rain\" ? \"var(--brand-teal)\" : \"var(--brand-red)\",\n      fillOpacity: d =&gt; d.which === \"Rain\" ? 0.35 : 0.15,\n      stroke: \"var(--brand-fg)\"\n    }),\n    // labels\n    Plot.text(umbrellaSegments, {\n      x: d =&gt; (d.x1 + d.x2) / 2,\n      y: 0,\n      text: \"label\",\n      dy: -8\n    })\n  ]\n})\n\n\n\n\n\n\n\n\nFigure 6.1: Everyday uncertainty — a 70% chance of rain means our belief favours rain over no rain given current information.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.2 (Exam Marks) Suppose \\theta is the average exam mark of a module. From past years, we believe:\n\nIt’s usually around 60 marks,\nbut could reasonably be anywhere between 50 and 70.\n\nWe could represent this belief as a Normal prior distribution centred at 60 with standard deviation 10.\n\n   Show Plot \n\nmarkDomain = [0, 100]\nmarkXs = d3.scaleLinear().domain(markDomain).ticks(400)\n\n// Normal PDF helper\nfunction normalPDF(x, mu, sigma){\n  const z = (x - mu) / sigma;\n  return Math.exp(-0.5 * z * z) / (sigma * Math.sqrt(2 * Math.PI));\n}\n\n// Prior parameters and curve\nmu_prior = 60\nsd_prior = 10\n\nmarkPrior = markXs.map(x =&gt; ({ x, y: normalPDF(x, mu_prior, sd_prior), which: \"Prior  N(60, 10²)\" }))\n\n// Shading bounds for \"plausible\" 50–70 region\nloBand = 50\nhiBand = 70\nbandFill = markXs\n  .filter(x =&gt; x &gt;= loBand && x &lt;= hiBand)\n  .map(x =&gt; ({ x, y: normalPDF(x, mu_prior, sd_prior) }))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot.plot({\n  height: 320,\n  marginLeft: 48,\n  marginBottom: 45,\n  x: { label: \"Average mark θ\", domain: markDomain },\n  y: { label: \"Density\" },\n  style: {\n    width: \"100%\",\n    display: \"block\", \n    margin: \"0 auto\", \n    maxWidth: \"960px\",\n    background: \"var(--brand-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont, \n    fontSize: 12\n  },\n  marks: [\n    Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n    // shade the 50–70 plausible band\n    Plot.areaY(bandFill, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\", fillOpacity: 0.12 }),\n    // main prior curve\n    Plot.lineY(markPrior, { x: \"x\", y: \"y\", stroke: \"var(--brand-teal)\", strokeWidth: 2 }),\n    // annotations\n    Plot.ruleX([mu_prior], { stroke: \"var(--brand-fg)\", strokeWidth: 2, strokeDasharray: \"3,3\", strokeOpacity: 0.4 }),\n    Plot.text(\n      [\n        { x: mu_prior + 8, y: normalPDF(mu_prior, mu_prior, sd_prior) * 0.99, label: \"Prior mean 60\" },\n        { x: (loBand+hiBand)/2, y: normalPDF((loBand+hiBand)/2, mu_prior, sd_prior) / 3, label: \"Plausible 50–70\" }\n      ],\n      { x: \"x\", y: \"y\", text: \"label\", dy: -10 }\n    )\n  ]\n})\n\n\n\n\n\n\n\n\nFigure 6.2: Prior for the average exam mark. A Normal prior centred at 60 with standard deviation 10 encodes “likely around 60, plausibly 50–70”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.3 (Disease Prevalance) Let \\theta be the proportion of people with a rare condition.\nBefore collecting data, experts might believe \\theta is “probably around 2\\%, but definitely less than 10\\%”.\nWe could express this with a Beta distribution 2.10 prior.\n\n   Show Plot \n\npDomain = [0, 0.12]  // zoom in to show the small probabilities clearly\npXs = d3.scaleLinear().domain(pDomain).ticks(400)\n\n// Beta PDF helper (using log-space for stability)\nfunction logGamma(z){ // Lanczos approximation via d3? keep simple: use Math.lgamma fallback if present; else crude Stirling\n  // Minimal Stirling for teaching visuals (fine for small α,β here)\n  return (z-0.5)*Math.log(z) - z + 0.5*Math.log(2*Math.PI);\n}\nfunction betaLogPDF(x, a, b){\n  if (x &lt;= 0 || x &gt;= 1) return -Infinity;\n  return (a-1)*Math.log(x) + (b-1)*Math.log(1-x) - (logGamma(a)+logGamma(b)-logGamma(a+b));\n}\nfunction betaPDF(x, a, b){\n  const lg = betaLogPDF(x, a, b);\n  return Number.isFinite(lg) ? Math.exp(lg) : 0;\n}\n\n// Prior parameters and curve\nalpha_prior = 2\nbeta_prior  = 98\n\nbetaPrior = pXs.map(x =&gt; ({ x, y: betaPDF(x, alpha_prior, beta_prior), which: \"Prior  Beta(2, 98)\" }))\n\n// Optional “&lt; 10%” visual marker\ncapThreshold = 0.10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot.plot({\n  height: 320,\n  marginLeft: 48,\n  marginBottom: 45,\n  x: { label: \"Prevalence θ\", domain: pDomain },\n  y: { label: \"Density\" },\n  style: {\n    width: \"100%\",\n    display: \"block\", \n    margin: \"0 auto\", \n    maxWidth: \"960px\",\n    background: \"var(--brand-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont, \n    fontSize: 14\n  },\n  marks: [\n    Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n    Plot.lineY(betaPrior, { x: \"x\", y: \"y\", stroke: \"var(--brand-red)\", strokeWidth: 2, strokeOpacity: 0.9 }),\n    Plot.areaY(betaPrior, { x: \"x\", y: \"y\", fill: \"var(--brand-red)\", fillOpacity: 0.15 }),\n    // visual cap at 10%\n    Plot.ruleX([capThreshold], { stroke: \"var(--brand-fg)\", strokeDasharray: \"3,3\", strokeOpacity: 0.6 }),\n    Plot.text(\n      [\n        { x: 0.02, y: betaPDF(0.02, alpha_prior, beta_prior), label: \"Prior mean ≈ 2%\" },\n        { x: capThreshold, y: 0, label: \"10% upper cap (unlikely)\" }\n      ],\n      { x: \"x\", y: \"y\", text: \"label\", dy: -10 }\n    )\n  ]\n})\n\n\n\n\n\n\n\n\nFigure 6.3: Prior for disease prevalence \\theta using a \\mathrm{Beta}(2, 98). This encodes “likely around 2\\%, very unlikely above 10\\%.”\n\n\n\n\n\n\n\n\n\nThis provides a language of degrees of belief: probability distributions describe how plausible different values of \\theta are, given what we know.\n\n\n6.1.2 The Bayesian Inference Procedure\nThe Bayesian approach to inference has three ingredients:\n\nPrior — a probability distribution that captures what we believe about \\theta before seeing the data.\nLikelihood — the distribution of the data \\underline{x} given \\theta.\nPosterior — the updated distribution for \\theta that combines prior information with the evidence from the data.\n\nThe update is performed using Bayes’ theorem (introduced in the next section). Intuitively:\n\n\\text{Posterior} \\;\\; \\propto \\;\\; \\text{Likelihood} \\times \\text{Prior}.\n\nThis equation expresses the central idea: our beliefs about \\theta are revised in light of the observed data.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part2/6-bayes-inference.html#bayes-theorem-for-densities",
    "href": "content/main/part2/6-bayes-inference.html#bayes-theorem-for-densities",
    "title": "6  Bayesian Inference",
    "section": "6.2 Bayes’ Theorem for Densities",
    "text": "6.2 Bayes’ Theorem for Densities\nBayesian inference is named after Bayes’ Theorem 1.2, a general identity in probability theory. For two events A and B, the conditional probability is given by \n\\mathrm{Pr}(A \\mid B) = \\frac{\\mathrm{Pr}(B \\mid A)\\,\\mathrm{Pr}(A)}{\\mathrm{Pr}(B)}.\n This rule is sometimes described as reversing conditioning: it lets us swap the order, turning “B given A” into “A given B,” with a correction for their overall probabilities.\nTo apply this idea in Bayesian inference, we extend it from events to random variables and their densities. Using conditional densities 1.7, \nf_{X \\mid Y}(x \\mid y) = \\frac{f_{XY}(x,y)}{f_Y(y)},\n\nwe arrive at Bayes’ theorem for densities.\n\n\n\n\n\n\n\nTheorem 6.1 (Bayes’ Theorem for Densities.) For random variables X and Y with joint density (or PMF) f(x,y):\n\nf(x \\mid y) = \\frac{f(y \\mid x)\\,f(x)}{f(y)}.\n\n\n\n\n\n\n\n\n\n\n\nNoteProof\n\n\n\n\n\n\nProof 6.1. By the definition of conditional density:\n\nf(x \\mid y) = \\frac{f(x,y)}{f(y)},\n\\qquad\nf(y \\mid x) = \\frac{f(x,y)}{f(x)}.\n\nRearranging the second expression gives f(x,y) = f(y \\mid x) f(x). Substituting this into the first gives\n\nf(x \\mid y) = \\frac{f(y \\mid x) f(x)}{f(y)}.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part2/6-bayes-inference.html#bayes-theorem-in-statistics",
    "href": "content/main/part2/6-bayes-inference.html#bayes-theorem-in-statistics",
    "title": "6  Bayesian Inference",
    "section": "6.3 Bayes’ Theorem in Statistics",
    "text": "6.3 Bayes’ Theorem in Statistics\nOnce we have specified a parameter \\theta, the model tells us the distribution of the data: \nf(\\underline{x} \\mid \\theta).\n\nThis is the likelihood 5 (the joint density/PMF of the observed sample under \\theta).\nOur Bayesian goal is the reverse: to describe the distribution of the parameter given the data: \n\\pi(\\theta \\mid \\underline{x}).\n\nThis is exactly the “reversing conditioning” step that Bayes’ theorem 1.2 makes possible. It takes the likelihood f(\\underline{x}\\mid \\theta) and the prior \\pi(\\theta) and turns them into the posterior \\pi(\\theta \\mid \\underline{x}): \n\\text{Known: } f(\\underline{x}\\mid \\theta)\n\\quad\\;\\; \\xRightarrow[\\text{Bayes’ theorem}]{} \\quad\\;\\;\n\\text{Wanted: } \\pi(\\theta \\mid \\underline{x})\n\n\n\n\n\n\n\nTipRemark (Likelihood vs. Likelihood Function)\n\n\n\n\n\n\nRemark (Likelihood vs. Likelihood Function). Here we use likelihood to mean the joint density/PMF f(\\underline{x}\\mid\\theta) itself.\nWhen viewed as a function of \\theta (with the data fixed), this is the likelihood function 5.1. In this course, we will not stress this distinction further.\n\n\n\n\n\n\n\n\n\n\nImportant 6.1: Notation in Bayesian Statistics\n\n\n\n\n\nBoth frequentist and Bayesian inference involve probability distributions for the data.\n\nIn the frequentist setting we write\n\nX_i \\sim \\mathrm{Distribution}(\\theta),\n\nwhere \\theta is a fixed but unknown parameter.\nIn the Bayesian setting we write\n\nX_i \\mid \\theta \\sim \\mathrm{Distribution}(\\theta),\n\nwhere the conditioning bar \\mid \\theta emphasises that \\theta itself is random, and we are describing the distribution of the data given a particular value of \\theta.\n\nIn both cases, f(x_i \\mid \\theta) denotes the PDF/PMF of the data conditional on \\theta.\n\nThe Bayesian addition: we also introduce probability distributions over the parameter \\theta itself. To emphasise the difference in notation:\n\nPrior distribution (before data): \\pi(\\theta)\nPosterior distribution (after data): \\pi(\\theta \\mid \\underline{x})\n\nIn Bayesian inference there are therefore two distinct kinds of distributions, which our notation keeps separate:\n\nData distributions: f(x \\mid \\theta) describe how the data would look if we knew \\theta.\nParameter distributions: \\pi(\\theta) and \\pi(\\theta \\mid \\underline{x}) describe our uncertainty about \\theta.\n\n\n\n\n\n6.3.1 From Bayes’ theorem to the Posterior\nTo apply Bayes’ theorem 6.1 in statistics we make the identification:\n\nx = \\theta : the parameter, treated as a random variable.\n\ny = \\underline{x} : the observed data.\n\nThis leads directly to the posterior distribution:\n\n\\pi(\\theta \\mid \\underline{x})\n= \\frac{f(\\underline{x} \\mid \\theta)\\,\\pi(\\theta)}{f(\\underline{x})}.\n\n\n\n\n\n\n\n\nDefinition 6.1 (Prior Distribution.) The prior distribution represents our uncertainty about \\theta before observing the data.\nWe denote its density (PDF or PMF) by\n\n\\pi(\\theta).\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 6.2 (Posterior Distribution) The posterior distribution represents our uncertainty about \\theta after observing the data.\nIt is defined by \n\\pi(\\theta \\mid \\underline{x})\n= \\frac{f(\\underline{x} \\mid \\theta)\\,\\pi(\\theta)}{f(\\underline{x})}.\n\n\nThe likelihood f(\\underline{x} \\mid \\theta) is the term where data and parameter appear together; it is this dependence that updates the prior into the posterior.\nThe prior \\pi(\\theta) reflects what we believed about \\theta before seeing the data.\nThe denominator f(\\underline{x}) is a normalising constant ensuring the posterior integrates to 1.\n\n\n\n\n\n\n\n6.3.2 Posteriors in Practice\nWe now work through a simple example to see how this update works.\n\n\n\n\n\n\n\nExample 6.4 (Biased Coin) Let \\theta = \\Pr(\\text{Head}) for a possibly biased coin.\n\nPrior: Before seeing data, we express no preference over \\theta \\in (0,1) by choosing a uniform prior:\n\n\\theta \\sim \\mathrm{Uniform}(0,1) \\equiv \\mathrm{Beta}(1,1),\n\\qquad \\pi(\\theta) = 1 \\text{ for } 0&lt;\\theta&lt;1.\n\nThis prior has mean \\mathrm{E}[\\theta]=0.5.\nData: We toss the coin n=5 times and observe x=1 head.\nPosterior: Bayes’ theorem combines the Binomial likelihood with the prior to give \\pi(\\theta \\mid x).\n\n\n   Solution \nLet X be the number of heads in 5 tosses. Assuming that each coin throw is independent and identically distributed, X is Binomial1: \n    X \\mid \\theta \\sim \\textrm{Bin}(5,\\theta).\n Note that there is only a single observation here: one experiment is “tossing the coin 5 times and seeing how many come up heads”. The probability of observing X=1 is \n    f(x = 1 \\mid \\theta) = 5\\theta(1-\\theta)^4\n If we plot this:\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\n\nset_plot_theme(\"light\")\n\ndef binom_lik(theta):\n    return 5 * theta * (1 - theta) ** 4\n\n\ntheta_grid = np.linspace(0, 1, 200)\nbinom_lik_vals = binom_lik(theta_grid)\n\nplt.figure(figsize=(5,3))\nplt.plot(theta_grid, binom_lik_vals)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Likelihood\")\nplt.title(\"Binomial Likelihood (with $n=5$ and $X=1$)\")\nplt.tight_layout()\nplt.show()  \n\nset_plot_theme(\"dark\")\n\nplt.figure(figsize=(5,3))\nplt.plot(theta_grid, binom_lik_vals)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Likelihood\")\nplt.title(\"Binomial Likelihood (with $n=5$ and $X=1$)\")\nplt.tight_layout()\nplt.show()  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwe see that this favours \\theta around 0.2. In fact, in Example 5.9, we saw that the MLE is \\hat{\\theta} = 0.2.\nOur prior for \\theta was \\pi(\\theta) = 1, for 0 &lt; \\theta &lt; 1. To update our beliefs, by conditioning on the single observation x=2, we use Bayes’ Theorem 6.2: \n    \\pi(\\theta|x=1)=\\frac{\\pi(\\theta)f(x=1|\\theta)}{f(x=1)} = \\frac{1 \\times 5\\theta(1-\\theta)^4}{f(x=1)}, \\quad 0 &lt; \\theta &lt; 1.\n To compute the denominator, f(x=1), we use the law of total probability 1.3:\n\\begin{align*}\nf(x=1) &=\\int_\\Theta\\pi(\\theta)f(x=1\\, |\\,\\theta)\\,d\\theta = \\int_0^1 1\\times 5\\theta(1-\\theta)^4\\,d\\theta \\\\\n&=\\int_0^1 \\theta\\times 5(1-\\theta)^4\\,d\\theta =\\left[-(1-\\theta)^5\\,\\theta\\right]^1_0\n+\\int_0^1 (1-\\theta)^5\\,d\\theta \\\\\n&=0 + \\left[-\\frac{(1-\\theta)^6}{6}\\right]^1_0 =\\frac{1}{6}.\n\\end{align*}\nTherefore, the posterior density is (for 0&lt;\\theta&lt;1):\n\\begin{align*}\n\\pi(\\theta|x=1)&=\\frac{\\pi(\\theta)f(x=1|\\theta)}{f(x=1)} =\\frac{5\\theta(1-\\theta)^4}{1/6}\\\\\n&=30\\,\\theta(1-\\theta)^4 =\\frac{\\theta(1-\\theta)^4}{\\mathrm{B}(2,5)},\\quad\\quad 0&lt;\\theta&lt;1,\n\\end{align*}\nand so the posterior distribution is \\theta|x=1\\sim \\textrm{Beta}(2,5). This distribution has its mode at \\theta=0.2, and mean at \\mathrm{E}[\\theta|x=1]=2/7=0.286.\n\n\n\n\n\nThe main difficulty in calculating the posterior distribution was in obtaining the f(x) term. However, in many cases we can recognise the posterior distribution without the need to calculate this constant term (constant with respect to \\theta). In this example, we can calculate the posterior distribution as\n\\begin{align*}\n\\pi(\\theta|\\underline{x})&\\propto\\pi(\\theta)f(x=1|\\theta) \\\\\n&\\propto 1\\times 5\\theta(1-\\theta)^4,\\quad\\quad 0&lt;\\theta&lt;1  \\\\\n&=k\\theta(1-\\theta)^4,\\quad\\quad 0&lt;\\theta&lt;1.\n\\end{align*}\nAs \\theta is a continuous quantity, what we would like to know is what continuous distribution defined on (0,1) has a probability density function which takes the form k\\theta^{g-1}(1-\\theta)^{h-1}. The answer is the \\textrm{Beta}(g,h) distribution. Therefore, choosing g and h appropriately, we can see that the posterior distribution is \\theta|x=1\\sim \\textrm{Beta}(2,5).\n\nInterpretation:\n\nMost likely value (mode): \\hat{\\theta} \\approx 0.2, the same as the sample proportion 1/5.\nPosterior mean: \\mathrm{E}[\\theta \\mid x] \\approx 0.286, slightly larger than 0.2 because the prior was centred at 0.5.\nUncertainty reduced: the posterior standard deviation shrinks from 0.289 (prior) to 0.160 (posterior).\n\nSo, after seeing the data, our beliefs about \\theta have been updated: we now think small values of \\theta are more plausible, but not as extremely as the raw data alone would suggest.\n\n   Show Plot \n\nmDomain = [0, 1]\npdfXs = d3.scaleLinear().domain(mDomain).ticks(200)  // 201 points including 0 and 1\n\n// PDFs (closed-form)\nfunction priorPDF(x)     { return (x &gt; 0 && x &lt; 1) ? 1 : 0; }\nfunction posteriorPDF(x) { return (x &gt; 0 && x &lt; 1) ? 30 * x * (1 - x) ** 4 : 0; }\n\n// Data (use the scalar x from map!)\nprior = pdfXs.map(x =&gt; ({ x, y: priorPDF(x), which: \"Prior  Beta(1,1)\" }))\npost  = pdfXs.map(x =&gt; ({ x, y: posteriorPDF(x), which: \"Posterior  Beta(2,5)\" }))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Create the plot directly without viewof\nPlot.plot({\n  // omit width to let it be responsive\n  height: 320,\n  marginLeft: 48,\n  marginBottom: 45,\n  x: { label: \"θ\", domain: [0, 1] },\n  y: { label: \"Density\" },\n  style: {\n    width: \"100%\",\n    display: \"block\", \n    margin: \"0 auto\", \n    maxWidth: \"960px\",\n    background: \"var(--brand-bg)\",\n    color: \"var(--brand-fg)\",\n    fontFamily: bodyFont, \n    fontSize: 14\n  },\n  marks: [\n    Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n    Plot.lineY(prior, { x: \"x\", y: \"y\", stroke: \"var(--brand-red)\",  strokeWidth: 2, strokeOpacity: 0.85 }),\n    Plot.areaY(prior, { x: \"x\", y: \"y\", fill: \"var(--brand-red)\", fillOpacity: 0.05 }),\n    Plot.lineY(post,  { x: \"x\", y: \"y\", stroke: \"var(--brand-teal)\", strokeWidth: 2 }),\n    Plot.areaY(post,  { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\", fillOpacity: 0.2 }),\n    Plot.text(\n      [\n        { x: 0.8, y: priorPDF(0.8),     label: \"Prior\" },\n        { x: 0.35, y: posteriorPDF(0.3), label: \"Posterior\" }\n      ],\n      { x: \"x\", y: \"y\", text: \"label\", dy: -8 }\n    )\n  ]\n})\n\n\n\n\n\n\n\n\nFigure 6.4: Prior and posterior distributions for the coin bias parameter \\theta=\\Pr(\\text{Head}) after observing 1 head in 5 tosses. The posterior is more concentrated, reflecting reduced uncertainty about \\theta compared to the uniform prior\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.5 Consider an experiment to determine how good a music expert is at distinguishing between pages from Haydn and Mozart scores. Let \\theta=\\mathrm{Pr}(\\text{correct choice}). Suppose that, before conducting the experiment, we have been told that the expert is very competent. In fact, it is suggested that we should have a prior distribution which has a mode around \\theta=0.95 and for which \\mathrm{Pr}(\\theta&lt;0.8) is very small. We choose \\theta\\sim \\textrm{Beta}(77,5), with probability density function \n\\pi(\\theta)=128107980\\,\\theta^{76}(1-\\theta)^4,\\quad\\quad 0&lt;\\theta&lt;1.\n A graph of this prior density is given as follows:\n\nPythonR\n\n\n\n\nShow code\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\nset_plot_theme(\"light\")\n\n# Beta(α, β) with α=77, β=5  →  π(θ) ∝ θ^(76) (1-θ)^(4)\nalpha, beta = 77, 5\n\n# B(α,β) = Γ(α)Γ(β)/Γ(α+β)  ⇒  1/B = exp(lgamma(α+β) - lgamma(α) - lgamma(β))\n# Note the lgamma function computes the logarithm of the Gamma function.\nbeta_const_inv = math.exp(math.lgamma(alpha + beta) - math.lgamma(alpha) - math.lgamma(beta))\n\ndef beta_pdf(theta):\n    return beta_const_inv * np.power(theta, alpha - 1) * np.power(1 - theta, beta - 1)\n\ntheta_grid = np.linspace(0.0, 1.0, 500)\npdf_values = beta_pdf(theta_grid)\n\nplt.figure(figsize=(7,4))\nplt.plot(theta_grid, pdf_values)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Density\")\nplt.title(rf\"Beta PDF: $\\alpha={alpha}$, $\\beta={beta}$\")\nplt.tight_layout()\nplt.show()\n\nset_plot_theme(\"dark\")\n\nplt.figure(figsize=(7,4))\nplt.plot(theta_grid, pdf_values)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Density\")\nplt.title(rf\"Beta PDF: $\\alpha={alpha}$, $\\beta={beta}$\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Show code\"\n#| fig-align: center\n\nalpha &lt;- 77\nbeta  &lt;- 5\n\n# Normalising constant via log-gamma (works like Python's lgamma)\nbeta_const_inv &lt;- exp(lgamma(alpha + beta) - lgamma(alpha) - lgamma(beta))\n\nbeta_pdf &lt;- function(theta) {\n  beta_const_inv * theta^(alpha - 1) * (1 - theta)^(beta - 1)\n}\n\ntheta_grid &lt;- seq(0, 1, length.out = 500)\npdf_values &lt;- beta_pdf(theta_grid)\n\nplot(theta_grid, pdf_values, type = \"l\",\n     xlab = expression(theta), ylab = \"Density\",\n     main = bquote(\"Beta PDF: \" ~ alpha == .(alpha) ~ \",\" ~ beta == .(beta)))\n\n\n\n\n   Solution \n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.6 Software engineers at Instagram are interested in the click-through rate \\theta of their advertisement recommender.\nThe click-through rate is the proportion of clicks out of the total number of impressions of an online advertisement.\nThe engineers assess the click-through rate by testing their recommender on users of Instagram. They obtain a total of n impressions.\n\nUsing a Beta prior 2.10, quantify your prior beliefs about \\theta.\nAfter running the test, the engineers obtained a total of X=47 successful clicks out of a total of n=10,000 impressions. Using a Binomial model and your prior specified in part (a), obtain the posterior distribution for \\theta.\n\n\n   Solution \na.\nI personally never click on adverts, apart from on accident. I don’t think many people do. So, I believe that the click-through rate \\theta should be close to 0.\nI am not very confident, so I will pick:\n\n\\theta \\sim \\text{Beta}(5,\\,100).\n\nThis prior has mean\n\n\\frac{5}{5+100} \\approx 0.047,\n\nand places the vast majority of its probability mass on values \\theta &lt; 0.1.\n\nb.\nThe data model is\n\nX \\mid \\theta \\sim \\text{Binomial}(n=10000,\\, \\theta), \\qquad X = 47,\n\nwhich has PMF\n\nf(x=47 \\mid \\theta)\n= \\binom{10000}{47} \\theta^{47}(1-\\theta)^{9953}.\n\nUsing Bayes’ theorem:\n\n\\pi(\\theta \\mid x)\n\\;\\propto\\; f(x \\mid \\theta)\\,\\pi(\\theta).\n\nFrom part (a) the prior is\n\n\\pi(\\theta) \\;\\propto\\; \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1},\n\\qquad \\alpha=5, \\;\\beta=100.\n\nTherefore,\n\n\\pi(\\theta \\mid x)\n\\;\\propto\\; \\theta^{47}(1-\\theta)^{9953}\\;\\cdot\\;\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\n\nSimplifying exponents:\n\n\\pi(\\theta \\mid x)\n\\;\\propto\\; \\theta^{(\\alpha+47)-1}(1-\\theta)^{(\\beta+9953)-1}.\n\nThus, the posterior distribution is\n\n\\theta \\mid x \\sim \\text{Beta}(\\alpha+47, \\; \\beta + 9953).\n\nSubstituting \\alpha=5, \\beta=100:\n\n\\theta \\mid X \\sim \\text{Beta}(5+47, \\; 100 + 9953) = \\text{Beta}(52, \\; 10053).\n\n\nInterpretation.\n\nThe posterior mean is\n\n\n\\mathrm{E}[\\theta \\mid X] = \\frac{52}{52+10053} \\approx 0.0052,\n\nwhich is about 0.52% click-through rate.\n\nThe posterior variance is very small because n=10{,}000 is large, so the engineers can be quite confident that \\theta is very close to 0.5%.\n\n\n   Show Plot \n\n\n\nBeta prior and posterior for the Instagram click-through rate parameter \\theta after observing X=47 clicks out of n=10{,}000 impressions. The posterior is sharply concentrated near ~0.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 6.7 (Measuring a particle’s speed) You are attempting to measure the speed of a particle \\theta and quantify the uncertainty in the measurement. The experiment is set up such that the particle travels 1 km and the measurements are the speeds X_i \\mid \\theta for i=1,\\ldots,n in kilometres per second (km/s).\nThere are a multitude of factors that additively result in measurement error for the speed of the particle.\n(a) Using a normal prior, quantify your prior beliefs about \\theta.\n\n  Solution (a)\nSince speed is physically constrained, a normal prior is imperfect because it places mass on the whole real line. For speed we should have 0&lt; \\theta &lt; c, where c=299{,}792 \\text{km/s} (speed of light).\nNonetheless, if we are asked to use a normal prior and have little prior knowledge about the particle type, a weakly informative prior is reasonable, e.g.\n\n\\theta \\sim \\mathcal{N}\\!\\big(1.5\\times 10^5,\\ (4\\times 10^4)^2\\big).\n\nThis concentrates most mass in the physically plausible range while remaining diffuse.\n\n\n(b) Why is a normal distribution appropriate for the likelihood? Write down the likelihood.\n\n  Solution (b)\nBecause many small, additive, independent sources of error contribute to each measurement, the Central Limit Theorem 4.1 motivates\n\nX_i \\mid \\theta \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\theta,\\sigma^2).\n\nHence the likelihood is\n\\begin{align*}\nf(\\underline{x}\\mid \\theta,\\sigma)\n&= (2\\pi)^{-n/2}\\sigma^{-n}\n\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\n\\sum_{i=1}^n (x_i-\\theta)^2\\right\\} \\\\\n&= (2\\pi)^{-n/2}\\sigma^{-n}\n\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\n\\Big(\\sum_{i=1}^n x_i^2 - 2\\theta \\sum_{i=1}^n x_i + n\\theta^2\\Big)\\right\\}.\n\\end{align*}\n\n\n(c) Assuming the standard deviation \\sigma of the measurements is known, derive the posterior under a prior \\theta \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2).\n\n  Solution (c)\nUp to proportionality,\n\nf(\\underline{x}\\mid\\theta,\\sigma)\\ \\propto\\\n\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\\big(n\\theta^2-2n\\bar{x}\\,\\theta\\big)\\right\\},\\qquad\n\\pi(\\theta)\\ \\propto\\\n\\exp\\!\\left\\{-\\frac{1}{2\\sigma_0^2}\\big(\\theta^2-2\\mu_0\\theta\\big)\\right\\}.\n\nMultiplying and completing the square, the posterior is normal with precision (inverse variance)\n\n\\frac{1}{V}=\\frac{n}{\\sigma^2}+\\frac{1}{\\sigma_0^2},\n\\qquad\nM = V\\left(\\frac{n\\bar{x}}{\\sigma^2}+\\frac{\\mu_0}{\\sigma_0^2}\\right).\n\nTherefore,\n\n\\boxed{\\ \\theta\\mid \\underline{x}\\ \\sim\\ \\mathcal{N}(M,V)\\ }.\n\n\n\n(d) Suppose you measured the speed 4 times and obtained (km/s): 306135,\\ 293227,\\ 307985,\\ 301298. Using the prior from (a), set \\sigma=5000 and derive your posterior distribution.\n\n  Solution (d)\nCompute \\bar{x}=(306135+293227+307985+301298)/4=302{,}161.25. With \\mu_0=150{,}000, \\sigma_0^2=(40{,}000)^2, \\sigma^2=(5{,}000)^2, n=4:\n\n\\frac{1}{V}=\\frac{n}{\\sigma^2}+\\frac{1}{\\sigma_0^2}\n=\\frac{4}{25{,}000{,}000}+\\frac{1}{1{,}600{,}000{,}000}\n=1.60625\\times 10^{-7},\n\\quad\nV=\\frac{1}{1.60625\\times 10^{-7}}\\approx 6{,}225{,}681.\n\n\nM = V\\left(\\frac{n\\bar{x}}{\\sigma^2}+\\frac{\\mu_0}{\\sigma_0^2}\\right)\n\\approx 6{,}225{,}681\\left(\\frac{4\\cdot 302{,}161.25}{25{,}000{,}000}+\\frac{150{,}000}{1{,}600{,}000{,}000}\\right)\n\\approx 301{,}569.18.\n\nThus,\n\n\\boxed{\\ \\theta\\mid \\underline{x}\\ \\sim\\ \\mathcal{N}\\!\\big(301{,}569.2,\\ 6{,}225{,}681\\big)\\ }\n\\quad \\text{(i.e., SD } \\approx 2{,}495.1\\text{ km/s)}.\n\n\n\n\n\n\n\n\n6.3.3 Conjugacy\nIn all the examples in Posteriors in Practice 6.3.2, a notable phenomenon occurred:\n\nThe prior distribution \\pi(\\theta)\nThe resulting posterior distribution \\pi(\\theta \\mid \\underline{x})\n\nbelonged to the same family of distributions.\nIn Bayesian inference, this property is called conjugacy, and it allows us to derive posterior distributions in closed form without approximation.\n\n\n\n\n\n\n\nDefinition 6.3 (Conjugate Prior) Suppose f(\\underline{x} \\mid \\theta) is the joint PDF/PMF of the observations.\nA prior distribution for \\theta is said to be conjugate if, after updating with the data, the posterior distribution \\pi(\\theta \\mid \\underline{x}) remains in the same family as the prior \\pi(\\theta).\n\n\n\n\n\n\n\n\n\n\nTipRemark (Why is conjugacy useful?)\n\n\n\n\n\n\nRemark 6.1 (Why is conjugacy useful?). \n\nConjugacy makes Bayesian updating algebraically simple: posterior parameters can often be obtained by just “updating counts” or “adding observations”.\nThis provides intuition for how prior information and data combine, and gives closed-form formulas that are easy to compute.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part2/6-bayes-inference.html#asymptotic-posterior-distribution",
    "href": "content/main/part2/6-bayes-inference.html#asymptotic-posterior-distribution",
    "title": "6  Bayesian Inference",
    "section": "6.4 Asymptotic Posterior Distribution",
    "text": "6.4 Asymptotic Posterior Distribution\nIn frequentist statistics, we saw two important results about the asymptotic 4.2 sampling distribution of estimators:\n\nThe Central Limit Theorem 4.1 showed that the sampling distribution of the sample mean 4.1 is approximately Normal for large n.\nThe Asymptotic Distribution of the MLE 5.3 showed that the sampling distribution of the maximum likelihood estimator is approximately Normal for large n.\n\nA similar phenomenon occurs in Bayesian inference: for large samples, the posterior distribution itself becomes approximately Normal, regardless of the prior (as long as it is not too extreme).\n\n\n\n\n\n\n\nTheorem 6.2 (Bernstein–von Mises) Suppose we have an i.i.d. sample X_1,\\ldots,X_n drawn from the same distribution with PDF/PMF f(x \\mid \\theta) and let \\pi(\\theta \\mid \\underline{X}^{(n)}) denote the posterior distribution for \\theta.\nUnder regularity conditions, as n \\to \\infty the posterior distribution satisfies\n\n\\theta \\mid \\underline{X}^{(n)} \\;\\overset{\\text{approx.}}{\\sim}\n\\mathcal{N}\\!\\Big(\\hat{\\theta}_n,\\, \\mathcal{I}_n(\\theta)^{-1}\\Big),\n\nwhere\n\n\\hat{\\theta}_n is the MLE,\n\\mathcal{I}_n(\\theta) is the Fisher information 5.1 for the whole sample.",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part2/6-bayes-inference.html#footnotes",
    "href": "content/main/part2/6-bayes-inference.html#footnotes",
    "title": "6  Bayesian Inference",
    "section": "",
    "text": "Binomial distribution. If we assume each coin throw C_i is an i.i.d. \\textrm{Bernoulli}(\\theta) trial with a 1 representing a heads landing, and a 0 representing a tails, the total number of heads out of 5 is X = C_1 + C_2 + C_3 + C_4 + C_5. Therefore: \n    X \\mid \\theta \\sim \\textrm{Bin}(5,\\theta).\n↩︎",
    "crumbs": [
      "Part II — Point Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bayesian Inference</span>"
    ]
  },
  {
    "objectID": "content/main/part3/7-freq-interval-estimation.html",
    "href": "content/main/part3/7-freq-interval-estimation.html",
    "title": "7  Frequentist Interval Estimation",
    "section": "",
    "text": "7.1 The Frequentist Perspective\nRecalling the main inference tasks 3.2, we now move from point estimation to interval estimation.\nThe key idea is that instead of giving a single “best guess”1 of a parameter, we want to provide a range of plausible values. In other words, an interval.\nRecall that, for frequentists, the parameter \\theta is fixed but unknown.\nThe randomness comes from the data: if we repeated the experiment many times, we would get different samples, different estimates, and hence different intervals.",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Frequentist Interval Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part3/7-freq-interval-estimation.html#the-frequentist-perspective",
    "href": "content/main/part3/7-freq-interval-estimation.html#the-frequentist-perspective",
    "title": "7  Frequentist Interval Estimation",
    "section": "",
    "text": "Point Estimate: a single statistic \\hat{\\theta}(\\underline{X}).\nInterval estimate: two statistics L(\\underline{X}) and U(\\underline{X}) that form a random interval.\n\n\n\n\n\n\n\n\nDefinition 7.1 (Confidence Interval) A 100(1-\\alpha)\\% confidence interval for \\theta is a random interval \n\\big[L(\\underline{X}),\\; U(\\underline{X})\\big]\n satisfying \n\\mathrm{Pr} \\big(L(\\underline{X}) &lt; \\theta &lt; U(\\underline{X})\\big) = 1 - \\alpha.\n\nThis property is called coverage: in the long run, a proportion 1-\\alpha of such intervals (constructed from repeated experiments) will contain the true \\theta.\n\n\n\n\n\n\nShow Visualisation\n\nbodyFont = getComputedStyle(document.body).fontFamily\n\n// ---------- Mutable state ----------\nmutable rngSeed = 1\nmutable resampleClicks = 0\nmutable resetClicks = 0\n\n// history of z-intervals: array of {L, U, covered}\nmutable ciZHistory = []\n\n// last interval (to archive on next click)\nmutable lastZ = null\n\n\n// ---------- Buttons ----------\nfunction styledButton(label, cls, options = {}) {\n  const el = Inputs.button(label, options);\n  const btn = el.querySelector('button');\n  if (btn) btn.classList.add(cls);\n  return el;\n}\nviewof resample = styledButton(\"Resample\", \"btn-resample\", { reduce: c =&gt; (c ?? 0) + 1 })\nviewof reset    = styledButton(\"Reset\",    \"btn-reset\",    { reduce: c =&gt; (c ?? 0) + 1 })\n\n// ---------- Edge triggers ----------\n{\n  if (reset &gt; resetClicks) {\n    mutable ciZHistory = [];\n    mutable lastZ = null;\n    mutable resetClicks = reset;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  if (resample &gt; resampleClicks) {\n    if (lastZ) {\n      mutable ciZHistory = [...ciZHistory, lastZ];\n    }\n    mutable rngSeed = rngSeed + 1;\n    mutable resampleClicks = resample;\n  }\n  return html``;\n}\n\n\n\n\n\n\n\nqnorm = (p) =&gt; {\n  if (p &lt;= 0 || p &gt;= 1) return NaN;\n  const a = [-3.969683028665376e+01,2.209460984245205e+02,-2.759285104469687e+02,1.383577518672690e+02,-3.066479806614716e+01,2.506628277459239e+00];\n  const b = [-5.447609879822406e+01,1.615858368580409e+02,-1.556989798598866e+02,6.680131188771972e+01,-1.328068155288572e+01];\n  const c = [-7.784894002430293e-03,-3.223964580411365e-01,-2.400758277161838e+00,-2.549732539343734e+00,4.374664141464968e+00,2.938163982698783e+00];\n  const d = [ 7.784695709041462e-03, 3.224671290700398e-01, 2.445134137142996e+00, 3.754408661907416e+00];\n  const plow = 0.02425, phigh = 1 - plow;\n  let q, r, x;\n  if (p &lt; plow) { q = Math.sqrt(-2*Math.log(p));\n    x = (((((c[0]*q+c[1])*q+c[2])*q+c[3])*q+c[4])*q+c[5]) / ((((d[0]*q+d[1])*q+d[2])*q+d[3])*q+1);\n  } else if (phigh &lt; p) { q = Math.sqrt(-2*Math.log(1-p));\n    x = -(((((c[0]*q+c[1])*q+c[2])*q+c[3])*q+c[4])*q+c[5]) / ((((d[0]*q+d[1])*q+d[2])*q+d[3])*q+1);\n  } else { q = p - 0.5; r = q*q;\n    x = (((((a[0]*r+a[1])*r+a[2])*r+a[3])*r+a[4])*r+a[5])*q / (((((b[0]*r+b[1])*r+b[2])*r+b[3])*r+b[4])*r+1);\n  }\n  const erf = x =&gt; { const s=Math.sign(x); x=Math.abs(x); const t=1/(1+0.5*x);\n    const tau=t*Math.exp(-x*x-1.26551223+1.00002368*t+0.37409196*t**2+0.09678418*t**3-0.18628806*t**4+0.27886807*t**5-1.13520398*t**6+1.48851587*t**7-0.82215223*t**8+0.17087277*t**9);\n    return s*(1-tau);\n  };\n  const SQRT2 = Math.SQRT2, SQRT2PI = Math.sqrt(2*Math.PI);\n  const e = 0.5 * (1 + erf(x / SQRT2)) - p;\n  const u = e * SQRT2PI * Math.exp(0.5 * x * x);\n  return x - u / (1 + x * u);\n}\n\n// ---------- Sample + statistics ----------\nX = {\n  const r = d3.randomNormal.source(d3.randomLcg(rngSeed))(controls.trueMu, controls.trueSigma);\n  return d3.range(controls.n).map(r);\n}\nxbar = d3.mean(X)\n\nalpha = controls.alpha\nzcrit = qnorm(1 - alpha/2)\n\n// z–CI for μ (known σ)\nciZ = ({\n  L: xbar - zcrit * (controls.trueSigma / Math.sqrt(controls.n)),\n  U: xbar + zcrit * (controls.trueSigma / Math.sqrt(controls.n))\n})\n\ncovers = (ci, theta) =&gt; (ci.L &lt;= theta && theta &lt;= ci.U);\ncurrentCoveredZ = covers(ciZ, controls.trueMu);\n\n// save current z so *next* resample archives it\n{\n  mutable lastZ = { ...ciZ, covered: currentCoveredZ };\n  return html``; // suppresses any output\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmakeDensityReducer = (total) =&gt; (values, extent) =&gt;\n  values.length / Math.max(1, total) / Math.max(1e-9, extent.x2 - extent.x1);\n\nxExtent = d3.extent(X)\nxPad    = 3 * controls.trueSigma\nxDomain = [xExtent[0] - 0.1*(xPad||1), xExtent[1] + 0.1*(xPad||1)]\n\nbins = d3.bin().domain(xDomain).thresholds(controls.bins)(X);\ndensities = bins.map(b =&gt; (b.length / Math.max(1, controls.n)) / Math.max(1e-9, (b.x1 - b.x0)));\nyMax = Math.max(0.05, d3.max(densities) ?? 0.05);\nyCI  = yMax * 0.75\n\nleftPlot = Plot.plot({\n  width: Math.min(680, Math.max(360, width/2 - 20)),\n  height: 340,\n  style: { background: \"var(--plot-panel-bg)\",\n           color: \"var(--brand-fg)\",\n           fontFamily: bodyFont, \n           fontSize: 14.\n  }, \n  x: { label: \"Data\", domain: xDomain },\n  y: { label: \"Density\" },\n  marks: [\n    Plot.rectY(X, Plot.binX({ y: makeDensityReducer(controls.n) }, { x: d=&gt;d, thresholds: controls.bins, inset: 0, fillOpacity: 0.4, fill: \"var(--brand-teal)\" })),\n    Plot.ruleX(X, { y1: 0, y2: yMax*0.05, stroke: \"var(--brand-teal)\", strokeWidth: 3, strokeOpacity: 1 }),\n    Plot.ruleX([controls.trueMu], { stroke: \"var(--brand-purple)\", strokeDasharray: \"4,3\", strokeWidth: 2 }),\n    Plot.ruleX([xbar], { stroke: \"currentColor\", strokeDasharray: \"2,2\" }),\n    Plot.dot([{x:xbar,y:0}], {x:\"x\",y:\"y\", r:3, fill:\"currentColor\"}),\n\n    // current z–CI (horizontal link)\n    Plot.link([{x1:ciZ.L, x2:ciZ.U, y1:yCI, y2:yCI}],\n      { x1:\"x1\", x2:\"x2\", y1:\"y1\", y2:\"y2\", stroke:\"var(--brand-orange)\", strokeWidth:4 }),\n    Plot.dot([{x:xbar,y:yCI}], {x:\"x\", y:\"y\", r:3, fill:\"var(--brand-orange)\"}),\n    Plot.text([{x:(ciZ.L+ciZ.U)/2, y:yCI + 0.05*yMax, label:`CI (${((1-alpha)*100)|0}%)`}],\n      {x:\"x\",y:\"y\",text:\"label\", dy:-4, fontSize:10, fill:\"var(--brand-orange)\"}),\n\n    Plot.ruleY([0])\n  ]\n})\n\n// ---------- Right panel: history as vertical z-CI segments ----------\nzHistory   = ciZHistory\nindices    = d3.range(1, zHistory.length + 1)\ncoverageZ  = zHistory.length ? d3.mean(zHistory, d =&gt; d.covered) : NaN\n\nrightYDomain = (() =&gt; {\n  const vals = [\n    controls.trueMu,\n    ...zHistory.flatMap(d =&gt; [d.L, d.U]),\n    ciZ.L, ciZ.U\n  ];\n  const lo = d3.min(vals), hi = d3.max(vals);\n  const pad = 0.08 * (hi - lo || 1);\n  return [lo - pad, hi + pad];\n})()\n\nrightPlot = Plot.plot({\n  width: Math.min(680, Math.max(360, width/2 - 20)),\n  height: 340,\n  style: { background: \"var(--plot-panel-bg)\",\n           color: \"var(--brand-fg)\",\n           fontFamily: bodyFont, \n           fontSize: 14.\n  }, \n  x: { label: \"Number of samples taken\", domain: [0.5, Math.max(1.5, indices.length + 1.5)] },\n  y: { label: \"μ\", domain: rightYDomain },\n  marks: [\n    Plot.ruleY([controls.trueMu], { stroke: \"var(--brand-purple)\", strokeDasharray: \"4,3\", strokeWidth: 2 }),\n\n    // archived z-CIs\n    Plot.ruleX(zHistory.map((d,i)=&gt;({x:i+1, y1:d.L, y2:d.U, covered:d.covered})),\n               { x:\"x\", y1:\"y1\", y2:\"y2\", stroke:(d)=&gt; d.covered ? \"var(--brand-orange)\" : \"#999\", strokeWidth: 3, opacity: 0.9 }),\n\n    // current interval (ghosted) at the next x-position\n    Plot.ruleX([{x:indices.length+1, y1:ciZ.L, y2:ciZ.U}],\n               { x:\"x\", y1:\"y1\", y2:\"y2\", stroke:\"var(--brand-orange)\", strokeWidth: 3, strokeOpacity:0.4 }),\n\n    // coverage text\n    Plot.text(\n      [{x: 0.7, y: rightYDomain[1], label: `z-CI coverage: ${isNaN(coverageZ) ? \"—\" : `${(100*coverageZ).toFixed(0)}%`} (${zHistory.length})`}],\n      {x:\"x\", y:\"y\", text:\"label\", dx: 4, dy: 4, textAnchor: \"start\", fontSize: 11}\n    )\n  ]\n})\n\n{\n  // Make the forms behave nicely in the grid\n  for (const f of [viewof resample, viewof reset]) {\n    f.style.margin = \"0\";\n    f.style.width = \"100%\";\n    f.style.maxWidth = \"none\";\n    f.style.display = \"flex\";\n  }\n  viewof resample.style.justifyContent = \"flex-start\";\n  viewof reset.style.justifyContent    = \"flex-end\";\n\n  return html`&lt;div class=\"ojs-toolbar-grid\"&gt;\n    &lt;div class=\"left\"&gt;${viewof resample}&lt;/div&gt;\n      &lt;div class=\"center\"&gt;\n        ${md`${tex`\\big[L(\\underline{X}),\\, U(\\underline{X})\\big] = \\big[${ciZ.L.toFixed(2)},\\; ${ciZ.U.toFixed(2)}\\big]`}`}\n      &lt;/div&gt;\n    &lt;div class=\"right\"&gt;${viewof reset}&lt;/div&gt;\n  &lt;/div&gt;\n\n  &lt;style&gt;\n    .ojs-toolbar-grid{\n      display:grid;\n      grid-template-columns:1fr auto 1fr; /* left, middle, right */\n      align-items:center;\n      width:100%;\n      box-sizing:border-box;\n      margin:0; padding:0;\n    }\n    .ojs-toolbar-grid form{\n      margin:0 !important;\n      width:100% !important;\n      max-width:none !important;\n      display:flex !important;\n    }\n    .ojs-toolbar-grid .left  form{ justify-content:flex-start !important; }\n    .ojs-toolbar-grid .right form{ justify-content:flex-end   !important; }\n\n    .btn.btn-resample{ background: var(--brand-teal); color:#fff; border:none; }\n    .btn.btn-resample:hover{ background: var(--brand-teal-hover); }\n    .btn.btn-reset{ background: var(--brand-red); color:#fff; border:none; }\n    .btn.btn-reset:hover{ background: var(--brand-red-hover); }\n    .btn.btn-resample:focus-visible,\n    .btn.btn-reset:focus-visible{\n      outline: 2px solid currentColor;\n      outline-offset: 2px;\n    }\n\n    .ojs-toolbar-grid .center{\n      text-align:center;\n      font-size:0.9rem;\n      color: var(--brand-fg);\n    }\n  &lt;/style&gt;`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div style=\"max-width:100%; display:flex; gap:14px; align-items:flex-start; flex-wrap:nowrap;\"&gt;\n  &lt;div&gt;${leftPlot}&lt;/div&gt;\n  &lt;div&gt;${rightPlot}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\nhtml`&lt;style&gt;\ndetails.controls-root &gt; summary {\n  list-style: none; cursor: pointer; user-select: none;\n  background: var(--surface);\n  border: 1px solid var(--border);\n  border-radius: 10px;\n  padding: 8px 10px;\n  font-weight: 600; font-size: 13px;\n  color: var(--fg-strong);\n  display: flex; align-items: center; gap: 8px;\n}\n/* ---------- Compact Inputs (fixed slider alignment) ---------- */\n.controls-col label { font-size: 12px !important; }\n\ndetails.controls-root &gt; summary::-webkit-details-marker { display: none; }\ndetails.controls-root[open] &gt; summary { border-bottom-left-radius: 0; border-bottom-right-radius: 0; }\ndetails.controls-root &gt; summary::before {\n  content: \"\"; display: inline-block; margin-right: 8px; width: 0; height: 0;\n  border-style: solid; border-width: 3px 0 3px 6px;\n  border-color: transparent transparent transparent var(--fg-strong);\n  transform: rotate(0deg); transform-origin: 3px 50%; transition: transform 60ms ease;\n}\ndetails.controls-root[open] &gt; summary::before { transform: rotate(90deg); }\n.controls-grid {\n  display: grid;\n  grid-template-columns: minmax(260px,1fr) minmax(260px,1fr);\n  gap: 12px;\n  border: 1px solid var(--border); border-top: none;\n  border-bottom-left-radius: 10px; border-bottom-right-radius: 10px;\n  padding: 10px;\n  background: var(--surface-weak);\n}\n.controls-col { min-width: 260px; }\n.controls-col h4 {\n  margin: 0 0 6px 0; font-size: 12px; font-weight: 700;\n  color: var(--fg-muted);\n}\n.controls-col input[type=\"range\"]{ width:100%; accent-color: var(--brand-teal,#55C3CB); }\n\n/* Toolbar + buttons */\n.btn.btn-resample{ background: var(--brand-teal); color:#fff; border:none; padding:6px 10px; border-radius:8px;}\n.btn.btn-resample:hover{ background: var(--brand-teal-hover,#4da2a8); }\n.btn.btn-reset{ background: var(--brand-red,#e65660); color:#fff; border:none; padding:6px 10px; border-radius:8px;}\n.btn.btn-reset:hover{ background: var(--brand-red-hover,#bd4a52); }\n.toolbar{ display:grid; grid-template-columns:1fr auto 1fr; align-items:center; gap:8px; margin: 6px 0 10px; }\n.toolbar .left form{ display:flex; justify-content:flex-start; margin:0 }\n.toolbar .right form{ display:flex; justify-content:flex-end;   margin:0 }\n.toolbar .center{ text-align:center; font-size:0.9rem; color:var(--brand-fg) }\n\n/* Plots container: force side-by-side; scroll if too narrow */\n.ci-row {\n  display: flex; gap: 14px; align-items: flex-start;\n  flex-wrap: nowrap; overflow-x: auto; max-width: 100%;\n}\n.ci-panel { flex: 0 0 50%; min-width: 460px; }\n&lt;/style&gt;`\n\n\n\n\n\n\n\nviewof controls = {\n  const left = Inputs.form({\n    n: Inputs.range([2, 400], { value: 20, step: 1, label: md`${tex`n`}` }),\n    trueMu: Inputs.range([-2, 2], { value: 0, step: 0.1, label: md`${tex`\\mu_{\\text{true}}`}` }),\n    trueSigma: Inputs.range([0.3, 3], { value: 1, step: 0.1, label: md`${tex`\\sigma\\ \\text{(known)}`}` })\n  }, { submit: false });\n\n  const right = Inputs.form({\n    alpha: Inputs.range([0.01, 0.2], { value: 0.05, step: 0.01, label: md`${tex`\\alpha\\ \\text{(1−}\\alpha\\text{ confidence)}`}` }),\n    bins: Inputs.range([10, 60], { value: 24, step: 1, label: \"Histogram bins\" })});\n\n  const root = html`&lt;details class=\"controls-root\" open&gt;\n    &lt;summary&gt;Simulation controls&lt;/summary&gt;\n    &lt;div class=\"controls-grid\"&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Data & truth&lt;/h4&gt;&lt;/div&gt;\n      &lt;div class=\"controls-col\"&gt;&lt;h4&gt;Confidence level & display&lt;/h4&gt;&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/details&gt;`;\n  root.querySelector(\".controls-grid\").children[0].append(left);\n  root.querySelector(\".controls-grid\").children[1].append(right);\n\n  const getValue = () =&gt; ({ ...left.value, ...right.value });\n  const update = () =&gt; { root.value = getValue(); root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true })); };\n  left.addEventListener(\"input\", update);\n  right.addEventListener(\"input\", update);\n  queueMicrotask(update);\n  return root;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant 7.1: Terminology: Exact vs. Approximate Confidence Intervals\n\n\n\nA confidence interval (CI) is a random interval, constructed from the data, that aims to contain the true parameter value with a specified probability (the coverage probability).\n\nExact CI. The coverage probability is exactly equal to the nominal level (e.g. 95\\%). Such intervals are sometimes called well-calibrated. These are rare, but they can be derived in some classical settings (e.g. certain normal models).\nApproximate CI. The coverage probability is only guaranteed asymptotically (typically as n \\to \\infty). In practice, most commonly used intervals are of this type.",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Frequentist Interval Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part3/7-freq-interval-estimation.html#interpreting-confidence-intervals",
    "href": "content/main/part3/7-freq-interval-estimation.html#interpreting-confidence-intervals",
    "title": "7  Frequentist Interval Estimation",
    "section": "7.2 Interpreting Confidence Intervals",
    "text": "7.2 Interpreting Confidence Intervals\nIn practice, we only ever observe one dataset \\underline{x}. So we calculate the observed interval: \n[L_{\\text{obs}}, U_{\\text{obs}}]\n= \\big[L(\\underline{x}), U(\\underline{x})\\big].\n\nOnce the data are observed, this interval is fixed, not random.\nTherefore, a frequentist would not say \n\\mathrm{Pr}(L_{\\text{obs}} &lt; \\theta &lt; U_{\\text{obs}}) = 1 - \\alpha.\n That statement is meaningless, because \\theta is not random in the frequentist view.\nInstead, the correct interpretation is: our method has long-run coverage 1-\\alpha.",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Frequentist Interval Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part3/7-freq-interval-estimation.html#sec-exact-ci",
    "href": "content/main/part3/7-freq-interval-estimation.html#sec-exact-ci",
    "title": "7  Frequentist Interval Estimation",
    "section": "7.3 Exact Confidence Intervals",
    "text": "7.3 Exact Confidence Intervals\nBefore turning to specific examples, it is useful to outline the general strategy for constructing an exact confidence intervals 7.1.\n\n7.3.1 General Recipe\n\nChoose an estimator. Start with an estimator \\hat{\\theta}=\\hat{\\theta}(X_1,\\ldots,X_n) for the parameter of interest \\theta.\nIdentify its sampling distribution. For exact intervals, the exact distribution of \\hat{\\theta} under the model must be known.\nForm a pivotal quantity. Construct a function Z=Z(\\underline{X},\\theta) whose distribution does not depend on any unknown parameters. Such a Z is called a pivot.\nUse quantiles of the pivot. From the known distribution of Z, find constants a,b such that\n\n\\operatorname{Pr}\\!\\big(a \\leq Z \\leq b\\big) = 1-\\alpha.\n\nInvert the inequalities. Solve a \\leq Z(\\underline{X},\\theta) \\leq b for \\theta. The result is an exact (1-\\alpha) confidence interval for \\theta.\n\n\n\n\n\n\n\nWarningNon-Examinable Content\n\n\n\nThis general strategy for constructing exact confidence intervals is not examinable. In particular, you do not need to remember the term pivot.\n\n\n\n\n7.3.2 The Normal Case (Known Variance)\nLet’s apply the general strategy 7.3.1 to construct an exact confidence interval for the mean of a normal distribution with known variance.\nSuppose we observe a normal random sample:\n\nX_i \\sim \\mathcal{N}(\\mu, \\sigma^2), \\quad i=1,\\dots,n.\n\n\nChoose an estimator. Use the sample mean:\n\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\nIdentify its sampling distribution. Since the X_i are normal, \n\\bar{X} \\sim \\mathcal{N}\\!\\left(\\mu, \\tfrac{\\sigma^2}{n}\\right).\n\nForm a pivotal quantity. Standardise to remove dependence on \\mu:\n\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0,1).\n\nUse quantiles of the pivot. For the standard normal,\n\n\\Pr\\!\\left(-z_{1-\\alpha/2} \\leq Z \\leq z_{1-\\alpha/2}\\right) = 1-\\alpha,\n\nwhere z_{1-\\alpha/2} is the (1-\\alpha/2) quantile.\nInvert the inequalities. Substituting Z and rearranging gives\n\n\\Pr\\!\\left(\\bar{X} - z_{1-\\alpha/2}\\,\\tfrac{\\sigma}{\\sqrt{n}} \\;\\leq\\; \\mu \\;\\leq\\; \\bar{X} + z_{1-\\alpha/2}\\,\\tfrac{\\sigma}{\\sqrt{n}}\\right) = 1-\\alpha.\n\n\nTherefore, an exact (1-\\alpha) confidence interval for \\mu is\n\n\\mu \\in \\Bigl[\\bar{X} - z_{1-\\alpha/2}\\,\\tfrac{\\sigma}{\\sqrt{n}}, \\;\\; \\bar{X} + z_{1-\\alpha/2}\\,\\tfrac{\\sigma}{\\sqrt{n}}\\Bigr],\n\nor equivalently,\n\n\\bar{X} \\;\\pm\\; z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\n\n\n\n\n\n\n\nDefinition 7.2 (Confidence Interval for the Normal Mean (Known Variance)) Suppose X_1,\\dots,X_n \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2) with known variance \\sigma^2. Then an exact (1-\\alpha) confidence interval for \\mu is\n\n\\mu \\;\\in\\;\n\\left[\n\\bar{X} - z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}, \\;\\;\n\\bar{X} + z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\right],\n\nor equivalently\n\n\\bar{X} \\;\\pm\\; z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}},\n\nwhere\n\n\\bar{X} is the sample mean 4.1, and\nz_{1-\\alpha/2} is the (1-\\alpha/2) quantile of the standard Normal distribution \\mathcal{N}(0,1).\n\n\n\n\n\n\n\n\n\n\n\nTipRemark (Quantiles of the pivot)\n\n\n\n\n\n\nRemark 7.1 (Quantiles of the pivot). When constructing a confidence interval from a pivot, the choice of quantiles is not unique.\n\nIn the symmetric case, we use\n\n\\Pr\\!\\left(-z_{1-\\alpha/2} \\leq Z \\leq z_{1-\\alpha/2}\\right) = 1-\\alpha,\n\nwhich gives the familiar two-sided interval.\nBut we could instead use any pair of quantiles z_{\\alpha_1}, z_{1-\\alpha_2} with \\alpha_1+\\alpha_2=\\alpha:\n\n\\Pr\\!\\left(z_{\\alpha_1} \\leq Z \\leq z_{1-\\alpha_2}\\right) = 1-\\alpha.\n\nAs a special case, a one-sided interval arises from\n\n\\Pr\\!\\left(Z \\leq z_{1-\\alpha}\\right) = 1-\\alpha.\n\n\nThe symmetric interval is usually preferred because it places equal probability mass in both tails, making it “balanced” around the estimator. This choice minimises the interval length for symmetric distributions (like the normal), which is why it is standard.\n\n\n\n\n\n\n\n\n\n\n\nExample 7.1 (Archaeology and Skeleton Lengths: CI with Known Variance) An archaeologist found preserved in a peat bog the skeletons of 30 adult males from an unknown human population. She is interested in skeleton lengths.\nThe sample mean is \\bar{x} = 161.72 cm. Assume that the skeleton lengths come from a \\mathcal{N}(\\mu, \\sigma^2) distribution.\nFurther, measurements from other human populations at the time suggest that it is reasonable to assume the population variance is \\sigma^2 = 100 \\ \\text{cm}^2.\n\nConstruct 95\\% and 99\\% confidence intervals for \\mu.\n\nHow many skeletons would be needed to ensure that the width of a 95\\% confidence interval for \\mu is no greater than 4 cm?\n\n\n   Solution \nStep 1. Confidence intervals for \\mu.\nWe have \\bar{x} = 161.72, n=30, \\sigma = 10.\nFor a confidence interval, the formula is \n\\bar{x} \\;\\pm\\; z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\n\nFor 95\\% confidence, z_{0.05/2} = 1.96:\n\n161.72 \\pm 1.96 \\cdot \\frac{10}{\\sqrt{30}}\n= 161.72 \\pm 3.578\n= (158.14, \\ 165.30).\n\nFor 99% confidence, z_{0.01/2} = 2.576:\n\n161.72 \\pm 2.576 \\cdot \\frac{10}{\\sqrt{30}}\n= 161.72 \\pm 4.703\n= (157.02, \\ 166.42).\n\n\n\nStep 2. Required sample size for desired width.\nThe width of a 95% CI is \n\\text{Width} = 2 \\cdot z_{0.05/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n= 2 \\cdot 1.96 \\cdot \\frac{10}{\\sqrt{n}}.\n\nWe want this \\leq 4: \n2 \\cdot 1.96 \\cdot \\frac{10}{\\sqrt{n}} \\leq 4\n\\quad \\Rightarrow \\quad\n\\sqrt{n} \\geq \\frac{2 \\cdot 1.96 \\cdot 10}{4} = 9.8.\n\nSo \nn \\geq (9.8)^2 = 96.04.\n\nTherefore, at least 97 skeletons are needed.\n\n\n\n\n\n\n\n7.3.3 The Normal Case (Unknown Variance)\nLet’s apply the general strategy 7.3.1 to construct an exact confidence interval for the mean of a normal distribution when the variance is unknown.\nSuppose we observe a normal random sample with unknown mean and variance:\n\nX_i \\sim \\mathcal{N}(\\mu, \\sigma^2), \\quad i=1,\\dots,n.\n\nSince \\sigma^2 is unknown, we estimate it using the sample variance 4.2:\n\nS^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X})^2.\n\n\n\nAside: The Student’s t Distribution\n\nThe Student-t 2.8 distribution was discovered in 1908 by William Sealy Gosset, who published under the pseudonym “Student”.\nIt arises when we replace the (unknown) variance \\sigma^2 in a Normal problem with its estimate from the data. Formally,\n\nT = \\frac{Z}{\\sqrt{U/\\nu}},\n\\quad Z \\sim \\mathcal{N}(0,1), \\;\\; U \\sim \\chi^2_\\nu,\n\nwhere Z and U are independent.\nThe t distribution looks very similar to the standard Normal, but has heavier tails - this accounts for the extra uncertainty caused by estimating \\sigma^2.\nAs the degrees of freedom (\\nu \\to \\infty), the t distribution becomes almost indistinguishable from \\mathcal{N}(0,1).\n\n\n   Show Visualisation \n\nfunction tPDF(x, nu) {\n  const B = Math.sqrt(nu * Math.PI) * gamma(nu/2) / gamma((nu+1)/2);\n  return Math.pow(1 + x*x/nu, -(nu+1)/2) / B;\n}\n\n// Gamma function (simplified approximation)\nfunction gamma(z) {\n  const g = 7;\n  const p = [0.99999999999980993, 676.5203681218851, -1259.1392167224028,\n             771.32342877765313, -176.61502916214059, 12.507343278686905,\n             -0.13857109526572012, 9.9843695780195716e-6, 1.5056327351493116e-7];\n  \n  if (z &lt; 0.5) return Math.PI / (Math.sin(Math.PI * z) * gamma(1 - z));\n  \n  z -= 1;\n  let x = p[0];\n  for (let i = 1; i &lt; g + 2; i++) x += p[i] / (z + i);\n  \n  const t = z + g + 0.5;\n  return Math.sqrt(2 * Math.PI) * Math.pow(t, z + 0.5) * Math.exp(-t) * x;\n}\n\n// Student t CDF using numerical integration (Simpson's rule)\nfunction tCDF(t, nu) {\n  if (t === 0) return 0.5;\n  \n  const n = 1000; // number of intervals\n  const a = t &lt; 0 ? t : 0;\n  const b = t &lt; 0 ? 0 : t;\n  const h = (b - a) / n;\n  \n  let sum = tPDF(a, nu) + tPDF(b, nu);\n  \n  for (let i = 1; i &lt; n; i++) {\n    const x = a + i * h;\n    sum += (i % 2 === 0 ? 2 : 4) * tPDF(x, nu);\n  }\n  \n  const integral = (h / 3) * sum;\n  \n  // For negative t, subtract from 0.5; for positive t, add to 0.5\n  return t &lt; 0 ? Math.max(0, integral) : 0.5 + integral;\n}\n\n// Helper function for linspace\nfunction linspace(start, end, n = 100) {\n  const step = (end - start) / (n - 1);\n  return Array.from({length: n}, (_, i) =&gt; start + i * step);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof t_nu = Inputs.range([1, 40], { value: 5, step: 1})\nviewof t_value = Inputs.range([-5, 5], { value: 1.5, step: 0.001 })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Plot cell: reads t_nu, t_value; returns plot + math; NO sliders embedded here\n{\n  const ν = Math.round(t_nu);\n  const t = t_value;\n\n  const xPoints = linspace(-5, 5, 300);\n  const pdfData = xPoints.map(x =&gt; ({ x, y: tPDF(x, ν) }));\n  const fillData = xPoints.filter(x =&gt; x &lt;= t).map(x =&gt; ({ x, y: tPDF(x, ν) }));\n  const yAtT = tPDF(t, ν);\n  const cdfValue = tCDF(t, ν);\n\n  const rightMath = md`**CDF:** ${tex`\\mathrm{Pr}(T \\leq ${t.toFixed(3)}) = ${cdfValue.toFixed(6)}`}`;\n\n  const plot = Plot.plot({\n    width: Math.min(960, width),\n    height: 320,\n    marginBottom: 50,\n    style: { background: \"var(--brand-bg)\", color: \"var(--brand-fg)\", fontFamily: bodyFont, fontSize: 14 },\n    y: { label: \"PDF\", domain: [0, Math.max(...pdfData.map(d =&gt; d.y)) * 1.1] },\n    x: { label: \"x\", domain: [-6, 6] },\n    marks: [\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n      Plot.areaY(fillData, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\", fillOpacity: 0.4 }),\n      Plot.lineY(pdfData, { x: \"x\", y: \"y\", stroke: \"var(--brand-teal)\", strokeWidth: 2 }),\n      Plot.ruleX([{ x: t, y1: 0, y2: yAtT }], { x: \"x\", y1: \"y1\", y2: \"y2\", stroke: \"var(--brand-fg)\", strokeWidth: 2, strokeDasharray: \"5,3\" }),\n      Plot.dot([{ x: t, y: yAtT }], { x: \"x\", y: \"y\", r: 4, fill: \"var(--brand-fg)\" }),\n      Plot.text([{ x: t, y: 0 }], { x: \"x\", y: \"y\", text: d =&gt; `CDF = ${cdfValue.toFixed(3)}`, dy: -10, dx: t &gt; 3 ? -40 : 40, fontSize: 12, fill: \"var(--brand-fg)\" })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"top-math-row\"&gt;&lt;div class=\"math\"&gt;${rightMath}&lt;/div&gt;&lt;/div&gt;\n    &lt;div class=\"plot-wrapper\"&gt;${plot}&lt;/div&gt;\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nhtml`&lt;div class=\"controls-row\"&gt;\n  &lt;div class=\"control-inline\"&gt;&lt;span class=\"label\"&gt;${tex`\\nu`}&lt;/span&gt;${viewof t_nu}&lt;/div&gt;\n  &lt;div class=\"control-inline\"&gt;&lt;span class=\"label\"&gt;${tex`t`}&lt;/span&gt;${viewof t_value}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n// Styling\nhtml`&lt;style&gt;\n.dist-panel {\n  width: 100%;\n  max-width: 960px;\n  margin: 0 auto;\n  text-align: center;\n}\n\n/* Center the math text */\n.top-math-row .math {\n  display: inline-block;\n  margin-bottom: 12px;\n  text-align: center;\n  background: var(--header-bg);\n  padding: 8px 12px;\n  border-radius: 6px;\n}\n\n/* Center plot */\n.plot-wrapper {\n  display: flex;\n  justify-content: center;\n  margin-bottom: 12px;\n}\n\n/* Two columns that are allowed to shrink */\n.controls-row {\n  display: grid;\n  grid-template-columns: minmax(0, 1fr) minmax(0, 1fr);\n  gap: 12px 16px;\n  max-width: 800px;\n  margin: 0 auto;\n}\n\n/* Inline label + slider; allow shrinking */\n.control-inline {\n  display: flex;\n  flex-direction: row;\n  align-items: center;\n  gap: 8px;\n  min-width: 0;            /* critical: let this flex item shrink */\n}\n\n/* Keep math label tidy */\n.control-inline .label {\n  white-space: nowrap;\n  min-width: 2ch;\n}\n\n/* The viewof wrapper is a &lt;form&gt;; let it flex and shrink */\n.control-inline form {\n  flex: 1 1 auto;\n  min-width: 0;            /* critical: allow the form to shrink */\n}\n\n/* Make the actual slider fill the row */\n.control-inline input[type=\"range\"] {\n  width: 100%;\n  max-width: 100%;\n  box-sizing: border-box;\n}\n\n/* Stack on small screens */\n@media (max-width: 640px) {\n  .controls-row {\n    grid-template-columns: 1fr;\n  }\n}\n\n&lt;/style&gt;`\n\n\n\n\n\n\n\n// Add custom CSS for the slider styling (without the details.controls-root requirement)\nhtml`&lt;style&gt;\n/* Style all range sliders in the document */\ninput[type=\"range\"] {\n  /* Reset browser defaults */\n  -webkit-appearance: none;\n  appearance: none;\n  \n  /* Layout */\n  width: 100%;\n  height: 18px;\n  background: transparent;\n  vertical-align: middle;\n  \n  /* Brand theming */\n  accent-color: var(--ctrl-brand);\n}\n\n\n/* Center the slider container */\nform:has(input[type=\"range\"]) {\n  margin: 0 auto;\n  max-width: 600px; /* Adjust as needed */\n  padding: 10px 0;\n}\n\n/* Slider track - WebKit */\ninput[type=\"range\"]::-webkit-slider-runnable-track {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n\n/* Slider thumb - WebKit */\ninput[type=\"range\"]::-webkit-slider-thumb {\n  -webkit-appearance: none;\n  appearance: none;\n  \n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  border: 0;\n  background: var(--ctrl-brand, #667eea);\n  \n  /* Center thumb over 4px track */\n  margin-top: -4px;\n}\n\n/* Slider track - Firefox */\ninput[type=\"range\"]::-moz-range-track {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n\n/* Slider thumb - Firefox */\ninput[type=\"range\"]::-moz-range-thumb {\n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  border: 0;\n  background: var(--ctrl-brand, #667eea);\n}\n\n/* Firefox progress styling */\ninput[type=\"range\"]::-moz-range-progress {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n&lt;/style&gt;`\n\n\n\n\n\n\n\n\n\nChoose an estimator. Use the sample mean:\n\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\nIdentify its sampling distribution. As before,\n\n\\bar{X} \\sim \\mathcal{N}\\!\\left(\\mu, \\tfrac{\\sigma^2}{n}\\right).\n\nBut now \\sigma^2 is unknown and must be estimated by S^2.\nForm a pivotal quantity. Standardise using S:\n\nT = \\frac{\\bar{X} - \\mu}{S/\\sqrt{n}}.\n\nIt can be shown (using \\chi^2 theory and independence between \\bar{X} and S^2) that\n\nT \\sim t_{n-1}.\n\nUse quantiles of the pivot. For the t distribution with n-1 degrees of freedom,\n\n\\Pr\\!\\left(-t_{n-1,\\,1-\\alpha/2} \\leq T \\leq t_{n-1,\\,1-\\alpha/2}\\right) = 1-\\alpha,\n\nwhere t_{n-1,\\,1-\\alpha/2} is the (1-\\alpha/2) quantile.\nInvert the inequalities. Substituting T and rearranging gives\n\n\\Pr\\!\\left(\\bar{X} - t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}} \\;\\leq\\; \\mu \\;\\leq\\; \\bar{X} + t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}}\\right) = 1-\\alpha.\n\n\nTherefore, an exact (1-\\alpha) confidence interval for \\mu is\n\n\\mu \\in \\Bigl[\\bar{X} - t_{n-1,\\,1-\\alpha/2}\\,\\tfrac{S}{\\sqrt{n}}, \\;\\; \\bar{X} + t_{n-1,\\,1-\\alpha/2}\\,\\tfrac{S}{\\sqrt{n}}\\Bigr],\n\nor equivalently,\n\n\\bar{X} \\;\\pm\\; t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}}.\n\n\n\n\n\n\n\n\nDefinition 7.3 (Confidence Interval for the Normal Mean (Unknown Variance)) Suppose X_1,\\dots,X_n \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2) with unknown variance \\sigma^2.\nThen an exact (1-\\alpha) confidence interval for \\mu is\n\n\\mu \\;\\in\\;\n\\left[\n\\bar{X} - t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}}, \\;\\;\n\\bar{X} + t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}}\n\\right],\n\nor equivalently\n\n\\bar{X} \\;\\pm\\; t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}},\n\nwhere\n\n\\bar{X} is the sample mean 4.1,\nS^2 is the sample variance 4.2, and\nt_{n-1,1-\\alpha/2} is the (1-\\alpha/2) quantile of the Student’s t distribution with n-1 degrees of freedom.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 7.2 (Archaeology and Skeleton Lengths: CI with Unknown Variance) Continuing with Example 7.1, suppose now that we don’t assume we know the population variance.\nIn addition to the sample mean \\bar{x}=161.72, we also compute the sample variance s^2=86.63.\nProvide the archaelogist with 95\\% and 99\\% confidence intervals for \\mu.\n\n   Solution \nWe need the critical values t_{29,\\,0.975} and t_{29,\\,0.995}.\nFrom using R, Python or the above visualisation with degrees of freedon \\nu = n-1 = 29, we have\n\nt_{29,\\,0.975} = 2.045 \\quad \\text{and} \\quad t_{29,\\,0.995} = 2.756.\n\nUsing the one-sample t CI from Definition 7.3: \n\\bar{X} \\;\\pm\\; t_{n-1,\\,1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}},\n\\qquad\nn=30,\\ \\bar{x}=161.72,\\ S^2=86.63\n\\;\\Rightarrow\\;\n\\frac{S}{\\sqrt{n}}=\\sqrt{\\frac{86.63}{30}} \\approx 1.6993.\n\nTherefore:\n\n95% CI: \n  161.72 \\;\\pm\\; 2.045 \\times \\sqrt{\\frac{86.63}{30}}\n  \\;=\\; (158.24,\\; 165.20).\n  \n99% CI \n  161.72 \\;\\pm\\; 2.756 \\times \\sqrt{\\frac{86.63}{30}}\n  \\;=\\; (157.04,\\; 166.40).",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Frequentist Interval Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part3/7-freq-interval-estimation.html#sec-approx-ci",
    "href": "content/main/part3/7-freq-interval-estimation.html#sec-approx-ci",
    "title": "7  Frequentist Interval Estimation",
    "section": "7.4 Approximate Confidence Intervals",
    "text": "7.4 Approximate Confidence Intervals\nFor more general distributions (not necessarily normal), exact CIs are not available. In such cases we rely on asymptotics 4.2 to derive approximate CIs. For example:\n\nThe Central Limit Theorem 4.1.\nThe Asymptotic Distribution of the MLE 5.3.\n\n\n7.4.1 CLT: Approximate CI for the Mean\nSuppose\n\nX_1,\\dots,X_n \\;\\overset{\\text{iid}}{\\sim}\\; \\mathrm{Distribution}(\\underline{\\theta})\n\nwith mean \\mu and variance \\sigma^2.\nThe sample mean 4.1 \\bar{X} is an estimator of \\mu. By the Central Limit Theorem 4.1, for large n:\n\n\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\;\\overset{\\text{approx.}}{\\sim}\\; \\mathcal{N}(0,1).\n\nSince \\sigma^2 is usually unknown, we replace it with the sample variance 4.2 S^2, noting that S^2 is a consistent estimator of \\sigma^2.\n\n\n\n\n\n\n\nDefinition 7.4 (CLT: Approximate CI for the Mean) Suppose X_1,\\dots,X_n \\overset{\\text{iid}}{\\sim} \\mathrm{Distribution}(\\underline{\\theta}) with mean \\mu. Then an approximate (1-\\alpha) confidence interval for \\mu is\n\n\\mu \\;\\in\\;\n\\left[\n\\bar{X} - z_{1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}}, \\;\\;\n\\bar{X} + z_{1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}}\n\\right],\n\nor equivalently\n\n\\bar{X} \\;\\pm\\; z_{1-\\alpha/2}\\,\\frac{S}{\\sqrt{n}},\n\nwhere\n\n\\bar{X} is the sample mean 4.1,\nS = \\sqrt{S^2} and S^2 is the sample variance 4.2,\nz_{1-\\alpha/2} is the (1-\\alpha/2) quantile of the standard Normal distribution \\mathcal{N}(0,1).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 7.3 (Poisson Goals: CLT Confidence Interval) Suppose the total number of goals in a Premier league football match is assumed to be \\mathrm{Poisson}(\\lambda) distributed.\nUsing the available data in Table 2.4, and assuming i.i.d. observations, and using the Central Limit Theorem 4.1 approximation, construct an approximate 95\\% confidence interval for the parameter \\lambda.\n\nSolution\nStep 1: Define the model and estimator\nLet X_i \\sim \\mathrm{Poisson}(\\lambda) denote the total number of goals per football match. Note that the Poisson distribution 1.4 satisfies \\mathrm{E}[X_i] = \\lambda.\nTherefore, we use the sample mean 4.1\n\n\\hat{\\lambda} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\nas our estimator of \\lambda.\nStep 2: Apply the CLT\nFrom the CLT 4.1, for sufficiently large n and known variance \\sigma^2 = \\mathrm{Var}(X_i), we have\n\n\\hat{\\lambda} \\;\\overset{\\text{approx.}}{\\sim}\\; \\mathcal N \\left(\\lambda, \\frac{\\sigma^2}{n}\\right).\n\nWe need an estimate of \\sigma^2=\\mathrm{Var}(X_i):\n\nOption 1 (empirical variance): \\widehat{\\sigma^2}=S^2 (sample variance).\nOption 2 (Poisson variance): since \\mathrm{Var}(X_i)=\\lambda, use \\widehat{\\sigma^2}=\\hat{\\lambda}.\n\nStep 3: Construct the CIs\nWith z_{0.975}=1.96:\n\nOption 1 (using S^2):\n\n\\lambda \\in \\left[\\ \\hat{\\lambda} - 1.96\\cdot \\frac{S}{\\sqrt{n}}\\ ,\\ \\hat{\\lambda} + 1.96\\cdot \\frac{S}{\\sqrt{n}}\\ \\right].\n\nOption 2 (using \\hat{\\lambda} for Poisson variance):\n\n\\lambda \\in \\left[\\ \\hat{\\lambda} - 1.96\\cdot \\sqrt{\\frac{\\hat{\\lambda}}{n}}\\ ,\\ \\hat{\\lambda} + 1.96\\cdot \\sqrt{\\frac{\\hat{\\lambda}}{n}}\\ \\right].\n\n\nStep 4: Apply to the data (first 10 matches shown)\nFrom Table 2.4, the total number of goals per match gives the data:\n\n\n\n\n\n\n\n\n\nMatch\nHome goals\nAway goals\nTotal goals\n\n\n\n\nNewcastle United vs Arsenal\n7\n0\nx_1 = 7\n\n\nManchester United vs Liverpool F.C.\n0\n1\nx_2 = 1\n\n\nTottenham Hotspur vs Chelsea F.C.\n1\n3\nx_3 = 4\n\n\nAston Villa vs Leeds United\n3\n2\nx_4 = 5\n\n\nWest Ham United vs Manchester City\n0\n4\nx_5 = 4\n\n\nBrighton & Hove Albion vs Everton\n2\n2\nx_6 = 4\n\n\nLeicester City vs Southampton\n1\n0\nx_7 = 1\n\n\nWolverhampton Wanderers vs Brentford\n2\n1\nx_8 = 3\n\n\nCrystal Palace vs Fulham\n0\n1\nx_9 = 1\n\n\nNottingham Forest vs Bournemouth\n1\n1\nx_{10} = 2\n\n\n…\n…\n…\n…\n\n\n\nThen\n\n\\hat{\\lambda}=\\bar{x}=\\frac{32}{10}=3.2,\\qquad\nS^2 \\approx 3.956.\n\n\nOption 1: \\text{SE}=S/\\sqrt{n}\\approx 0.629 \\Rightarrow\n\n\\lambda \\in [\\,3.20 \\pm 1.96\\times 0.629\\,] \\ =\\ [\\,1.97,\\ 4.43\\,].\n\nOption 2: \\text{SE}=\\sqrt{\\hat{\\lambda}/n}\\approx 0.566 \\Rightarrow\n\n\\lambda \\in [\\,3.20 \\pm 1.96\\times 0.566\\,] \\ =\\ [\\,2.09,\\ 4.31\\,].\n\n\nResult. With these 10 matches, the approximate 95\\% CIs are\n\n\\boxed{\\ [1.97,\\ 4.43]\\ \\text{(using }S^2\\text{)} \\quad\\text{and}\\quad [2.09,\\ 4.31]\\ \\text{(using }\\hat{\\lambda}\\text{)}\\ }.\n\n\nNotes:\n\nOption 2 uses the Poisson property \\mathrm{Var}(X_i) = \\lambda, whereas Option 1 is more agnostic (i.e. can be used more broadly) and can be preferable if there’s overdispersion (variance &gt; mean) or mild model misspecification.\nIf the model is well-specified (i.e. the total number of goals is Poisson distributed), as we observe more matches (larger n) the two intervals will get closer.\n\n\n\n\n\n\n\n\n7.4.2 Asymptotic MLE: Approximate CI for the MLE\nSuppose \\hat{\\theta}_n is the maximum likelihood estimator of \\theta based on n IID observations.\nFrom the Asymptotic Distribution of the MLE 5.3,\n\n\\hat{\\theta}_n \\;\\overset{\\text{approx.}}{\\sim} \\; \\mathcal{N} \\Big(\\theta,\\; \\mathcal{I}_n(\\theta)^{-1}\\Big),\n\nwhere \\mathcal{I}_n(\\theta) is the Fisher information 5.1 for the whole sample.\nBut in practice, \\theta is unknown - that’s the very reason we’re estimating it! So we cannot evaluate \\mathcal{I}_n(\\theta) directly.\nJust as in the CLT confidence interval 7.4 we replaced the unknown \\sigma with its estimator S, here we replace the unknown \\theta inside \\mathcal{I}_n(\\theta) with the maximum likelihood estimate \\hat{\\theta}_n.\n\nThis gives a computable estimate of the Fisher information, called the observed Fisher information 5.10: \n\\mathcal{I}_n(\\theta) \\;\\approx\\; \\mathcal{I}_n(\\hat{\\theta}_n).\n\nSince \\hat{\\theta}_n \\to \\theta as n \\to \\infty (consistency of the MLE), this substitution is asymptotically valid.\n\nIn other words, this plug-in idea ensures the confidence interval uses only observable quantities, while still being asymptotically correct.\n\n\n\n\n\n\n\nDefinition 7.5 (Asymptotic MLE: Approximate CI) Suppose \\hat{\\theta}_n is the maximum likelihood estimator of \\theta based on n IID observations. Then an approximate (1-\\alpha) confidence interval for \\theta is\n\n\\theta \\;\\in\\;\n\\left[\n\\hat{\\theta}_n - z_{1-\\alpha/2}\\,\\sqrt{\\mathcal{I}_n(\\hat{\\theta}_n)^{-1}}, \\;\\;\n\\hat{\\theta}_n + z_{1-\\alpha/2}\\,\\sqrt{\\mathcal{I}_n(\\hat{\\theta}_n)^{-1}}\n\\right],\n\nor equivalently\n\n\\hat{\\theta}_n \\;\\pm\\; z_{1-\\alpha/2}\\,\\sqrt{\\mathcal{I}_n(\\hat{\\theta}_n)^{-1}},\n\nwhere\n\n\\hat{\\theta}_n is the maximum likelihood estimator,\n\\mathcal{I}_n(\\theta) is the Fisher information 5.1 for the whole sample, evaluated at \\hat{\\theta}_n, and\nz_{1-\\alpha/2} is the (1-\\alpha/2) quantile of the standard Normal distribution \\mathcal{N}(0,1).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 7.4 (Poisson Goals: MLE Confidence Interval) Following from Example 7.3, but now using the Asymptotic Distribution of the MLE 5.3, construct an approximate 95\\% confidence interval for \\lambda.\n\nSolution\nStep 1: Relevant quantities\nFrom Poisson MLE 5.11, the MLE is\n\n\\hat{\\lambda}=\\bar{X}.\n\nFrom Poisson Fisher Information 5.14, the Fisher information for the whole sample is\n\n\\mathcal{I}_n(\\lambda)=\\frac{n}{\\lambda}.\n\nStep 2: Asymptotic MLE distribution and CI\nBy Asymptotic MLE 5.3,\n\n\\hat{\\lambda}\\ \\overset{\\text{approx.}}{\\sim}\\ \\mathcal{N}\\!\\Big(\\lambda,\\ \\mathcal{I}_n(\\lambda)^{-1}\\Big)\n= \\mathcal{N}\\!\\Big(\\lambda,\\ \\tfrac{\\lambda}{n}\\Big).\n\nSince the variance involves the unknown \\lambda, we follow Definition 7.5 by plugging-in the MLE \\hat{\\lambda} into \\lambda:\n\n\\tfrac{\\lambda}{n} \\approx \\sqrt{\\tfrac{\\hat{\\lambda}}{n}}.\n\nHence an approximate (1-\\alpha) CI is\n\n\\lambda \\ \\in\\\n\\left[\n\\hat{\\lambda} - z_{1-\\alpha/2}\\,\\sqrt{\\tfrac{\\hat{\\lambda}}{n}},\\ \\\n\\hat{\\lambda} + z_{1-\\alpha/2}\\,\\sqrt{\\tfrac{\\hat{\\lambda}}{n}}\n\\right].\n\nStep 3: Apply to data\nFrom Table 2.4 (first 10 rows),\n\n\\underline{x}=(7,1,4,5,4,4,1,3,1,2),\\quad n=10,\n\nso\n\n\\hat{\\lambda}=\\bar{X}=\\frac{32}{10}=3.2,\\qquad\n\\widehat{\\mathrm{SE}}=\\sqrt{\\frac{3.2}{10}}=\\sqrt{0.32}\\approx 0.5657.\n\nWith z_{0.975}=1.96,\n\n\\lambda \\in \\left[\\,3.2 \\pm 1.96\\times 0.5657\\,\\right]\n= [\\,3.2 \\pm 1.108\\,]\n= \\boxed{[\\,2.09,\\ 4.31\\,]} \\quad(\\text{to 2 d.p.}).\n\n\nNotes.\nThis matches the CLT option that used \\mathrm{Var}(X)=\\lambda (since the Poisson model implies variance equals mean). If there were overdispersion, the sample-variance based CLT interval would be wider.",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Frequentist Interval Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part3/7-freq-interval-estimation.html#footnotes",
    "href": "content/main/part3/7-freq-interval-estimation.html#footnotes",
    "title": "7  Frequentist Interval Estimation",
    "section": "",
    "text": "Recall from Chapter 6 that Bayesians do not return a single “best guess,” but a full posterior distribution over parameter values. From this distribution we can compute summaries such as plausible ranges of \\theta (see Chapter 8), which play a role similar to confidence intervals but with a different interpretation.↩︎",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Frequentist Interval Estimation</span>"
    ]
  },
  {
    "objectID": "content/main/part3/8-bayes-interval-estimation.html",
    "href": "content/main/part3/8-bayes-interval-estimation.html",
    "title": "8  Bayesian Intervals",
    "section": "",
    "text": "8.1 The Bayesian perspective\nWe now consider the Bayesian analogue of frequentist confidence intervals.\nRecall from Chapter 6 that Bayesian inference returns a full distribution over the parameter - the posterior 6.2: \n\\pi(\\theta \\mid \\underline{x}) \\ \\propto\\ \\pi(\\theta)\\, f_{\\underline{X}}(\\underline{x}\\mid\\theta).\nFrom this posterior we can construct a Bayesian credible interval, which represents a range of parameter values that are plausible given the data and prior assumptions.\nFor any posterior distribution there are infinitely many valid (1-\\alpha) credible intervals.\nThis mirrors the frequentist setting, where infinitely many (1-\\alpha) confidence intervals also exist, though in practice one often chooses a canonical version (for example, the symmetric interval around the estimator).",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Bayesian Intervals</span>"
    ]
  },
  {
    "objectID": "content/main/part3/8-bayes-interval-estimation.html#the-bayesian-perspective",
    "href": "content/main/part3/8-bayes-interval-estimation.html#the-bayesian-perspective",
    "title": "8  Bayesian Intervals",
    "section": "",
    "text": "Definition 8.1 (Credible interval) A 100(1-\\alpha)\\% credible interval for \\theta is any set C_\\alpha such that \n\\Pr(\\theta \\in C_\\alpha \\mid \\underline{x})\n\\;=\\;\\int_{C_\\alpha}\\!\\pi(\\theta\\mid \\underline{x})\\,\\mathrm{d}\\theta\n\\;=\\;1-\\alpha .\n For discrete \\theta, replace the integral by a sum.\n\n\n\n\n\n\n\nShow Visualisation\n\nfunction betaPDF(x, alpha, beta) {\n  if (x &lt;= 0 || x &gt;= 1) return 0;\n  // Using the log-gamma function for numerical stability\n  const logBeta = lgamma(alpha) + lgamma(beta) - lgamma(alpha + beta);\n  return Math.exp((alpha - 1) * Math.log(x) + (beta - 1) * Math.log(1 - x) - logBeta);\n}\n\nfunction lgamma(z) {\n  const g = 7;\n  const p = [0.99999999999980993, 676.5203681218851, -1259.1392167224028,\n             771.32342877765313, -176.61502916214059, 12.507343278686905,\n             -0.13857109526572012, 9.9843695780195716e-6, 1.5056327351493116e-7];\n  \n  if (z &lt; 0.5) return Math.log(Math.PI) - Math.log(Math.sin(Math.PI * z)) - lgamma(1 - z);\n  \n  z -= 1;\n  let x = p[0];\n  for (let i = 1; i &lt; g + 2; i++) x += p[i] / (z + i);\n  \n  const t = z + g + 0.5;\n  return Math.log(2 * Math.PI) / 2 + (z + 0.5) * Math.log(t) - t + Math.log(x);\n}\n\n// Beta CDF using incomplete beta function (numerical approximation)\nfunction betaCDF(x, alpha, beta) {\n  if (x &lt;= 0) return 0;\n  if (x &gt;= 1) return 1;\n  \n  // Use regularized incomplete beta function\n  // For simplicity, using numerical integration\n  const n = 1000;\n  const h = x / n;\n  let sum = 0;\n  \n  for (let i = 1; i &lt; n; i++) {\n    const t = i * h;\n    sum += betaPDF(t, alpha, beta);\n  }\n  \n  return h * (betaPDF(0, alpha, beta) / 2 + sum + betaPDF(x, alpha, beta) / 2);\n}\n\n// Inverse CDF using bisection method\nfunction betaInvCDF(p, alpha, beta) {\n  if (p &lt;= 0) return 0;\n  if (p &gt;= 1) return 1;\n  \n  let low = 0, high = 1;\n  const tol = 1e-6;\n  \n  while (high - low &gt; tol) {\n    const mid = (low + high) / 2;\n    const cdf = betaCDF(mid, alpha, beta);\n    \n    if (cdf &lt; p) {\n      low = mid;\n    } else {\n      high = mid;\n    }\n  }\n  \n  return (low + high) / 2;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// Generate intervals based on number of segments\nfunction generateIntervals(nIntervals, targetProb, alpha, beta) {\n  const intervals = [];\n  const remainingProb = 1 - targetProb; // This is α\n  \n  if (nIntervals === 1) {\n    // Single interval: use equal-tailed interval as default\n    const tailProb = remainingProb / 2;\n    intervals.push({\n      start: betaInvCDF(tailProb, alpha, beta),\n      end: betaInvCDF(1 - tailProb, alpha, beta),\n      prob: targetProb\n    });\n  } else {\n    // Multiple intervals: distribute probability evenly\n    const probPerInterval = targetProb / nIntervals;\n    const gapProb = remainingProb / (nIntervals + 1);\n    \n    let cumProb = gapProb;\n    for (let i = 0; i &lt; nIntervals; i++) {\n      const start = betaInvCDF(cumProb, alpha, beta);\n      cumProb += probPerInterval;\n      const end = betaInvCDF(cumProb, alpha, beta);\n      cumProb += gapProb;\n      \n      intervals.push({ start, end, prob: probPerInterval });\n    }\n  }\n  \n  return intervals;\n}\n\n\n\n\n\n\n\n// Main visualization\n{\n  const width = 960;\n  const height = 400;\n  const marginTop = 40;\n  const marginBottom = 60;\n  const marginLeft = 60;\n  const marginRight = 40;\n  \n  // Generate posterior PDF data\n  const xDomain = [0, 1];\n  const nPoints = 500;\n  const xValues = d3.range(nPoints).map(i =&gt; i / (nPoints - 1));\n  const pdfData = xValues.map(x =&gt; ({\n    x: x,\n    y: betaPDF(x, betaAlpha, betaBeta)\n  }));\n  \n  // Generate intervals\n  const intervals = generateIntervals(numIntervals, 1 - alphaLevel, betaAlpha, betaBeta);\n  \n  // Calculate actual total probability (for display)\n  let totalProb = 0;\n  intervals.forEach(interval =&gt; {\n    const prob = betaCDF(interval.end, betaAlpha, betaBeta) - \n                  betaCDF(interval.start, betaAlpha, betaBeta);\n    totalProb += prob;\n  });\n  \n  // Create color scale for intervals\n  const colors = [\n    \"var(--brand-teal)\",\n    \"var(--brand-orange)\",\n    \"var(--brand-purple)\",\n    \"var(--brand-red)\",\n    \"var(--brand-teal)\",\n    \"var(--brand-orange)\",\n    \"var(--brand-purple)\",\n    \"var(--brand-red)\",\n    \"var(--brand-teal)\",\n    \"var(--brand-orange)\",\n    \"var(--brand-purple)\",\n    \"var(--brand-red)\",\n  ];\n  \n  // Calculate mean and mode for display\n  const posteriorMean = betaAlpha / (betaAlpha + betaBeta);\n  const posteriorMode = betaAlpha &gt; 1 && betaBeta &gt; 1 \n    ? (betaAlpha - 1) / (betaAlpha + betaBeta - 2)\n    : posteriorMean;\n  \n  // Create the plot\n  const plot = Plot.plot({\n    width,\n    height,\n    marginTop,\n    marginBottom,\n    marginLeft,\n    marginRight,\n    style: {\n      background: \"var(--brand-bg)\",\n      color: \"var(--brand-fg)\",\n      fontFamily: bodyFont,\n      fontSize: 14\n    },\n    x: {\n      label: \"θ\",\n      domain: xDomain,\n      grid: false\n    },\n    y: {\n      label: \"Posterior density π(θ|x)\",\n      domain: [0, Math.max(...pdfData.map(d =&gt; d.y)) * 1.1]\n    },\n    marks: [\n      // Grid baseline\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n      \n      // Posterior PDF curve\n      Plot.lineY(pdfData, { \n        x: \"x\", \n        y: \"y\", \n        stroke: \"currentColor\", \n        strokeWidth: 2,\n        strokeOpacity: 0.9\n      }),\n      \n      // Credible intervals (filled areas)\n      ...intervals.map((interval, i) =&gt; {\n        const intervalData = pdfData.filter(d =&gt; \n          d.x &gt;= interval.start && d.x &lt;= interval.end\n        );\n        return Plot.areaY(intervalData, {\n          x: \"x\",\n          y: \"y\",\n          fill: colors[i % colors.length],\n          fillOpacity: 0.3,\n        });\n      }),\n      \n      // Interval boundaries (vertical lines)\n      ...intervals.flatMap((interval, i) =&gt; [\n        Plot.ruleX([interval.start], {\n          stroke: colors[i % colors.length],\n          strokeWidth: 2,\n          strokeDasharray: \"3,2\"\n        }),\n        Plot.ruleX([interval.end], {\n          stroke: colors[i % colors.length],\n          strokeWidth: 2,\n          strokeDasharray: \"3,2\"\n        })\n      ]),\n      \n      // Labels for intervals\n      ...intervals.map((interval, i) =&gt; {\n        const midpoint = (interval.start + interval.end) / 2;\n        const yValue = betaPDF(midpoint, betaAlpha, betaBeta);\n        return Plot.text([{\n          x: midpoint,\n          y: yValue,\n          text: `C${i + 1}`\n        }], {\n          x: \"x\",\n          y: \"y\",\n          text: \"text\",\n          dy: -30,\n          fontSize: 12,\n          fontWeight: \"bold\",\n          fill: colors[i % colors.length]\n        });\n      })\n    ]\n  });\n  \n  // Stats display\n  const stats = html`\n    &lt;div style=\"margin-bottom: 15px; padding: 12px; background: var(--header-bg); border-radius: 6px; font-size: 14px;\"&gt;\n      &lt;div style=\"display: flex; justify-content: space-between; flex-wrap: wrap; gap: 20px;\"&gt;\n        &lt;div&gt;\n          &lt;strong&gt;Posterior:&lt;/strong&gt; Beta(${betaAlpha}, ${betaBeta})\n        &lt;/div&gt;\n        &lt;div&gt;\n          &lt;strong&gt;Mean:&lt;/strong&gt; ${posteriorMean.toFixed(3)}\n        &lt;/div&gt;\n        &lt;div&gt;\n          &lt;strong&gt;Target credibility:&lt;/strong&gt; ${((1 - alphaLevel) * 100).toFixed(1)}%\n        &lt;/div&gt;\n        &lt;div&gt;\n          &lt;strong&gt;Actual coverage:&lt;/strong&gt; ${(totalProb * 100).toFixed(2)}%\n        &lt;/div&gt;\n      &lt;/div&gt;\n      ${numIntervals &gt; 1 ? html`\n        &lt;div style=\"margin-top: 10px; padding-top: 10px; border-top: 1px solid var(--border);\"&gt;\n          &lt;em style=\"color: var(--fg-muted);\"&gt;\n            Note: With ${numIntervals} disjoint intervals, the ${((1 - alphaLevel) * 100).toFixed(0)}% \n            probability mass is distributed equally across all intervals, with equal-sized gaps between them.\n          &lt;/em&gt;\n        &lt;/div&gt;\n      ` : html`\n        &lt;div style=\"margin-top: 10px; padding-top: 10px; border-top: 1px solid var(--border);\"&gt;\n          &lt;em style=\"color: var(--fg-muted);\"&gt;\n            Note: Single interval uses the equal-tailed credible interval \n            (${(alphaLevel * 50).toFixed(1)}% in each tail).\n          &lt;/em&gt;\n        &lt;/div&gt;\n      `}\n    &lt;/div&gt;\n  `;\n  \n  return html`&lt;div style=\"width: 100%; max-width: 960px; margin: 0 auto;\"&gt;\n    ${stats}\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof credibleControls = {\n  const alphaSlider = Inputs.range([0.01, 0.5], { \n    value: 0.05, \n    step: 0.01, \n    label: tex`\\alpha` \n  });\n  \n  const intervalsSlider = Inputs.range([1, 12], { \n    value: 1, \n    step: 1, \n    label: \"Number of intervals\" \n  });\n  \n  const betaAlphaSlider = Inputs.range([1, 30], { \n    value: 8, \n    step: 0.5, \n    label: tex`\\text{Beta } \\alpha \\text{ parameter}` \n  });\n  \n  const betaBetaSlider = Inputs.range([1, 30], { \n    value: 3, \n    step: 0.5, \n    label: tex`\\text{Beta } \\beta \\text{ parameter}` \n  });\n  \n  const root = html`&lt;details class=\"controls-root\" open&gt;\n    &lt;summary style=\"cursor: pointer; font-weight: 600;\"&gt;Credible Interval Controls&lt;/summary&gt;\n    &lt;div class=\"controls-grid\" style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px; padding: 15px;\"&gt;\n      &lt;div class=\"controls-col\"&gt;\n        &lt;h4 style=\"margin-bottom: 10px;\"&gt;Interval Configuration&lt;/h4&gt;\n        ${alphaSlider}\n        &lt;div style=\"margin-top: 15px;\"&gt;\n          ${intervalsSlider}\n        &lt;/div&gt;\n      &lt;/div&gt;\n      &lt;div class=\"controls-col\"&gt;\n        &lt;h4 style=\"margin-bottom: 10px;\"&gt;Posterior Parameters&lt;/h4&gt;\n        ${betaAlphaSlider}\n        &lt;div style=\"margin-top: 15px;\"&gt;\n          ${betaBetaSlider}\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/details&gt;`;\n  \n  // Set up value forwarding\n  root.value = {\n    alpha: alphaSlider.value,\n    numIntervals: intervalsSlider.value,\n    betaAlpha: betaAlphaSlider.value,\n    betaBeta: betaBetaSlider.value\n  };\n  \n  root.addEventListener(\"input\", () =&gt; {\n    root.value = {\n      alpha: alphaSlider.value,\n      numIntervals: intervalsSlider.value,\n      betaAlpha: betaAlphaSlider.value,\n      betaBeta: betaBetaSlider.value\n    };\n    root.dispatchEvent(new CustomEvent(\"input\", { bubbles: true }));\n  });\n  \n  return root;\n}\n\n// Reactive bindings\nalphaLevel = credibleControls.alpha\nnumIntervals = credibleControls.numIntervals\nbetaAlpha = credibleControls.betaAlpha\nbetaBeta = credibleControls.betaBeta",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Bayesian Intervals</span>"
    ]
  },
  {
    "objectID": "content/main/part3/8-bayes-interval-estimation.html#interpreting-credible-intervals",
    "href": "content/main/part3/8-bayes-interval-estimation.html#interpreting-credible-intervals",
    "title": "8  Bayesian Intervals",
    "section": "8.2 Interpreting Credible Intervals",
    "text": "8.2 Interpreting Credible Intervals\nA 95\\% credible interval means that, given the observed data and the prior, there is a 95\\% posterior probability that \\theta lies inside the chosen interval. The probability statement is about the parameter itself, conditional on the data at hand.\nIn contrast, a 95\\% confidence interval is a procedure: if we were to repeatedly draw new samples and reconstruct a confidence interval each time, then 95\\% of those intervals would cover the true parameter. It does not mean there is a 95\\% chance that \\theta lies inside the one interval we have.\nThus, credible intervals are often more natural to interpret, but they depend explicitly on the prior as well as the data.",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Bayesian Intervals</span>"
    ]
  },
  {
    "objectID": "content/main/part3/8-bayes-interval-estimation.html#highest-density-intervals",
    "href": "content/main/part3/8-bayes-interval-estimation.html#highest-density-intervals",
    "title": "8  Bayesian Intervals",
    "section": "8.3 Highest Density Intervals",
    "text": "8.3 Highest Density Intervals\n\n\n\n\n\n\n\nDefinition 8.2 (Highest Density Interval (HDI)) A 100(1-\\alpha)\\% highest density interval (HDI) for \\theta is the region\n\nC_\\alpha = \\{\\theta :~ \\pi(\\theta \\mid \\underline{x}) \\geq \\gamma \\},\n\nwhere \\gamma is chosen so that \\mathrm{Pr}(\\theta \\in C_\\alpha \\mid \\underline{x}) = 1-\\alpha.\nAmong all (1-\\alpha) credible intervals 8.1, the HDI has shortest length.\n\n\n\n\nIf the posterior distribution has many modes, then it is possible that the HDI will be the union of several disjoint regions. For example,\n\nC_\\alpha = (a,b)\\cup(c,d)\\cup(e,f), \\quad a&lt;b&lt;c&lt;d&lt;e&lt;f.\n\n\n\n\n\n\n\n\nExample 8.1 (Beta HDI) Suppose that the posterior distribution for \\theta is a \\mathrm{Beta}(1,24) distribution, with probability density function\n\n\\pi(\\theta \\mid \\underline{x}) = 24(1-\\theta)^{23}, \\quad 0&lt;\\theta&lt;1.\n\nTask. Determine the 100(1-\\alpha)\\% HDI for~\\theta.\n\n   Solution \nThe HDI must include those values of \\theta with highest posterior density and so must take the form C_\\alpha=(0,b). The end-point b must satisfy\n\n\\int_0^b 24(1-\\theta)^{23}\\,d\\theta = 1-\\alpha.\n\nNow,\n\n\\int_0^b 24(1-\\theta)^{23}\\,d\\theta\n= \\left[-(1-\\theta)^{24}\\right]^b_0 = 1-(1-b)^{24}.\n\nHence,\n\n1-(1-b)^{24} = 1-\\alpha\n\\quad\\Longrightarrow\\quad\n1-b=\\alpha^{1/24}\n\\quad\\Longrightarrow\\quad\nb=1-\\alpha^{1/24}.\n\nTherefore, a 100(1-\\alpha)\\% HDI for \\theta is\n\n(0,\\, 1-\\alpha^{1/24}).\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 8.2 (Normal HDI) Suppose we have a random sample \\underline{x}e from a \\mathcal{N}(\\mu,1/\\tau) distribution (where \\tau is known).\nWe have seen that, assuming vague prior knowledge, the posterior distribution is\n\n\\mu \\mid \\underline{x} \\sim \\mathcal{N}\\!\\left(\\bar x,\\; \\tfrac{1}{n\\tau}\\right).\n\nTask. Determine the 100(1-\\alpha)\\% HDI for~\\mu.\n\n   Solution \n\n\n\n\n\n\n\n\n\n\n\nTipSolution\n\n\n\n\n\n\nSolution 8.1. This distribution has a symmetric bell shape and so the HDI takes the form C_\\alpha=(a,b) with end-points\n\na=\\bar x - \\frac{z_{\\alpha/2}}{\\sqrt{n\\tau}},\n\\qquad\nb=\\bar x + \\frac{z_{\\alpha/2}}{\\sqrt{n\\tau}},\n\nwhere z_\\alpha is the upper \\alpha-quantile of the \\mathcal{N}(0,1) distribution.\nTherefore, the 95% HDI for~\\mu is\n\n\\left(\\bar x - \\frac{1.96}{\\sqrt{n\\tau}},\\;\n\\bar x + \\frac{1.96}{\\sqrt{n\\tau}}\\right).\n\nNote that this interval is numerically identical to the 95% frequentist confidence interval for the (population) mean of a normal random sample with known variance.\nHowever, the interpretation is very different.",
    "crumbs": [
      "Part III - Interval Estimation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Bayesian Intervals</span>"
    ]
  },
  {
    "objectID": "content/main/part4/9-freq-hypothesis-testing.html",
    "href": "content/main/part4/9-freq-hypothesis-testing.html",
    "title": "9  Frequentist Hypothesis Testing",
    "section": "",
    "text": "9.1 The Testing Procedure\nRecalling the main inference tasks 3.2, we now move from interval estimation to hypothesis testing.\nThe name hypothesis testing comes from the scientific method:\nIf the data are consistent, this provides support for the hypothesis (though never proof). If the data look very unlikely under the hypothesis, this is evidence against it.\nUnlike interval estimation (which gives a range of plausible values), hypothesis testing asks a yes/no question about the parameter \\theta.\nTo make this precise, we specify a null hypothesis H_0, a concrete mathematical statement about \\theta: \nH_0 : \\theta \\in \\Theta_0,\nwhere \\Theta_0 \\subseteq \\Theta is part of the parameter space.\nThe alternative hypothesis is simply the complement set: \nH_1 : \\theta \\in \\Theta \\setminus \\Theta_0,\n i.e. the parameter values in \\Theta which are not in \\Theta_0.\nSo every hypothesis test is really just a partition 1.3 of the parameter space into two regions: one where the null holds, and one where it does not.\nWe then use the observed data \\underline{x} to evaluate whether H_0 is plausible. The frequentist reasoning is:\nTo make this comparison practical, we do not usually work with the full data distribution. Instead, we reduce the sample to a test statistic T(\\underline{X}) that captures the evidence relevant to H_0.",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Frequentist Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/9-freq-hypothesis-testing.html#the-testing-procedure",
    "href": "content/main/part4/9-freq-hypothesis-testing.html#the-testing-procedure",
    "title": "9  Frequentist Hypothesis Testing",
    "section": "",
    "text": "9.1.1 General Recipe\n\nSpecify the hypotheses.\nWrite down the null hypothesis H_0 and (optionally) an alternative H_1.\nH_1 is not always needed at this stage, but it helps to define what counts as “extreme.”\nChoose a test statistic.\nSelect a statistic T(\\underline{X}) that would tend to take unusually large or small values if H_0 were false.\nFind its distribution under H_0.\nWork out (exactly or approximately) the sampling distribution of T(\\underline{X}) assuming H_0 is true.\nDefine a rejection region R_\\alpha.\nFor a chosen significance level \\alpha, determine a set R_\\alpha of “extreme” values of T(\\underline{X}) such that\n\n\\max_{\\theta \\in H_0} \\, \\mathrm{Pr} \\big(T \\in R_\\alpha \\mid \\theta \\big) \\;\\leq\\; \\alpha.\n\n\nIf H_0 is a single value (simple null) and T is a continuous random variable, this maximum occurs exactly at that value, so we can choose R_\\alpha so that the probability equals \\alpha.\nIf H_0 is composite or T is discrete, the test may be conservative: the probability is strictly less than \\alpha for some \\theta \\in H_0.\n\nCompute the observed statistic.\nFrom the data, calculate T_{\\text{obs}} = T(\\underline{x}).\nDecision.\n\nIf T_{\\text{obs}} \\in R_\\alpha, reject H_0.\n\nIf T_{\\text{obs}} \\notin R_\\alpha, fail to reject1 H_0.\n\n\n\n\n\n\n\n\nImportant 9.1: Ingredients of a Hypothesis Test\n\n\n\n\n\nTo define a hypothesis test we need two choices:\n\nA test statistic T(\\underline{X}) that captures evidence against H_0.\n\nA method of constructing the rejection region R_\\alpha for T at level \\alpha.\n\nTogether, (T, R_\\alpha) specify the test completely.\nHowever:\n\nThere are usually several possible choices of test statistic T(\\underline{X}).\nWe prefer ones that are powerful - i.e. they give a high chance of detecting departures from H_0.\nEven once T is chosen, there can be different possible rejection regions R.\nBy convention we use regions that capture the most extreme values of T in the direction(s) specified by H_1.\n\nIn addition, the sampling distribution 4.3 the test statistic T(\\underline{X}) under H_0 must be computed. However, it may be obtained exactly, or approximately by using asymptotic distributions 4.2.\n\n\n\n\n\n\n\n\n\n\nDefinition 9.1 (Rejection Region) Given a test statistic T(\\underline{X}) and significance level \\alpha, a rejection region is a subset R_\\alpha of the sample space of T such that\n\n\\max_{\\theta \\in H_0} \\, \\mathrm{Pr} \\big(T \\in R_\\alpha \\mid \\theta \\big) \\;\\leq\\; \\alpha.\n\nThis ensures that, no matter which parameter value in H_0 is true, the probability of a false rejection (Type I error) never exceeds \\alpha.\n\nFor a simple null with a continuous test statistic, the maximum occurs at the null value itself, and we can usually choose R_\\alpha so that the probability equals \\alpha.\n\nFor a composite null or a discrete statistic, the maximum may be strictly less than \\alpha, making the test conservative.\n\nIn practice:\n- For a two-sided test, R_\\alpha is typically chosen as both tails of the distribution of T under H_0.\n- For a one-sided test, R_\\alpha is typically one tail (upper or lower), depending on the alternative H_1.\nOther choices of R_\\alpha are mathematically possible, but by convention we use the most extreme values of T, since this usually maximises power.\n\n\n\n\nAs our first example of a hypothesis test, we will pick a bad choice of test statistic T and a couple of choices of rejection region R.\n\n\n\n\n\n\n\nExample 9.1 (A Terrible Hypothesis Test) Suppose X_1,\\dots,X_n \\overset{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, 1) and we wish to test\n\nH_0: \\mu = 0.\nH_1: \\mu \\neq 0.\n\nWe choose T = X_1 as our test statistic.\n\nFor a chosen \\alpha, determine two different rejection regions.\nWith the observed sample \n  x_1=0.4,\\; x_2=3.2,\\; x_3=2.1,\\; x_4=2.3,\\; x_5=1.8.\n   For which \\alpha would you reject H_0?\n\n\nSolution\na. Two possible rejection regions\nUnder H_0, T \\sim \\mathcal{N}(0,1).\n\nConventional two-sided test: Reject if T is very large in magnitude:\n\nR_\\alpha^{(1)} = \\{\\,|T| &gt; z_{1-\\alpha/2}\\,\\}.\n\nUnconventional one-sided test: Reject if T is very large and positive only:\n\nR_\\alpha^{(2)} = \\{\\,T &gt; z_{1-\\alpha}\\,\\}.\n\nThis region also has probability \\alpha under H_0, but it only detects positive departures from 0.\n\nOther choices are mathematically possible (e.g. a left-tail test, or even a symmetric band around 0 with total mass \\alpha), but these would be poor at detecting the alternatives we care about.\n\nb. Observed value\nHere T_{\\text{obs}} = x_1 = 0.4.\n\nFor the two-sided region R_\\alpha^{(1)}: Reject if |0.4| &gt; z_{1-\\alpha/2}. This happens only if \\alpha \\gtrsim 0.689.\nFor the one-sided region R_\\alpha^{(2)}: Reject if 0.4 &gt; z_{1-\\alpha}. This requires \\alpha \\gtrsim 0.345.\n\nSo in both cases you would only reject H_0 at extremely large (non-standard) significance levels. At any usual choice like \\alpha=0.05 or 0.01, you fail to reject.\n\nWhy this test is terrible (and instructive):\n\nIt ignores n-1 observations, so the power is extremely poor (see Example 9.2).\nDifferent R_\\alpha give different answers, showing that both T and R matter.\nThe statistic X_1 is a very unstable indicator of \\mu.\n\n\n\n\n\n\nIn Example 9.1 we effectively solved for the smallest significance level \\alpha at which the observed test statistic would fall in the rejection region.\nThis motivates the formal definition of the p-value:\n\n\n\n\n\n\n\nDefinition 9.2 (p-value) Given an observed test statistic T_{\\text{obs}}, the p-value is the smallest significance level \\alpha for which T_{\\text{obs}} \\in R_\\alpha.\nEquivalently, it is the probability, under H_0, of observing a test statistic at least as extreme as T_{\\text{obs}}:\n\np = \\Pr \\big( T \\text{ is at least as extreme as } T_{\\text{obs}} \\mid H_0 \\big).\n\n\nFor a two-sided test, “extreme” means either very large or very small values of T.\n\nFor a one-sided test, “extreme” means only one direction, determined by H_1.\n\n\n\n\n\n\nAlmost all tests in practice are either one-sided or two-sided. Restricting to these two cases fixes the form of the rejection region:\n\n\n\n\n\n\n\nDefinition 9.3 (One-Sided and Two-Sided Tests)  \n\nIn a one-sided test, the alternative hypothesis H_1 specifies a direction.\n\nExample: H_0: \\mu \\leq \\mu_0 vs. H_1: \\mu &gt; \\mu_0.\nThe rejection region is of the form\n\nR_\\alpha = \\{ T \\mid T \\geq c_\\alpha \\},\n\ni.e. we only reject for large values of T.\nSimilarly, if H_1 is in the other direction, H_1:\\mu &lt; \\mu_0, then\n\nR_\\alpha = \\{ T \\mid T \\leq c_\\alpha \\}.\n\n\nIn a two-sided test, the alternative hypothesis H_1 does not specify a direction (e.g. H_1: \\mu \\neq \\mu_0).\n\nThe rejection region is then in both tails:\n\nR_\\alpha = \\{ T \\mid |T| \\geq c_\\alpha \\}.\n\nHere, the \\alpha level is usually split between the two tails, so each tail has probability \\alpha/2 under H_0.\n\n\n\n\n\n\n\n\n9.1.2 Types of Errors\nBecause decisions are based on data (which vary by chance), mistakes are inevitable.\nA hypothesis test produces a yes/no decision about H_0. Comparing this decision with the true state of H_0 gives four logical possibilities.\n\n\n\n\n\n\n\n\nDecision\nReality: H_0 true\nReality: H_0 false\n\n\n\n\nReject H_0\nType I Error (wrongly rejecting a true H_0)\nCorrect decision\n\n\nFail to reject H_0\nCorrect decision\nType II Error (missing a false H_0)\n\n\n\n\n\n\n\n\n\n\nDefinition 9.4 (Errors in Hypothesis Tests)  \n\nType I Error (False Positive): Rejecting H_0 when it is actually true.\n\nType II Error (False Negative): Failing to reject H_0 when the alternative is true.\n\nBy the definition of the rejection region 9.1, the probability of a Type I Error is exactly the significance level \\alpha.\n\n\n\n\n\n\n9.1.3 Power of a Test\nTo describe both types of error within a single framework, we define the power function:\n\n\n\n\n\n\n\nDefinition 9.5 (Power Function) The power function of a test is \n\\beta(\\theta) = \\Pr\\!\\big(T \\in R_\\alpha \\mid \\theta\\big), \\qquad \\theta \\in \\Theta.\n\n\nIf \\theta \\in H_0, this is the type I error probability, which by design is at most \\alpha.\n\nIf \\theta \\in H_1, this is the probability of correctly rejecting H_0 at that parameter value.\n\nThus the power function unifies the error probabilities: it is small on H_0, and we hope it is large on H_1.\n\n\n\n\n\nHigh power means the test is good at detecting departures from H_0.\n\nHigh specificity means the test is good at not raising false alarms.\n\nIn practice, there is a trade-off: lowering \\alpha reduces false positives but usually reduces power too.\nComputing the power of a test depends on the true value of the parameter \\theta:\n\n\n\n\n\n\n\nExample 9.2 (The Power of a Terrible Hypothesis Test) Continuing from Example 9.1, for each of the rejection regions\n\nR_\\alpha^{(1)} = \\{\\,|T| &gt; z_{1-\\alpha/2}\\,\\}, and\nR_\\alpha^{(2)} = \\{\\,T &gt; z_{1-\\alpha}\\,\\},\n\nderive the power functions of the test as a function of \\mu.\n\nSolution\nThe alternative hypothesis is H_1: \\mu \\neq 0. If H_1 were true, then our test statistic would have distribution \nT = X_1 \\sim \\mathcal{N}(\\mu, 1), \\quad \\mu \\neq 0.\n\n1. R_\\alpha^{(1)}\nFor R_\\alpha^{(1)}, we reject if the test statistic T satisfies |T| &gt; z_{1-\\alpha/2}, we can compute this as:\n\\begin{align*}\n\\Pr(|T| &gt; z_{1-\\alpha/2}) &= \\Pr(T &gt; z_{1-\\alpha/2}) + \\Pr(T &lt; - z_{1-\\alpha/2}) \\\\\n&= \\Pr\\left( \\frac{T - \\mu}{1} &gt; z_{1-\\alpha/2} \\right) + \\Pr\\left( \\frac{T - \\mu}{1} &lt; - z_{1-\\alpha/2} \\right) \\\\\n&= \\Pr\\left(Z &gt; \\mu + z_{1-\\alpha/2} \\right) + \\Pr\\left(Z &lt; \\mu - z_{1-\\alpha/2}\\right) \\\\\n&= 1 - \\Phi(\\mu +  z_{1-\\alpha/2}) + \\Phi(\\mu - z_{1-\\alpha/2}),\n\\end{align*} where Z \\sim \\mathcal{N}(0,1) and \\Phi is its CDF.\n2. R_\\alpha^{(2)}\nFor R_\\alpha^{(2)}, we reject if the test statistic T satisfies T &gt; z_{1-\\alpha}, we can compute this as:\n\\begin{align*}\n\\Pr(T &gt; z_{1-\\alpha}) &= \\Pr\\left(\\frac{Z - \\mu}{1} &gt; z_{1-\\alpha}\\right) \\\\\n&= \\Pr(Z &gt; z_{1-\\alpha} + \\mu) \\\\\n&= 1 - \\Phi(z_{1-\\alpha} + \\mu),\n\\end{align*} where Z \\sim \\mathcal{N}(0,1) and \\Phi is its CDF.\n\nSummary\n\nFor the two-sided test\n\n\\beta(\\mu)\n= \\Pr(|T| &gt; z_{1-\\alpha/2} \\mid \\mu)\n= 1 - \\Big[ \\Phi(z_{1-\\alpha/2} - \\mu) - \\Phi(-z_{1-\\alpha/2} - \\mu)\\Big].\n\nThis is one minus the probability that T falls inside the acceptance region.\nFor the one-sided test\n\n\\beta(\\mu)\n= \\Pr(T &gt; z_{1-\\alpha} \\mid \\mu)\n= 1 - \\Phi(z_{1-\\alpha} - \\mu).\n\n\nBoth expressions reduce to \\beta(0) = \\alpha when \\mu=0, as required.\n\n\n\n\n\n\n\n   Show Visualisation \nThe following plot displays the two power curves in Example 9.2.\nThe blue line plots \\mathrm{Power}(\\mu) = 1 - \\Big[ \\Phi(z_{1-\\alpha/2} - \\mu) - \\Phi(-z_{1-\\alpha/2} - \\mu)\\Big] and the red line plots \\mathrm{Power}(\\mu)  = 1 - \\Phi(z_{1-\\alpha} - \\mu).\n\n// Alpha slider\nviewof alphaValue = Inputs.range([0.01, 0.8], {\n  value: 0.05,\n  step: 0.005,\n  label: ''\n})\n\n\n\n\n\n\n\nmuDomain = [-4, 4]\nmuXs = d3.scaleLinear().domain(muDomain).ticks(401)\n\n// Standard normal PDF/CDF helpers\nSQRT2 = Math.sqrt(2)\nSQRT2PI = Math.sqrt(2 * Math.PI)\n\n// erf approximation (Abramowitz & Stegun 7.1.26)\nerf = (x) =&gt; {\n  const sign = Math.sign(x);\n  x = Math.abs(x);\n  const a1 = 0.254829592, a2 = -0.284496736, a3 = 1.421413741;\n  const a4 = -1.453152027, a5 = 1.061405429, p = 0.3275911;\n  const t = 1 / (1 + p * x);\n  const y = 1 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x*x);\n  return sign * y;\n}\n\nnormalCDF = (x) =&gt; 0.5 * (1 + erf(x / SQRT2))\n\n// Inverse normal CDF (Acklam's approximation, high accuracy)\nfunction normalInvCDF(p){\n  // Coefficients\n  const a = [-3.969683028665376e+01,  2.209460984245205e+02, -2.759285104469687e+02,\n              1.383577518672690e+02, -3.066479806614716e+01,  2.506628277459239e+00];\n  const b = [-5.447609879822406e+01,  1.615858368580409e+02, -1.556989798598866e+02,\n              6.680131188771972e+01, -1.328068155288572e+01];\n  const c = [-7.784894002430293e-03, -3.223964580411365e-01, -2.400758277161838e+00,\n             -2.549732539343734e+00,  4.374664141464968e+00,  2.938163982698783e+00];\n  const d = [ 7.784695709041462e-03,  3.224671290700398e-01,  2.445134137142996e+00,\n              3.754408661907416e+00];\n  // Break-points\n  const plow = 0.02425, phigh = 1 - plow;\n  let q, r, x;\n  if (p &lt; plow){\n    q = Math.sqrt(-2 * Math.log(p));\n    x = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) /\n        ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1);\n  } else if (p &gt; phigh){\n    q = Math.sqrt(-2 * Math.log(1 - p));\n    x = -(((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) /\n          ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1);\n  } else {\n    q = p - 0.5; r = q*q;\n    x = (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5]) * q /\n        (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4])*r + 1);\n  }\n  // One step of Halley refinement\n  const e = normalCDF(x) - p;\n  const u = e * Math.sqrt(2*Math.PI) * Math.exp(x*x/2);\n  return x - u / (1 + x*u/2);\n}\n// Critical values based on current alpha\nz_twoSided = normalInvCDF(1 - alphaValue / 2)\nz_oneSided = normalInvCDF(1 - alphaValue)\n\n// Power functions using dynamic critical values\npowerTwoSided = (mu) =&gt; {\n  // Power(μ) = P(|T| &gt; z | μ) = Φ(μ - z) + Φ(-μ - z)\n  return normalCDF(mu - z_twoSided) + normalCDF(-mu - z_twoSided);\n}\n\npowerOneSided = (mu) =&gt; {\n  // Power(μ) = P(T &gt; z | μ) = 1 - Φ(z - μ)\n  return 1 - normalCDF(z_oneSided - mu);\n}\n\n// Build curves\ntwoSided = muXs.map(mu =&gt; ({ mu, y: powerTwoSided(mu), which: \"Two-sided\" }))\noneSided = muXs.map(mu =&gt; ({ mu, y: powerOneSided(mu), which: \"One-sided\" }))\n\n// Mark the μ=0 point (both equal α)\nat0 = [\n  { mu: 0, y: powerTwoSided(0), which: \"Two-sided\" },\n  { mu: 0, y: powerOneSided(0), which: \"One-sided\" }\n]\n\n\n// On-curve label anchors (choose different μ to avoid overlap)\nmuLabelTwo = 2.4\nmuLabelOne = 1.2\nlabelDots = [\n  { mu: muLabelTwo, y: powerTwoSided(muLabelTwo), label: \"Two-sided\", color: \"var(--brand-teal)\" },\n  { mu: muLabelOne, y: powerOneSided(muLabelOne), label: \"One-sided\", color: \"var(--brand-red)\" }\n]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const plot = Plot.plot({\n    height: 340,\n    marginLeft: 52,\n    marginBottom: 46,\n    marginTop: 40,\n    x: { label: \"Effect size μ\", domain: muDomain },\n    y: { label: \"Power\", domain: [0, 1] },\n    style: {\n      background: \"var(--brand-bg)\",\n      color: \"var(--brand-fg)\",\n      fontFamily: bodyFont,\n      fontSize: 12\n    },\n    marks: [\n      // baseline and bands\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 }),\n      Plot.ruleY([1], { stroke: \"var(--border)\", strokeOpacity: 0.15 }),\n      Plot.ruleY([alphaValue], { \n        stroke: \"var(--brand-fg)\", \n        strokeWidth: 1, \n        strokeOpacity: 0.3, \n        strokeDasharray: \"6,3\" \n      }),\n      Plot.ruleX([0], { \n        stroke: \"var(--brand-fg)\", \n        strokeWidth: 1.5, \n        strokeOpacity: 0.35, \n        strokeDasharray: \"3,3\" \n      }),\n\n      // two-sided curve & light fill\n      Plot.areaY(twoSided, { \n        x: \"mu\", \n        y: \"y\", \n        fill: \"var(--brand-teal)\", \n        fillOpacity: 0.10 \n      }),\n      Plot.lineY(twoSided, { \n        x: \"mu\", \n        y: \"y\", \n        stroke: \"var(--brand-teal)\", \n        strokeWidth: 2 \n      }),\n\n      // one-sided curve & light fill\n      Plot.areaY(oneSided, { \n        x: \"mu\", \n        y: \"y\", \n        fill: \"var(--brand-red)\", \n        fillOpacity: 0.10 \n      }),\n      Plot.lineY(oneSided, { \n        x: \"mu\", \n        y: \"y\", \n        stroke: \"var(--brand-red)\", \n        strokeWidth: 2 \n      }),\n\n      // points at μ=0 (both equal α)\n      Plot.dot(at0, { \n        x: \"mu\", \n        y: \"y\", \n        r: 4, \n        fill: \"var(--brand-fg)\",\n        stroke: \"var(--brand-bg)\",\n        strokeWidth: 2\n      }),\n      \n      // On-curve labels (placed at different μ values)\n      Plot.dot(labelDots, { x: \"mu\", y: \"y\", r: 2, fill: d =&gt; d.color }),\n      Plot.text(labelDots, { \n        x: \"mu\", y: \"y\", text: \"label\", \n        dx: -30, dy: -20, \n        fill: d =&gt; d.color, \n        fontWeight: \"bold\"\n      }),\n\n      \n      // Alpha level annotation\n      Plot.text([{x: -3.5, y: alphaValue}], {\n        x: \"x\",\n        y: \"y\",\n        text: d =&gt; `α = ${alphaValue.toFixed(2)}`,\n        dx: 0,\n        dy: -8,\n        fontSize: 11,\n        fill: \"var(--brand-fg)\",\n        fillOpacity: 0.7\n      })\n    ]\n  });\n  \n  // Display info about current settings\n  const info = html`\n    &lt;div style=\"margin-top: 10px; padding: 10px; background: var(--header-bg); border-radius: 4px; font-size: 13px;\"&gt;\n      &lt;strong&gt;Settings:&lt;/strong&gt; α = ${alphaValue.toFixed(3)} | \n      Critical values: z&lt;sub&gt;${(1 - alphaValue/2).toFixed(3)}&lt;/sub&gt; = ${z_twoSided.toFixed(3)} (two-sided), \n      z&lt;sub&gt;${(1 - alphaValue).toFixed(3)}&lt;/sub&gt; = ${z_oneSided.toFixed(3)} (one-sided) |\n      Power at μ=0: ${(alphaValue).toFixed(3)}\n    &lt;/div&gt;\n  `;\n  \n  return html`&lt;div style=\"width: 100%; max-width: 960px; margin: 0 auto;\"&gt;\n    ${plot}\n    ${info}\n  &lt;/div&gt;`;\n\n}\n\n\n\n\n\n\n\n\nFigure 9.3: Power curves for one-sided and two-sided z-tests, testing H_0\\colon \\mu = 0 using T\\sim\\mathcal{N}(\\mu, 1). The one-sided test is more powerful in the correct direction; the two-sided test splits α across both tails.\n\n\n\n\n\n// Add custom CSS for the slider styling (without the details.controls-root requirement)\nhtml`&lt;style&gt;\n/* Style all range sliders in the document */\ninput[type=\"range\"] {\n  /* Reset browser defaults */\n  -webkit-appearance: none;\n  appearance: none;\n  \n  /* Layout */\n  width: 100%;\n  height: 18px;\n  background: transparent;\n  vertical-align: middle;\n  \n  /* Brand theming */\n  accent-color: var(--ctrl-brand);\n}\n\n/* Hide the number input box that appears with Inputs.range */\nform:has(input[type=\"range\"]) input[type=\"number\"] {\n  display: none !important;\n}\n\n/* Center the slider container */\nform:has(input[type=\"range\"]) {\n  margin: 0 auto;\n  max-width: 600px; /* Adjust as needed */\n  padding: 10px 0;\n}\n\n/* Slider track - WebKit */\ninput[type=\"range\"]::-webkit-slider-runnable-track {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n\n/* Slider thumb - WebKit */\ninput[type=\"range\"]::-webkit-slider-thumb {\n  -webkit-appearance: none;\n  appearance: none;\n  \n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  border: 0;\n  background: var(--ctrl-brand, #667eea);\n  \n  /* Center thumb over 4px track */\n  margin-top: -4px;\n}\n\n/* Slider track - Firefox */\ninput[type=\"range\"]::-moz-range-track {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n\n/* Slider thumb - Firefox */\ninput[type=\"range\"]::-moz-range-thumb {\n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  border: 0;\n  background: var(--ctrl-brand, #667eea);\n}\n\n/* Firefox progress styling */\ninput[type=\"range\"]::-moz-range-progress {\n  height: 4px;\n  border-radius: 999px;\n  background: color-mix(in srgb, var(--ctrl-brand, #667eea) 35%, transparent);\n}\n&lt;/style&gt;`",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Frequentist Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/9-freq-hypothesis-testing.html#exact-hypothesis-tests",
    "href": "content/main/part4/9-freq-hypothesis-testing.html#exact-hypothesis-tests",
    "title": "9  Frequentist Hypothesis Testing",
    "section": "9.2 Exact Hypothesis Tests",
    "text": "9.2 Exact Hypothesis Tests\nIn this section, we derive commonly used hypothesis tests and consider their power.\n\n9.2.1 One-Sample Normal (known variance)\nIn Example 9.1, we considered i.i.d. normally distributed data with known variance. However, we considered a bad test statistic. For general i.i.d. X_i \\sim \\mathcal{N}(\\mu, \\sigma^2), it is much more natural to use the sample mean 4.1, \n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n to test H_0: \\mu = \\mu_0 vs. either a one-sided or two-sided alternative. Let’s do this:\n\n\n\n\n\n\n\nExample 9.3 (One-Sample Normal Test (known variance)) Suppose we have i.i.d. data X_i \\sim \\mathcal{N}(\\mu, \\sigma^2). Suppose we wish to test:\n\nH_0: \\mu = \\mu_0, H_1: \\mu \\neq \\mu_0.\nH_0: \\mu \\leq \\mu_0, H_1: \\mu &gt; \\mu_0.\nH_0: \\mu \\geq \\mu_0, H_1: \\mu &lt; \\mu_0.\n\nUsing the test statistic: \nT = \\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i,\n\nderive the one-sided and two-sided rejection regions at significance level \\alpha.\n\nSolution\n1.\nUnder the null hypothesis, the test statistic T has distribution: \nT \\mid \\mu = \\mu_0 \\sim \\mathcal{N}\\left(\\mu_0, \\frac{\\sigma^2}{n}\\right).\n Since the alternative is two-sided, we want power in both directions and so pick a two-sided rejection region. We have \n\\frac{T - \\mu_0}{\\sigma / \\sqrt{n}} \\sim \\mathcal{N}(0,1).\n Therefore, since\n\\begin{align*}\n\\Pr\\left( \\frac{T - \\mu_0}{\\sigma / \\sqrt{n}} \\geq z_{1-\\alpha/2}  \\;\\middle|\\; \\mu = \\mu_0 \\right)\n+ \\Pr\\left( \\frac{T - \\mu_0}{\\sigma / \\sqrt{n}} \\leq -z_{1-\\alpha/2}  \\;\\middle|\\; \\mu = \\mu_0 \\right)\n&= 1-\\alpha \\\\\n\\Pr\\left( \\,|T - \\mu_0| \\geq \\frac{z_{1-\\alpha/2} \\sigma}{\\sqrt{n}} \\;\\middle|\\; \\mu = \\mu_0 \\right)\n&= 1-\\alpha.\n\\end{align*}\nTherefore, a valid two-sided 1-\\alpha rejection region takes the form: \nR_\\alpha = \\left\\{ T \\mid \\; |T - \\mu_0| &gt; \\frac{\\sigma \\, z_{1-\\alpha/2}}{\\sqrt{n}} \\right\\}.\n\n2.\nUnder the null hypothesis, the test statistic T has distribution: \nT \\mid \\mu \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right), \\quad \\text{for } \\mu \\leq \\mu_0.\n\nThe null hypothesis does not fully specify the distribution of the null.\n\n\n\n\n\n\n\n9.2.2 One-Sample Normal (unknown variance)\n\n\n9.2.3 Two-Sample Normal (unknown variances)\nSo far, we have only ever considered a single sample",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Frequentist Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/9-freq-hypothesis-testing.html#approximate-hypothesis-tests",
    "href": "content/main/part4/9-freq-hypothesis-testing.html#approximate-hypothesis-tests",
    "title": "9  Frequentist Hypothesis Testing",
    "section": "9.3 Approximate Hypothesis Tests",
    "text": "9.3 Approximate Hypothesis Tests\n\n9.3.1 CLT: Approximate Hypothesis Tests\n\n\n\n\n\n\n\nExample 9.4 (Test of Proportions)  \n\n\n\n\n\n\n9.3.2 Asymptotic MLE: Approximate Hypothesis Tests",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Frequentist Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/9-freq-hypothesis-testing.html#likelihood-ratio-test",
    "href": "content/main/part4/9-freq-hypothesis-testing.html#likelihood-ratio-test",
    "title": "9  Frequentist Hypothesis Testing",
    "section": "9.4 Likelihood Ratio Test",
    "text": "9.4 Likelihood Ratio Test",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Frequentist Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/9-freq-hypothesis-testing.html#footnotes",
    "href": "content/main/part4/9-freq-hypothesis-testing.html#footnotes",
    "title": "9  Frequentist Hypothesis Testing",
    "section": "",
    "text": "It is common to say “reject H_0” when the p-value is small, and “fail to reject H_0” otherwise. Both phrases should be interpreted with care: rejecting H_0 does not prove it is false, and failing to reject H_0 does not prove it is true. Instead, hypothesis testing provides a decision rule about whether the data are sufficiently inconsistent with H_0 at a chosen significance level.↩︎",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Frequentist Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/10-bayes-hypothesis-testing.html",
    "href": "content/main/part4/10-bayes-hypothesis-testing.html",
    "title": "10  Bayesian Hypothesis Testing",
    "section": "",
    "text": "10.1 The Bayesian Setup\nRecalling the main inference tasks 3.2, we now move from interval estimation to hypothesis testing in the Bayesian framework, and consider the Bayesian analogue of frequentist hypothesis testing..\nThe Bayesian perspective is slightly different from the frequentist one: instead of asking whether data look unlikely under a hypothesis, we ask:\nJust like in frequentist hypothesis testing 9, the Bayesian approach compares two hypotheses:\nH_0 : \\theta \\in \\Theta_0,\n\\qquad\nH_1 : \\theta \\in \\Theta_1,\n where \\Theta_1 = \\Theta \\setminus \\Theta_0.\nThe Bayesian perspective is to assign probabilities to hypotheses and to parameter values.\nThis involves two ingredients:",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Bayesian Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/main/part4/10-bayes-hypothesis-testing.html#the-bayesian-setup",
    "href": "content/main/part4/10-bayes-hypothesis-testing.html#the-bayesian-setup",
    "title": "10  Bayesian Hypothesis Testing",
    "section": "",
    "text": "Prior probabilities of the hypotheses: \n\\Pr(H_0) \\quad \\text{and} \\quad \\Pr(H_1),\n\nsuch that \\Pr(H_0) + \\Pr(H_1) = 1.\nConditional priors for the parameter under each hypothesis: \n\\pi(\\theta \\mid H_0) \\quad \\text{and} \\quad \\pi(\\theta \\mid H_1).\n\n\n\n10.1.1 Posterior Probabilities of Hypotheses\nAfter observing data \\underline{x}, Bayes’ theorem gives \n\\Pr(H_0 \\mid \\underline{x})\n= \\frac{f(\\underline{x}\\mid H_0)\\,\\Pr(H_0)}{f(\\underline{x})}.\n\nIf H_0 is not simple, the likelihood f(\\underline{x}\\mid H_0) is obtained by averaging over \\theta \\in \\Theta_0 with the conditional prior: \nf(\\underline{x} \\mid H_0)\n= \\int_{\\Theta_0} f(\\underline{x}\\mid\\theta)\\,\\pi(\\theta \\mid H_0)\\,\\mathrm{d}\\theta.\n\nSo we can write \n\\Pr(H_0 \\mid \\underline{x})\n= \\frac{m_0(\\underline{x}) \\,\\Pr(H_0)}{m(\\underline{x})},\n\nwhere\n\nm_0(\\underline{x}) = \\int_{\\Theta_0} f(\\underline{x}\\mid\\theta)\\,\\pi(\\theta\\mid H_0)\\,\\mathrm{d}\\theta is the marginal likelihood under H_0,\n\nm_1(\\underline{x}) = \\int_{\\Theta_1} f(\\underline{x}\\mid\\theta)\\,\\pi(\\theta\\mid H_1)\\,\\mathrm{d}\\theta is the marginal likelihood under H_1,\n\nm(\\underline{x}) = m_0(\\underline{x})\\Pr(H_0) + m_1(\\underline{x})\\Pr(H_1) is the overall marginal likelihood.\n\nThus the Bayesian procedure directly yields the posterior probabilities \\Pr(H_0 \\mid \\underline{x}) and \\Pr(H_1 \\mid \\underline{x}) for the competing hypotheses.\n\n\n10.1.2 Bayes Factor\nThe Bayes factor summarises how strongly the data update our beliefs:\n\nB_{10} = \\frac{m_1(\\underline{x})}{m_0(\\underline{x})}.\n\nIt measures how much more (or less) the data support H_1 compared to H_0.\nPosterior odds are obtained from prior odds via:\n\n\\frac{\\mathrm{Pr}(H_1 \\mid \\underline{x})}{\\mathrm{Pr}(H_0 \\mid \\underline{x})}\n= B_{10} \\times \\frac{\\mathrm{Pr}(H_1)}{\\mathrm{Pr}(H_0)}.\n\n\nIf B_{10} &gt; 1: the data increase belief in H_1.\n\nIf B_{10} &lt; 1: the data increase belief in H_0.\n\n\n\nShow Visualisation\nSuppose our model is\n\nX_i \\mid \\mu \\sim \\mathcal{N}(\\mu, 10),\n\nand we want to test whether \\mu = 200:\n\nH_0: \\mu = 200\n\nH_1: \\mu \\sim \\mathcal{N}(200, 25) (a vague prior centred on 200)\n\nWe compare the likelihood of the observed sample mean under each hypothesis.\n\nn = 30\nsigma = 10\nmu0 = 200\n\n// Slider for observed sample mean\nviewof xbar_obs = Inputs.range([mu0 - 3*sigma, mu0 + 3*sigma], \n  {step: 0.5, value: mu0, label: md`Observed sample mean ${tex`\\bar{x}_{obs}`}`} )\n\n// Likelihood under H0 (point null)\nm0 = 1/(sigma/Math.sqrt(n)*Math.sqrt(2*Math.PI)) *\n     Math.exp(-0.5*((xbar_obs - mu0)/(sigma/Math.sqrt(n)))**2)\n\n// Marginal likelihood under H1 (normal prior on mu)\ntau = 25        // prior variance for H1\npost_var = 1 / (1/tau + n/sigma**2)\npost_mean = post_var * (mu0/tau + n*xbar_obs/sigma**2)\n\n// Under H1, the marginal distribution of xbar is Normal(mu0, sigma^2/n + tau)\nm1 = 1/Math.sqrt(2*Math.PI*(sigma**2/n + tau)) *\n     Math.exp(-0.5*((xbar_obs - mu0)**2)/(sigma**2/n + tau))\n\n// Bayes factor\nB10 = m1/m0\n\nmd`**Bayes factor** ${tex`B_{10}`} = ${B10.toFixed(3)}`",
    "crumbs": [
      "Part IV — Hypothesis Testing",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Bayesian Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "content/appendix/formula-sheet.html#discrete-distributions",
    "href": "content/appendix/formula-sheet.html#discrete-distributions",
    "title": "Formula Sheet",
    "section": "Discrete distributions",
    "text": "Discrete distributions\n\nBernoulli\nModel. X \\sim \\operatorname{Bernoulli}(p) with 0&lt;p&lt;1.\nSupport. x \\in \\{0,1\\}.\nPMF. \n\\operatorname{Pr}(X=x) = p^{\\,x}(1-p)^{1-x}, \\quad x\\in\\{0,1\\}.\n Mean/Var. \\mathbb{E}[X]=p,\\quad \\operatorname{Var}(X)=p(1-p).\n\n\n\nBinomial\nModel. X \\sim \\operatorname{Binom}(n,p), n\\in \\mathbb{N}, 0&lt;p&lt;1.\nSupport. x=0,1,\\ldots,n.\nPMF. \n\\operatorname{Pr}(X=x) = \\binom{n}{x} p^x (1-p)^{n-x}.\n Mean/Var. \\mathbb{E}[X]=np,\\quad \\operatorname{Var}(X)=np(1-p).\n\n\n\nMultinomial\nModel. \\mathbf{X}=(X_1,\\ldots,X_k) \\sim \\operatorname{Multinomial}(n,\\mathbf{p}), with n\\in\\mathbb{N}, k\\ge 2, \\mathbf{p}=(p_1,\\ldots,p_k), p_i&gt;0, and \\sum_{i=1}^k p_i=1.\nSupport. \\mathbf{x}=(x_1,\\ldots,x_k) where x_i\\in\\{0,1,\\ldots,n\\} and \\sum_{i=1}^k x_i=n.\nPMF. \n\\Pr(\\mathbf{X}=\\mathbf{x})\n=\\frac{n!}{x_1!\\cdots x_k!}\\prod_{i=1}^k p_i^{\\,x_i}.\n Mean/Cov. \n\\mathbb{E}[X_i]=n p_i,\\qquad\n\\operatorname{Var}(X_i)=n p_i(1-p_i),\\qquad\n\\operatorname{Cov}(X_i,X_j)=-\\,n p_i p_j\\quad (i\\ne j).\n Vector form. \n\\mathbb{E}[\\mathbf{X}]=n\\,\\mathbf{p},\\qquad\n\\operatorname{Cov}(\\mathbf{X})=n\\left(\\operatorname{diag}(\\mathbf{p})-\\mathbf{p}\\mathbf{p}^\\top\\right).\n\nNote. For k=2, the first component X_1 \\sim \\operatorname{Bin}(n,p_1) (Binomial).\n\n\n\nPoisson\nModel. X \\sim \\operatorname{Pois}(\\lambda), \\lambda&gt;0.\nSupport. x=0,1,2,\\ldots.\nPMF. \n\\operatorname{Pr}(X=x)=\\frac{\\lambda^x e^{-\\lambda}}{x!}.\n Mean/Var. \\mathbb{E}[X]=\\lambda,\\quad \\operatorname{Var}(X)=\\lambda.\n\n\n\nGeometric\nModel. X \\sim \\operatorname{Geom}(p) (trials until first success, counting the success), 0&lt;p&lt;1.\nSupport. x=1,2,\\ldots.\nPMF. \n\\operatorname{Pr}(X=x)=p(1-p)^{x-1}.\n Mean/Var. \\mathbb{E}[X]=\\frac{1}{p},\\quad \\operatorname{Var}(X)=\\frac{1-p}{p^2}.\n\n\n\n\n\n\nWarningParameterisation alert\n\n\n\nSome texts start at x=0 (failures before the first success).\n\n\n\n\n\nNegative Binomial\nModel. X \\sim \\operatorname{NegBin}(r,p): number of trials to achieve the r-th success (counts the successes), r&gt;0 (often integer), 0&lt;p&lt;1.\nSupport. x=r,r+1,\\ldots.\nPMF. \n\\operatorname{Pr}(X=x) = \\binom{x-1}{r-1} p^{\\,r} (1-p)^{x-r}.\n Mean/Var. \\mathbb{E}[X]=\\frac{r}{p},\\quad \\operatorname{Var}(X)=\\frac{r(1-p)}{p^2}.\n\n\n\n\n\n\nWarningParameterisation alert\n\n\n\nAnother common version counts failures before the r-th success (x=0,1,\\dots) with different mean/variance. Always check which one is used.",
    "crumbs": [
      "Additional Material",
      "Formula Sheet"
    ]
  },
  {
    "objectID": "content/appendix/formula-sheet.html#continuous-distributions",
    "href": "content/appendix/formula-sheet.html#continuous-distributions",
    "title": "Formula Sheet",
    "section": "Continuous distributions",
    "text": "Continuous distributions\n\nUniform (continuous)\nModel. X \\sim \\mathcal{U}(a,b), a&lt;b.\nSupport. a&lt;x&lt;b.\nPDF. \nf_X(x;a,b)=\\frac{1}{b-a}.\n Mean/Var. \\mathbb{E}[X]=\\frac{a+b}{2},\\quad \\operatorname{Var}(X)=\\frac{(b-a)^2}{12}.\n\n\n\nExponential\nModel. X \\sim \\operatorname{Exponential}(\\lambda) with rate \\lambda&gt;0.\nSupport. x&gt;0.\nPDF. \nf_X(x;\\lambda)=\\lambda e^{-\\lambda x}.\n Mean/Var. \\mathbb{E}[X]=\\frac{1}{\\lambda},\\quad \\operatorname{Var}(X)=\\frac{1}{\\lambda^2}.\n\n\n\nGamma\nModel. X \\sim \\operatorname{Gamma}(a,b) with shape a&gt;0 and rate b&gt;0.\nSupport. x&gt;0.\nPDF. \nf_X(x;a,b)=\\frac{b^a}{\\Gamma(a)} x^{a-1} e^{-bx}.\n Mean/Var. \\mathbb{E}[X]=\\frac{a}{b},\\quad \\operatorname{Var}(X)=\\frac{a}{b^2}.\n\n\n\n\n\n\nWarningParameterisation alert\n\n\n\nMany sources use scale \\beta=1/b: then f(x)=\\frac{1}{\\Gamma(a)\\beta^a}x^{a-1}e^{-x/\\beta} and \\mathbb{E}[X]=a\\beta.\n\n\n\n\n\nInverse Gamma\nModel. X \\sim \\operatorname{InvGamma}(a,b), with a&gt;0, b&gt;0.\nSupport. x&gt;0.\nPDF. \nf_X(x;a,b)=\\frac{b^a}{\\Gamma(a)} x^{-(a-1)} e^{-bx^{-1}}.\n Statistics. \\mathbb{E}[X]=\\frac{b}{a-1},\\quad \\operatorname{Var}(X)=\\frac{b^2}{(a-1)^2(a-2)} and \\text{Mode}(X) = \\frac{b}{a+1} if a &gt; 2.\n\n\n\nNormal\nModel. X \\sim \\mathcal{N}(\\mu,\\sigma^2) with \\sigma&gt;0.\nSupport. x\\in\\mathbb{R}.\nPDF. \nf_X(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\n\\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right).\n Mean/Var. \\mathbb{E}[X]=\\mu,\\quad \\operatorname{Var}(X)=\\sigma^2.\n\nProperties\nSuppose X_1,\\ldots, X_n are independent normal random variables, then:\n\n\n\n\nLognormal\nModel. X \\sim \\operatorname{LogNormal}(\\mu,\\sigma^2) meaning \\ln X \\sim \\mathcal{N}(\\mu,\\sigma^2).\nSupport. x&gt;0.\nPDF. \nf_X(x;\\mu,\\sigma^2)=\\frac{1}{x\\sqrt{2\\pi\\sigma^2}}\n\\exp\\!\\left(-\\frac{(\\ln x-\\mu)^2}{2\\sigma^2}\\right).\n Mean/Var. \\mathbb{E}[X]=e^{\\mu+\\sigma^2/2},\\quad \\operatorname{Var}(X)=\\big(e^{\\sigma^2}-1\\big)e^{2\\mu+\\sigma^2}.\n\n\n\nChi-squared\nModel. X \\sim \\chi^2_\\nu with \\nu&gt;0 degrees of freedom.\nSupport. x&gt;0.\nPDF. \nf_X(x;\\nu)=\\frac{1}{2^{\\nu/2}\\Gamma(\\nu/2)}x^{\\nu/2-1}e^{-x/2}.\n Mean/Var. \\mathbb{E}[X]=\\nu,\\quad \\operatorname{Var}(X)=2\\nu.\n\n\n\n\n\n\nNote\n\n\n\n\\chi^2_\\nu is a special case of Gamma with a=\\nu/2, b=1/2.\n\n\n\n\n\nStudent-t\nModel. X \\sim t_\\nu with \\nu&gt;0 degrees of freedom.\nSupport. x\\in\\mathbb{R}.\nPDF. \nf_X(x;\\nu)=\\frac{\\Gamma\\!\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu\\pi}\\,\\Gamma\\!\\left(\\frac{\\nu}{2}\\right)}\n\\left(1+\\frac{x^2}{\\nu}\\right)^{-(\\nu+1)/2}.\n Mean/Var. \\mathbb{E}[X]=0 for \\nu&gt;1; undefined for \\nu\\le 1.\n\\operatorname{Var}(X)=\\frac{\\nu}{\\nu-2} for \\nu&gt;2; infinite for 1&lt;\\nu\\le 2; undefined for \\nu\\le 1.\n\n\n\nF distribution\nModel. X \\sim F_{d_1,d_2} with d_1,d_2&gt;0 degrees of freedom.\nSupport. x&gt;0.\nPDF. \nf_X(x;d_1,d_2)=\\frac{\\Gamma\\!\\left(\\frac{d_1+d_2}{2}\\right)}{\\Gamma\\!\\left(\\frac{d_1}{2}\\right)\\Gamma\\!\\left(\\frac{d_2}{2}\\right)}\n\\left(\\frac{d_1}{d_2}\\right)^{d_1/2}\\frac{x^{d_1/2-1}}{\\left(1+\\frac{d_1}{d_2}x\\right)^{(d_1+d_2)/2}}.\n Mean/Var. \\mathbb{E}[X]=\\frac{d_2}{d_2-2} for d_2&gt;2.\n\\operatorname{Var}(X)=\\frac{2d_2^2(d_1+d_2-2)}{d_1(d_2-2)^2(d_2-4)} for d_2&gt;4.\n\n\n\nBeta\nModel. X \\sim \\operatorname{Beta}(a,b), a&gt;0, b&gt;0.\nSupport. 0&lt;x&lt;1.\nPDF. \nf_X(x;a,b)=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\,x^{a-1}(1-x)^{b-1}.\n Mean/Var. \\mathbb{E}[X]=\\frac{a}{a+b},\\quad \\operatorname{Var}(X)=\\frac{ab}{(a+b)^2(a+b+1)}.\n\n\n\nWeibull\nModel. X \\sim \\operatorname{Weibull}(\\beta,\\theta), \\beta&gt;0, \\theta&gt;0.\nSupport. x &gt; 0.\nPDF. \nf_X(x) = \\frac{\\beta}{\\theta}x^{\\beta - 1} \\exp\\left(-\\frac{x^\\beta}{\\theta}\\right)",
    "crumbs": [
      "Additional Material",
      "Formula Sheet"
    ]
  },
  {
    "objectID": "content/appendix/formula-sheet.html#multivariate-distributions",
    "href": "content/appendix/formula-sheet.html#multivariate-distributions",
    "title": "Formula Sheet",
    "section": "Multivariate Distributions",
    "text": "Multivariate Distributions\n\nMultivariate Normal\nModel. \\mathbf{X} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu},\\Sigma) with \\Sigma positive definite.\nSupport. \\mathbf{x}\\in\\mathbb{R}^p.\nPDF. \nf_{\\mathbf{X}}(\\mathbf{x};\\boldsymbol{\\mu},\\Sigma)=\\frac{1}{(2\\pi)^{p/2}(\\det\\Sigma)^{1/2}}\n\\exp\\!\\left(-\\tfrac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\Sigma^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right).\n Mean/Cov. \\mathbb{E}[\\mathbf{X}]=\\boldsymbol{\\mu},\\quad \\operatorname{Var}(\\mathbf{X})=\\Sigma.",
    "crumbs": [
      "Additional Material",
      "Formula Sheet"
    ]
  },
  {
    "objectID": "content/appendix/revision-sheet.html",
    "href": "content/appendix/revision-sheet.html",
    "title": "Revision Sheet",
    "section": "",
    "text": "Under Construction…",
    "crumbs": [
      "Additional Material",
      "Revision Sheet"
    ]
  },
  {
    "objectID": "content/appendix/distribution-explorer.html",
    "href": "content/appendix/distribution-explorer.html",
    "title": "Distribution Explorer",
    "section": "",
    "text": "ACCENT  = \"var(--brand-teal)\"\nACCENT2 = \"var(--brand-red)\"\nGRID    = \"var(--border)\"\n\n// Numerical helpers\nlinspace = (a, b, n=401) =&gt; Array.from({length:n}, (_,i)=&gt; a + (b-a)*(i/(n-1)))\n\n// Log-Gamma (Lanczos) and friends (for stable PMFs/PDFs)\nfunction logGamma(z){\n  const g = 7;\n  const p = [\n    0.99999999999980993, 676.5203681218851, -1259.1392167224028,\n    771.32342877765313, -176.61502916214059, 12.507343278686905,\n    -0.13857109526572012, 9.9843695780195716e-6, 1.5056327351493116e-7\n  ];\n  if(z &lt; 0.5){\n    return Math.log(Math.PI) - Math.log(Math.sin(Math.PI*z)) - logGamma(1 - z);\n  }\n  z -= 1;\n  let x = p[0];\n  for(let i=1; i&lt;p.length; i++) x += p[i] / (z + i);\n  const t = z + g + 0.5;\n  return 0.5*Math.log(2*Math.PI) + (z+0.5)*Math.log(t) - t + Math.log(x);\n}\n\nlogChoose = (n,k) =&gt; logGamma(n+1) - logGamma(k+1) - logGamma(n-k+1)\n\n// Discrete PMFs (stable in log-domain)\nbinomPMF = (n,p,k) =&gt; Math.exp(logChoose(n,k) + k*Math.log(p) + (n-k)*Math.log(1-p))\npoisPMF  = (lambda,k) =&gt; Math.exp(k*Math.log(lambda) - lambda - logGamma(k+1))\ngeomPMF1 = (p,k) =&gt; p * Math.pow(1-p, k-1) // support {1,2,...}\nnegbinPMF = (r,p,x) =&gt; {\n  if(x &lt; r) return 0;\n  return Math.exp(logChoose(x-1, r-1) + r*Math.log(p) + (x-r)*Math.log(1-p));\n}\n\n// Continuous PDFs\nnormPDF = (x,mu,sig) =&gt; Math.exp(-0.5*((x-mu)/sig)**2)/(sig*Math.sqrt(2*Math.PI))\nlognormPDF = (x,mu,sig) =&gt; x&lt;=0 ? 0 : Math.exp(-((Math.log(x)-mu)**2)/(2*sig*sig)) / (x*sig*Math.sqrt(2*Math.PI))\nunifPDF = (x,a,b) =&gt; (x&gt;a && x&lt;b) ? 1/(b-a) : 0\nexpPDF = (x,lambda) =&gt; x&gt;0 ? lambda*Math.exp(-lambda*x) : 0\ngammaPDF = (x,a,b) =&gt; { // shape a, rate b\n  if(x&lt;=0) return 0;\n  return Math.exp(a*Math.log(b) - logGamma(a) + (a-1)*Math.log(x) - b*x)\n}\nbetaPDF = (x,a,b) =&gt; {\n  if(x&lt;=0 || x&gt;=1) return 0;\n  const logB = logGamma(a)+logGamma(b)-logGamma(a+b);\n  return Math.exp((a-1)*Math.log(x) + (b-1)*Math.log(1-x) - logB)\n}\nchisqPDF = (x,nu) =&gt; gammaPDF(x, nu/2, 1/2)\ntPDF = (x,nu) =&gt; {\n  const logC = logGamma((nu+1)/2) - (0.5*Math.log(nu*Math.PI) + logGamma(nu/2));\n  return Math.exp(logC - ((nu+1)/2)*Math.log(1 + (x*x)/nu));\n}\nfPDF = (x,d1,d2) =&gt; {\n  if(x&lt;=0) return 0;\n  const logC = logGamma((d1+d2)/2) - (logGamma(d1/2)+logGamma(d2/2)) + (d1/2)*Math.log(d1/d2);\n  return Math.exp(logC + (d1/2 - 1)*Math.log(x) - ((d1+d2)/2)*Math.log(1 + (d1/d2)*x))\n}\n\n// Convenient domain heuristics\ndomainNormal = (mu,sig) =&gt; [mu - 4*sig, mu + 4*sig]\ndomainGamma  = (a,b) =&gt; [0, Math.max(5, a/b + 6*Math.sqrt(a)/b)]\ndomainExp    = (lambda) =&gt; [0, Math.max(5, 6/lambda)]\ndomainBeta   = [0,1]\ndomainPos    = [0, 10]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBernoulliBinomialPoissonGeometricNegative BinomialUniformExponentialGammaNormalLognormalChi-squaredStudent t\n\n\n\n{\n  const p = bern_p;\n  const data = [0, 1].map(x =&gt; ({ x, y: x ? p : 1 - p }));\n\n  const stats = md`**Mean** ${tex`= p`} = ${p.toFixed(2)}; \n  **Var** ${tex`= p(1-p)`} = ${(p * (1 - p)).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\", domain: [0, 1] },\n    x: { label: \"x\", type: \"band\", domain: [0, 1] },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof bern_p = Inputs.range([0.01, 0.99], {\n  value: 0.6, step: 0.01, label: md`${tex`p`}`\n})\n\n\n\n\n\n\n\n\n\n{\n  const n = binom_n, p = binom_p;\n  const data = Array.from({ length: n + 1 }, (_, k) =&gt; ({ x: k, y: binomPMF(n, p, k) }));\n  const xDomain = Array.from({ length: n + 1 }, (_, k) =&gt; k);  // &lt;-- 0..n categories\n\n  const stats = md`**Mean** ${tex`= np`} = ${(n * p).toFixed(2)}; \n  **Var** ${tex`= np(1-p)`} = ${(n * p * (1 - p)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n    y: { label: \"PMF\" },\n    x: { label: \"x\", type: \"band\", domain: xDomain, padding: 0.05 },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof binom_n = Inputs.range([1, 200], { value: 20, step: 1,  label: md`${tex`n`}` })\nviewof binom_p = Inputs.range([0.01, 0.99], { value: 0.3, step: 0.01, label: md`${tex`p`}` })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  // compute locally (no exported names)\n  const L     = pois_lambda;\n  const kmax  = Math.max(15, Math.ceil(L + 6*Math.sqrt(L)));\n  const pois_data = Array.from({length: kmax + 1}, (_, k) =&gt; ({ x: k, y: poisPMF(L, k) }));\n\n  // build the UI bits\n  const stats = md`**Mean** ${tex`= \\lambda`} = ${L.toFixed(2)}; \n  **Var** ${tex`= \\lambda`} = ${L.toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(pois_data, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\" }),\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return both in a single wrapper\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof pois_lambda = Inputs.range([0.2, 30], {\n  value: 6, step: 0.2, label: md`${tex`\\lambda`}`\n})\n\n\n\n\n\n\n\n\n\n{\n  // compute locally\n  const p = geom_p;\n  const raw   = Math.log(1e-4) / Math.log(1 - p);            // tail cutoff\n  const kmax  = Math.max(5, Math.min(200, Math.ceil(raw)));  // clamp for stability\n  const geom_data = Array.from({ length: kmax }, (_, i) =&gt; {\n    const k = i + 1; \n    return { x: k, y: geomPMF1(p, k) }; // PMF = p(1-p)^{k-1}\n  });\n\n  // stats readout\n  const stats = md`**Mean** ${tex`= 1/p`} = ${(1/p).toFixed(2)}; \n  **Var** ${tex`= (1-p)/p^2`} = ${(((1-p)/(p*p))).toFixed(2)}.`;\n\n  // plot\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(geom_data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return one wrapper node\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof geom_p = Inputs.range([0.02, 0.98], {\n  value: 0.3, step: 0.02, label: md`${tex`p`}`\n})\n\n\n\n\n\n\n\n\n\n{\n  const r = Math.round(negbin_r), p = negbin_p;\n  const mean = r / p, sd = Math.sqrt(r * (1 - p)) / p;\n  const xmax = Math.min(400, Math.ceil(mean + 6 * sd));\n\n  const data = Array.from({ length: Math.max(0, xmax - r + 1) }, (_, i) =&gt; {\n    const x = r + i;\n    return { x, y: negbinPMF(r, p, x) };\n  });\n\n  const stats = md`**Mean** ${tex`= r/p`} = ${(r/p).toFixed(2)}; \n  **Var** ${tex`= r(1-p)/p^2`} = ${((r*(1-p))/(p**2)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PMF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof negbin_r = Inputs.range([1, 30], {value: 5, step: 1, label: md`${tex`r`}`})\nviewof negbin_p = Inputs.range([0.02, 0.98], {value: 0.4, step: 0.02, label: md`${tex`p`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const a = unif_a, b = unif_b;\n  const data = linspace(a - 1, b + 1, 401).map(x =&gt; ({ x, y: unifPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= (a+b)/2`} = ${(((a+b)/2)).toFixed(2)}; \n  **Var** ${tex`= (b-a)^2/12`} = ${(((b-a)**2)/12).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof unif_a = Inputs.range([-5, 5], {value: -2, step: 0.1, label: md`${tex`a`}`})\nviewof unif_b = Inputs.range([unif_a + 0.2, unif_a + 10], {value: 3, step: 0.1, label: md`${tex`b`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const λ = exp_lambda;\n  const [lo, hi] = domainExp(λ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: expPDF(x, λ) }));\n\n  const stats = md`**Mean** ${tex`= 1/\\lambda`} = ${(1/λ).toFixed(2)}; \n  **Var** ${tex`= 1/\\lambda^2`} = ${((1/(λ**2))).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof exp_lambda = Inputs.range([0.2, 5], {value: 1, step: 0.1, label: md`${tex`\\lambda`}`})\n\n\n\n\n\n\n\n\n\n{\n  const a = gamma_a, b = gamma_b;\n  const [lo, hi] = domainGamma(a, b);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: gammaPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= a/b`} = ${(a/b).toFixed(2)}; \n  **Var** ${tex`= a/b^2`} = ${(a/(b**2)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof gamma_a = Inputs.range([0.5, 10], {value: 3, step: 0.1, label: md`${tex`a\\ \\text{(shape)}`}`})\nviewof gamma_b = Inputs.range([0.2, 5],  {value: 1, step: 0.1, label: md`${tex`b\\ \\text{(rate)}`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const μ = norm_mu, σ = norm_sig;\n  const [lo, hi] = domainNormal(μ, σ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: normPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= \\mu`} = ${μ.toFixed(2)}; \n  **Var** ${tex`= \\sigma^2`} = ${(σ**2).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n    width, height: 260,\n    style: { background: \"var(--plot-panel-bg)\", color: \"var(--brand-fg)\" },\n    x: { label: \"x\" }, y: { label: \"PDF\" },\n    marks: [\n      // shaded area under the PDF:\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n\n      // PDF outline:\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof norm_mu  = Inputs.range([-3, 3], {value: 0, step: 0.05, label: md`${tex`\\mu`}`})\nviewof norm_sig = Inputs.range([0.05, 3], {value: 1, step: 0.05, label: md`${tex`\\sigma`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const μ = lnorm_mu, σ = lnorm_sig;\n  const hi = Math.exp(μ + 5 * σ);\n  const data = linspace(0, hi).map(x =&gt; ({ x, y: lognormPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= e^{\\mu+\\sigma^2/2}`} = ${(Math.exp(μ + (σ**2)/2)).toFixed(2)}; \n  **Var** ${tex`= (e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2}`} = ${(((Math.exp(σ**2)-1)*Math.exp(2*μ + σ**2))).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n  \n}\n\n\n\n\n\n\n\nviewof lnorm_mu  = Inputs.range([-1.5, 2],  {value: 0,   step: 0.1, label: md`${tex`\\mu (\\log X)`}`})\nviewof lnorm_sig = Inputs.range([0.01, 1.5], {value: 0.6, step: 0.01, label: md`${tex`\\sigma (\\log X)`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const ν = Math.round(chi_nu);\n  const hi = Math.max(5, ν + 6 * Math.sqrt(2 * ν));\n  const data = linspace(0, hi).map(x =&gt; ({ x, y: chisqPDF(x, ν) }));\n\n  const stats = md`**Mean** ${tex`= \\nu`} = ${ν}; \n  **Var** ${tex`= 2\\nu`} = ${2*ν}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof chi_nu = Inputs.range([1, 40], {value: 8, step: 1, label: md`${tex`\\nu`}`})\n\n\n\n\n\n\n\n\n\n{\n  const ν = Math.round(t_nu);\n  const data = linspace(-6, 6).map(x =&gt; ({ x, y: tPDF(x, ν) }));\n\n  const stats = md`${tex`\\mathrm{E}[X]=0 (\\nu&gt;1)`}, \n  ${tex`\\operatorname{Var}(X)=\\nu/(\\nu-2)\\ (\\nu&gt;2)`}.  \n  Current: ${ν}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof t_nu = Inputs.range([1, 40], {value: 5, step: 1, label: md`${tex`\\nu`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nUse the tabs to switch distributions. Adjust the sliders to see how the PMF/PDF changes.",
    "crumbs": [
      "Additional Material",
      "Distribution Explorer"
    ]
  },
  {
    "objectID": "content/appendix/question-bank.html",
    "href": "content/appendix/question-bank.html",
    "title": "Question Bank",
    "section": "",
    "text": "bodyFont = getComputedStyle(document.body).fontFamily\n\n\n\n\n\n\n\nallQuestions = Array.from(document.querySelectorAll('.question'))\n\nallTags = Array.from(new Set(\n  allQuestions.flatMap(el =&gt; (el.dataset.tags || \"\")\n    .split(/\\s+/).map(t =&gt; t.trim()).filter(Boolean))\n)).sort()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  for (const el of allQuestions) {\n    // --- Tagbar (unchanged) ---\n    if (!el.querySelector('.tagbar')) {\n      const tags = (el.dataset.tags || \"\").split(/\\s+/).filter(Boolean);\n      const bar = document.createElement('div');\n      bar.className = 'tagbar';\n      bar.append(...tags.map(t =&gt; Object.assign(document.createElement('span'), {\n        className: 'tag', textContent: t\n      })));\n      el.appendChild(bar);\n    }\n\n    // --- Difficulty peppers in header (RHS) ---\n    const header = el.querySelector('.callout-header');\n    if (header && !header.querySelector('.difficulty-peppers')) {\n      const level = Number(el.dataset.difficulty ?? 0);\n\n      // Always show, but only add peppers if &gt;0\n      const span = document.createElement('span');\n      span.className = `difficulty-peppers level-${level}`;\n      span.setAttribute('aria-label', `Difficulty ${level}`);\n      span.textContent = level &gt; 0 ? `(${ \"🌶\".repeat(level) })` : \"( )\";\n      header.appendChild(span);\n    }\n  }\n  return html``  // silence\n}\n\n\n\n\n\n\n\nviewof typed = {\n  // --- DOM\n  const wrapper = html`&lt;div class=\"token-autocomplete\"&gt;&lt;/div&gt;`;\n  const labelEl = html`&lt;label class=\"token-label\"&gt;Filter by tags (type, space-separated):&lt;/label&gt;`;\n  const input   = html`&lt;input class=\"token-input\" type=\"text\" placeholder=\"e.g. bayes probability\"&gt;`;\n  wrapper.append(labelEl, input);\n\n  // --- PORTAL: suggestions list lives at document.body so it can overlay everything\n  const list = html`&lt;div class=\"token-suggestions\" role=\"listbox\" hidden&gt;&lt;/div&gt;`;\n  document.body.appendChild(list);\n\n  // Make sure it floats above all content\n  list.style.position = \"fixed\";\n  list.style.zIndex = \"9999\"; // high z-index to overlay everything\n\n  // --- value plumbing\n  Object.defineProperty(wrapper, \"value\", {\n    get() { return input.value; },\n    set(v) { input.value = v ?? \"\"; }\n  });\n\n  // --- helpers\n  const TAGS = () =&gt; (typeof allTags !== \"undefined\" ? allTags : []);\n  const tokens = () =&gt; input.value.split(/\\s+/).filter(Boolean);\n  const lastToken = () =&gt; (input.value.match(/(?:^|\\s)(\\S*)$/)?.[1]) ?? \"\";\n  const pretty = t =&gt; t.replace(/-/g, \" \").replace(/\\b\\w/g, c =&gt; c.toUpperCase());\n\n  // Position portal directly below the input, matching its width\n  const alignList = () =&gt; {\n    const r = input.getBoundingClientRect();\n    list.style.left = `${r.left}px`;\n    list.style.top  = `${r.bottom + 4}px`;\n    list.style.width = `${r.width}px`;\n  };\n\n  // --- render suggestions\n  let selectedIndex = -1;\n  const applyActiveStyles = () =&gt; {\n    const items = Array.from(list.children);\n    items.forEach((el, i) =&gt; el.classList.toggle(\"active\", i === selectedIndex));\n  };\n\n  function renderSuggestions() {\n    const q = lastToken().toLowerCase();\n    const already = new Set(tokens().map(s =&gt; s.toLowerCase()));\n    const tags = TAGS();\n\n    const candidates = q\n      ? tags.filter(t =&gt; t.toLowerCase().startsWith(q) && !already.has(t.toLowerCase()))\n      : [];\n\n    list.innerHTML = \"\";\n    if (candidates.length === 0) { list.hidden = true; return; }\n\n    for (const t of candidates.slice(0, 8)) {\n      const item = html`&lt;div class=\"token-suggestion\" role=\"option\" data-token=\"${t}\"&gt;${pretty(t)}&lt;/div&gt;`;\n      item.addEventListener(\"mousedown\", (e) =&gt; { e.preventDefault(); acceptSuggestion(t); });\n      list.appendChild(item);\n    }\n    selectedIndex = -1;\n    applyActiveStyles();\n    list.hidden = false;\n    alignList(); // ensure correct position when shown\n  }\n\n  function commit() {\n    const parts = tokens();\n    input.value = parts.join(\" \") + (parts.length ? \" \" : \"\");\n    wrapper.dispatchEvent(new Event(\"input\", { bubbles: true }));\n  }\n\n  function acceptSuggestion(tag) {\n    const parts = input.value.split(/\\s+/);\n    if (/\\S/.test(input.value)) parts.pop(); // replace last token\n    const set = new Set(parts.filter(Boolean).map(s =&gt; s.toLowerCase()));\n    if (!set.has(tag.toLowerCase())) parts.push(tag);\n    input.value = parts.filter(Boolean).join(\" \") + \" \";\n    list.hidden = true;\n    commit();\n    input.focus();\n  }\n\n  function moveSelection(delta) {\n    const items = Array.from(list.children);\n    if (items.length === 0) return;\n    selectedIndex = (selectedIndex + delta + items.length) % items.length;\n    applyActiveStyles();\n    if (selectedIndex &gt;= 0) items[selectedIndex].scrollIntoView({ block: \"nearest\" });\n  }\n\n  // --- events\n  input.addEventListener(\"input\", renderSuggestions);\n  input.addEventListener(\"focus\", () =&gt; { alignList(); }); // realign on focus\n\n  input.addEventListener(\"keydown\", (e) =&gt; {\n    if (!list.hidden && (e.key === \"ArrowDown\" || e.key === \"ArrowUp\")) {\n      e.preventDefault(); moveSelection(e.key === \"ArrowDown\" ? +1 : -1); return;\n    }\n    if (e.key === \"Enter\") {\n      if (!list.hidden && selectedIndex &gt;= 0) {\n        e.preventDefault();\n        const choice = list.children[selectedIndex]?.dataset.token;\n        if (choice) acceptSuggestion(choice);\n      } else {\n        commit();\n      }\n    } else if (e.key === \"Escape\") {\n      list.hidden = true;\n    }\n  });\n\n  // Delay blur to allow mousedown on suggestion to fire first\n  input.addEventListener(\"blur\", () =&gt; {\n    setTimeout(() =&gt; { list.hidden = true; commit(); }, 200);\n  });\n\n  // Close when clicking outside (remember list is outside wrapper now)\n  const onDocClick = (e) =&gt; {\n    if (e.target !== input && !list.contains(e.target)) list.hidden = true;\n  };\n  document.addEventListener(\"click\", onDocClick, true);\n\n  // Reposition on any scroll/resize (capture scrolls from nested containers)\n  const onViewportChange = () =&gt; { if (!list.hidden) alignList(); };\n  window.addEventListener(\"resize\", onViewportChange, { passive: true });\n  window.addEventListener(\"scroll\", onViewportChange, true);\n\n  // Initial alignment\n  queueMicrotask(alignList);\n\n  // Cleanup when the cell re-runs\n  wrapper.dispose = () =&gt; {\n    document.removeEventListener(\"click\", onDocClick, true);\n    window.removeEventListener(\"resize\", onViewportChange, { passive: true });\n    window.removeEventListener(\"scroll\", onViewportChange, true);\n    list.remove();\n  };\n\n  // Initial render\n  renderSuggestions();\n\n  return wrapper;\n}\n\n\n\n\n\n\n\nviewof chosen = Inputs.checkbox(allTags, {\n  label: md`Or pick tags:`,\n  value: []\n})\n\nviewof levels = Inputs.checkbox(\n  [0, 1, 2, 3],\n  {\n    label: md`Difficulty:`,\n    value: [0, 1, 2, 3],                 // default: show all\n    format: d =&gt; [\"Easy\", \"Medium\", \"Hard\", \"Too hard\"][d]\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  // Sync checkboxes to the committed text tokens\n  const lcMap = new Map(allTags.map(t =&gt; [t.toLowerCase(), t])); // lower → original\n  const typedNow = (typed || \"\").split(/\\s+/).filter(Boolean).map(s =&gt; s.toLowerCase());\n  const selected = typedNow.map(s =&gt; lcMap.get(s)).filter(Boolean);\n\n  const el = viewof chosen;\n  if (el && Array.isArray(el.value)) {\n    // compare sets to avoid churn\n    const cur = new Set(el.value);\n    let equal = selected.length === cur.size && selected.every(v =&gt; cur.has(v));\n    if (!equal) {\n      el.value = selected;\n      el.dispatchEvent(new Event(\"input\", {bubbles:true}));\n    }\n  }\n  return html``;\n}\n\n\n\n\n\n\n\n{\n  const typedSet  = new Set((typed || \"\").split(/\\s+/).filter(Boolean));\n  const chosenSet = new Set(chosen || []);\n  const required  = new Set([...typedSet, ...chosenSet]);   // AND over tags\n  const chosenLv  = new Set(levels || []);                  // allowed levels\n\n  let shown = 0;\n  for (const el of allQuestions) {\n    // tags check\n    const elTags = new Set((el.dataset.tags || \"\").split(/\\s+/).filter(Boolean));\n    const passTags = required.size === 0 || [...required].every(t =&gt; elTags.has(t));\n\n    // difficulty check (0 default)\n    const level = Number(el.dataset.difficulty ?? 0);\n    const passDiff = chosenLv.has(level);\n\n    const show = passTags && passDiff;\n    el.style.display = show ? \"\" : \"none\";\n    if (show) shown += 1;\n  }\n\n  return html`&lt;div&gt;&lt;strong&gt;Showing ${shown}&lt;/strong&gt; of ${allQuestions.length} questions.&lt;/div&gt;`\n}\n\n\n\n\n\n\n\n\n\n\n\n\nImportantProbability of heads\n\n\n\nA fair coin is tossed 10 times. What is the probability of exactly 6 heads?\n\n\nSolution\n\nWork it via the Binomial: \n\\mathrm{Pr}(X=6)=\\binom{10}{6} (1/2)^{10}.",
    "crumbs": [
      "Additional Material",
      "Question Bank"
    ]
  },
  {
    "objectID": "content/ide/python-ide.html",
    "href": "content/ide/python-ide.html",
    "title": "Python IDE",
    "section": "",
    "text": "Editor\n    \nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 2*np.pi, 100)\nplt.plot(x, np.sin(x), label='sin(x)')\nplt.plot(x, np.cos(x), label='cos(x)')\nplt.legend()\nplt.title('Trigonometric Functions')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n    \n  \n\n  \n    \n      Output\n      \n        ▶ Run\n        Clear\n        Loading...",
    "crumbs": [
      "Additional Material",
      "Python IDE"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html",
    "href": "content/main/1-overview-of-machine-learning.html",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "1.1 What is Machine Learning?\nYou might be surprised to learn that machine learning is not just a buzzword; it is a rich collection of mathematical concepts that can be rigorously studied.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#what-is-machine-learning",
    "href": "content/main/1-overview-of-machine-learning.html#what-is-machine-learning",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "1.1.1 Tasks\n\n\n\n\n\n\n\nDefinition 1.1 (Supervised Learning Task) Fix sets \\mathcal{X}, \\mathcal{Y}, and \\mathcal{Z}, a probability distribution P on \\mathcal{X} \\times \\mathcal{Y}, and a loss function L : \\mathcal{Y} \\times \\mathcal{Z} \\rightarrow \\mathbb{R}.\nGiven a training dataset \\{(\\mathbf{x}_i,\\mathbf{y}_i)\\}_{i=1}^n consisting of n independent samples from P, try to find a function f : \\mathcal{X} \\rightarrow \\mathcal{Z} for which \n\\mathbb{E}_{(\\mathbf{X},\\mathbf{Y}) \\sim P} [ L(\\mathbf{Y},f(\\mathbf{X})) ]\n is minimal.\n\n\n\n\nTo unpack this definition we are going to recap some of the prerequisite mathematical concepts, which you should have already studied:\n\n\n1.1.1.0.0.1 Set Notation I\nA set is a collection of objects, e.g. \\mathbb{N} is the set of natural numbers, \\mathbb{N}_0 = \\{0\\} \\cup \\mathbb{N} is the set of non-negative integers, and \\mathbb{R} is the set of real numbers.\nGiven a pair of sets, say \\mathcal{X} and \\mathcal{Y}, the Cartesian product of \\mathcal{X} and \\mathcal{Y} consists of all (ordered) pairs (x,y) where x is an element of \\mathcal{X} and y is an element of \\mathcal{Y}.\nAs a shorthand for set membership we can write x \\in \\mathcal{X} and y \\in \\mathcal{Y}. The Cartesian product of \\mathcal{X} and \\mathcal{Y} is denoted \\mathcal{X} \\times \\mathcal{Y}. For example, \\mathbb{R} \\times \\mathbb{R} is the two-dimensional Euclidean plane; we often abbreviate this to \\mathbb{R}^2.\nMore generally we could consider d-fold Cartesian products such as \\mathbb{R}^d.\n\n\n\n\n1.1.1.0.0.2 Probability mass functions; Definition 7 in MAS2909\nLet P be a probability distribution on a countable set \\mathcal{X} = \\{x_1, x_2, \\dots \\}.\nThen P is characterised by its probability mass function \np : \\mathcal{X} \\rightarrow [0,\\infty).\n Indeed, P assigns an amount of probability P(S) = \\sum_{x \\in S} p(x) to each S \\subset \\mathcal{X}.\nFrom the definition of a probability measure it must hold that p(\\mathcal{X}) = \\sum_{x \\in \\mathcal{X}} p(x) = 1.\n\n\n\n\n\n\n\n\n\nExample 1.1 (Binomial Distribution) The Binomial Distribution 1.2, with n trials and success parameter \\rho \\in [0,1], is a probability distribution on \\mathcal{X} = \\{0,1,2, \\dots , n \\} with probability mass function \np(x) = \\binom{n}{x} \\rho^x (1-\\rho)^{n-x}.\n In shorthand this is denoted \\mathrm{Binom}(n,\\rho).\n\n\nShow Visualisation\n\n{\n  const n = binom_n, p = binom_p;\n  const data = Array.from({ length: n + 1 }, (_, k) =&gt; ({ x: k, y: binomPMF(n, p, k) }));\n  const xDomain = Array.from({ length: n + 1 }, (_, k) =&gt; k);  // &lt;-- 0..n categories\n\n  const stats = md`**Mean** ${tex`= n\\rho`} = ${(n * p).toFixed(2)}; \n  **Variance** ${tex`= n\\rho(1-\\rho)`} = ${(n * p * (1 - p)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n    y: { label: \"PMF\" },\n    x: { label: \"x\", type: \"band\", domain: xDomain, padding: 0.05 },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof binom_n = Inputs.range([1, 200], { value: 20, step: 1,  label: md`${tex`n`}` })\nviewof binom_p = Inputs.range([0.01, 0.99], { value: 0.3, step: 0.01, label: md`${tex`\\rho`}` })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.2 (Poisson Distribution) The Poisson Distribution 1.4, with rate parameter \\lambda &gt;0, is a probability distribution on \\mathcal{X} = \\{0,1,2, \\dots  \\} with probability mass function \np(x) = \\frac{ e^{-\\lambda} \\lambda^x }{ x! } .\n In shorthand this is denoted \\mathrm{Pois}(\\lambda).\n\n\nShow Visualisation\n\n{\n  // compute locally (no exported names)\n  const L     = pois_lambda;\n  const kmax  = Math.max(15, Math.ceil(L + 6*Math.sqrt(L)));\n  const pois_data = Array.from({length: kmax + 1}, (_, k) =&gt; ({ x: k, y: poisPMF(L, k) }));\n\n  // build the UI bits\n  const stats = md`**Mean** ${tex`= \\lambda`} = ${L.toFixed(2)}; \n  **Variance** ${tex`= \\lambda`} = ${L.toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(pois_data, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\" }),\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return both in a single wrapper\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof pois_lambda = Inputs.range([0.2, 30], {\n  value: 6, step: 0.2, label: md`${tex`\\lambda`}`\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.1.0.0.3 Set Notation II\nIf a set \\mathcal{X} is contained in another set \\mathcal{Y} we write \\mathcal{X} \\subset \\mathcal{Y}.\nIn this case, the indicator function of the set \\mathcal{X} is the function 1_{\\mathcal{X}} : \\mathcal{Y} \\rightarrow \\{0,1\\} for which f_{\\mathcal{X}}(y) = 1 if and only if y \\in \\mathcal{X}.\nFor example, 1_{[0,1]}(x) is equal to 1 when 0 \\leq x \\leq 1 and equal to 0 if x lies outside this interval.\n\n\n\n\n1.1.1.0.0.4 Probability Density Function\nLet P be a sufficiently regular1 probability distribution on \\mathbb{R}^d.\nThen P is characterised by its probability density function \np : \\mathbb{R}^d \\rightarrow [0,\\infty).\n Indeed, P assigns an amount of probability P(S) = \\int 1_S(\\mathbf{x}) p(\\mathbf{x}) \\; \\mathrm{d}\\mathbf{x} to each set S \\subset \\mathbb{R}^d.\nFrom the definition of a probability measure it must hold that \\int p(\\mathbf{x}) \\; \\mathrm{d}\\mathbf{x} = 1.\n\n\n\n\n\n\n\n\n\nExample 1.3 (Uniform Distribution; Section 1.4 in MAS2909) The Uniform Distribution 2.1 on an interval [a,b] with a &lt; b has probability density function \np(x) = \\frac{1}{b-a} 1_{[a,b]}(x).\n In shorthand this is denoted \\mathcal{U}(a,b).\n\n\nShow Visualisation\n\n{\n  const a = unif_a, b = unif_b;\n  const data = linspace(a - 1, b + 1, 401).map(x =&gt; ({ x, y: unifPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= (a+b)/2`} = ${(((a+b)/2)).toFixed(2)}; \n  **Variance** ${tex`= (b-a)^2/12`} = ${(((b-a)**2)/12).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof unif_a = Inputs.range([-5, 5], {value: -2, step: 0.1, label: md`${tex`a`}`})\nviewof unif_b = Inputs.range([unif_a + 0.2, unif_a + 10], {value: 3, step: 0.1, label: md`${tex`b`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.4 (Normal Distribution on \\mathbb{R}; Section 1.4 in MAS2909) The Normal Distribution 2.5, with mean parameter \\mu \\in \\mathbb{R} and variance parameter \\sigma^2 &gt; 0, has probability density function \np(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( - \\frac{1}{2 \\sigma^2} (x-\\mu)^2 \\right).\n In shorthand this is denoted \\mathcal{N}(\\mu,\\sigma^2).\n\n\nShow Visualisation\n\n{\n  const μ = norm_mu, σ = norm_sig;\n  const [lo, hi] = domainNormal(μ, σ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: normPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= \\mu`} = ${μ.toFixed(2)}; \n  **Variance** ${tex`= \\sigma^2`} = ${(σ**2).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n    width, height: 260,\n    style: { background: \"var(--plot-panel-bg)\", color: \"var(--brand-fg)\" },\n    x: { label: \"x\" }, y: { label: \"PDF\" },\n    marks: [\n      // shaded area under the PDF:\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n\n      // PDF outline:\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof norm_mu  = Inputs.range([-3, 3], {value: 0, step: 0.05, label: md`${tex`\\mu`}`})\nviewof norm_sig = Inputs.range([0.05, 3], {value: 1, step: 0.05, label: md`${tex`\\sigma`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom variables were formally defined in MAS2909. Following standard convention, we will use upper-case Roman letters (e.g. X) for random variables and lower-case Roman letters (e.g. x) for specific values that could be taken by X.\n\n\n1.1.1.0.0.5 Distribution of a Random Variable\nLet X be a random variable taking values in a set \\mathcal{X}.\nThe distribution of X is the probability distribution P for which P(S) = \\mathrm{Prob}(X \\in S) for each S \\subset \\mathcal{X}.\n\n\nIt is common to write X \\sim P as shorthand for “X has distribution P”. Another reasonably common notation, which will be used in this module, is \\mathcal{P}(\\mathcal{X}) to denote the set of probability distributions on a set \\mathcal{X}.\n\n\n\n\n\n\n\nExercise 1.1 (Coin Tossing) A biased coin, which with probability 0.6 lands on heads, is tossed 10 times in total.\nWhat is the probability of observing at least 8 heads?\n\nSolution\nLet X denote the number of heads.\nThen X is a random variable with distribution P = \\mathrm{Binom}(10,0.6). We have P(\\{8,9,10\\}) = p(8) + p(9) + p(10) = \\binom{10}{8} 0.6^8 (1-0.6)^{2} + \\binom{10}{9} 0.6^9 (1-0.6)^1 + \\binom{10}{10} 0.6^{10} (1-0.6)^0 = 0.1673 (4 s.f.)\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 1.2 (Sums of random variables) Let X_1 \\sim \\mathcal{U}(0,1) and X_2 \\sim \\mathcal{U}(0,1) be independent.\nLet Z = X_1 + X_2.\nFind a probability density function for Z.\n(Hint: Recall Proposition 1 in MAS2909.)\n\nSolution\nFrom Proposition 1 in MAS2909 we have \np(z) = \\int 1_{[0,1]}(x) 1_{[0,1]}(z-x) \\; \\mathrm{d}x\n and we can evaluate this integral: \\begin{align*}\np(z)   &= \\int 1_{[\\max\\{0 , z-1 \\},\\min\\{1,z\\}]}(x) \\; \\mathrm{d}x \\\\\n    &= \\max\\{ \\min\\{1,z\\} - \\max\\{0 , z-1 \\} , 0 \\} \\\\\n    &= \\left\\{ \\begin{array}{ll} z & 0 &lt; z \\leq 1 \\\\ 2 - z & 1 &lt; z &lt; 2 \\\\ 0 & \\text{otherwise} \\end{array} \\right.\n\\end{align*} This is called the triangular distribution.\n\n\n\n\n\n\n\n1.1.1.0.0.6 Probabilistic calculus\nWhich of the following equivalent statements do you think is most natural?\n\nZ = X_1 + X_2 where X_1 \\sim \\mathcal{U}(a,b) and X_2 \\sim \\mathcal{N}(\\mu,\\sigma^2) are independent\nZ has probability density function \n\\frac{1}{b-a} \\int 1_{[a,b]}(x) \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (z - x - \\mu)^2 \\right) \\; \\mathrm{d}x\n\n\nIt of course depends on what we are trying to do - a good rule of thumb is to “use random variables for intuition, and use densities for computation”.\n\n\n\n\n1.1.1.0.0.7 Joint Distribution\nGiven random variables X_1 and X_2, we can define a new random variable as \\mathbf{X} = (X_1,X_2).\nThe distribution of \\mathbf{X} is called the joint distribution of X_1 and X_2.\nThe concept naturally extends to more than two random variables as well.\n\n\n\n\n1.1.1.0.0.8 Marginal Distribution; Section 2.3 of MAS2909\nGiven a random variable \\mathbf{X} = (X_1,X_2) with probability (mass or) density function p.\nThe distribution of X_1 is called the marginal distribution of X_1; i.e. the probability distribution whose probability (mass or) density function is \np_1(x_1) = \\int p(\\mathbf{x}) \\; \\mathrm{d}x_2,\n where \\mathbf{x} = (x_1,x_2).\n(For probability mass functions this integral should be replaced by a sum.)\nIntuitively, the marginal distribution of X_1 is just the distribution of X_1 if we have not observed X_2.\n\n\n\n\n1.1.1.0.0.9 Conditional Distribution; Section 2.4 of MAS2909\nGiven a random variable \\mathbf{X} = (X_1,X_2) with probability (mass or) density function p, let p_1 and p_2 denote probability (mass or) density functions for the marginal distributions of X_1 and X_2.\nThe conditional distribution of X_1 given X_2 = x_2 is the probability distribution whose probability (mass or) density function is \np(\\mathbf{x}) / p_2(x_2),\n where \\mathbf{x} = (x_1,x_2). The associated random variable is usually denoted X_1 | X_2 = x_2.\nIntuitively, the conditional distribution of X_1 given X_2 represents our understanding of X_1 if we had observed the value of X_2 (e.g. our understanding of the weather given we had observed someone putting on a coat).\n\n\n\n\n1.1.1.0.0.10 Independence; Section 2.5 of MAS2909\nTwo random variables X_1 and X_2 are independent if their joint distribution admits a probability (mass or) density function of the form p(\\mathbf{x}) = p_1(x_1) p_2(x_2) where p_i is a probability density function for X_i and \\mathbf{x} = (x_1,x_2).\nIntuitively, if X_1 and X_2 are independent, then observing X_2 tells us nothing about X_1 (and vice versa).\nThe concept naturally extends to multiple random variables; we say X_1,\\dots,X_n are independent if \np(\\mathbf{x}) = p_1(x_1) p_2(x_2) \\cdots p_n(x_n)\n where \\mathbf{x} = (x_1,\\dots,x_n).\n\n\n\n\n\n\n\n\n\nExercise 1.3 (Normal distribution on \\mathbb{R}^d) Let X_1 , \\dots X_d be independent with X_i \\sim \\mathcal{N}(\\mu_i , \\sigma_i^2) for each i \\in \\{1,\\dots,d\\}. Let \\mathbf{X} = (X_1, \\dots , X_d).\nShow that \\mathbf{X} \\sim \\mathcal{N}(\\bm{\\mu},\\bm{\\Sigma}) where \\bm{\\mu} = (\\mu_1,\\dots,\\mu_d)^\\top and \\bm{\\Sigma} = \\mathrm{diag}(\\sigma_1^2 , \\dots , \\sigma_d^2).\n\nSolution\nFrom independence we know that \\mathbf{X} has distribution p(\\mathbf{x}) = p_1(x_1) \\cdots p_d(x_d) where p_i(x_i) = \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp( - \\frac{1}{2 \\sigma_i^2} (x_i-\\mu_i)^2 ).\nAlgebra gives the result.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "MAS3919: Foundations of Machine Learning",
    "section": "Course Overview",
    "text": "Course Overview\nThe first section 1  Overview of Machine Learning of these notes aims to provide an overview of the module, and to recap important prerequisites from Stage 2. In many cases we will indicate precisely where concepts can be found (up to minor presentational variation) in the lecture notes from Stage 2. These notes represent the definitive version of MAS3919 and MAS8607; in-person lectures are an opportunity to review a subset of the material in real-time, but are not a substitute for studying these lecture notes in detail. Students are recommended to read through the lecture notes in advance of the lecture, in a flipped classroom format.\nDistinct from most other modules, we will tend to emphasise understanding of concepts as opposed to detailed calculations, and your examination will test your ability both to recall these concepts and to give a coherent written explanation of their relevance in a given context. After taking this module you should feel equipped with a broad knowledge of machine learning, enabling you to coherently communicate at a technical level in (e.g.) a job interview for a machine learning engineer post. In addition, we will provide practical demonstrations of machine learning in Python; you are strongly encouraged to try these out as homework, as experience of implementing machine learning in Python is a valuable addition to any CV.\nThese lecture notes are new for 2026 and are therefore bound to contain small errors; we would appreciate these being brought to our attention by emailing chris.oates@ncl.ac.uk or matthew.fisher@ncl.ac.uk.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#footnotes",
    "href": "content/main/1-overview-of-machine-learning.html#footnotes",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "Students who have taken MAS3716 will understand that we require P to be absolutely continuous with respect to the Lebesgue measure on \\mathbb{R}^d in order for a density to exist. An example of a probability distribution which fails this requirement is the distribution that places all mass at a single point. Such issues will not be the focus of this module; cf. Remark 1.2.↩︎",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#sec-what-is-ml",
    "href": "content/main/1-overview-of-machine-learning.html#sec-what-is-ml",
    "title": "1  Overview of Machine Learning",
    "section": "",
    "text": "1.1.1 Tasks\n\n\n\n\n\n\n\nDefinition 1.1 (Supervised Learning Task) Fix sets \\mathcal{X}, \\mathcal{Y}, and \\mathcal{Z}, a probability distribution P on \\mathcal{X} \\times \\mathcal{Y}, and a loss function L : \\mathcal{Y} \\times \\mathcal{Z} \\rightarrow \\mathbb{R}.\nGiven a training dataset \\{(\\mathbf{x}_i,\\mathbf{y}_i)\\}_{i=1}^n consisting of n independent samples from P, try to find a function f : \\mathcal{X} \\rightarrow \\mathcal{Z} for which \n\\mathbb{E}_{(\\mathbf{X},\\mathbf{Y}) \\sim P} [ L(\\mathbf{Y},f(\\mathbf{X})) ]\n is minimal.\n\n\n\n\nTo unpack this definition we are going to recap some of the prerequisite mathematical concepts, which you should have already studied:\n\n\n1.1.1.0.0.1 Set Notation I\nA set is a collection of objects, e.g. \\mathbb{N} is the set of natural numbers, \\mathbb{N}_0 = \\{0\\} \\cup \\mathbb{N} is the set of non-negative integers, and \\mathbb{R} is the set of real numbers.\nGiven a pair of sets, say \\mathcal{X} and \\mathcal{Y}, the Cartesian product of \\mathcal{X} and \\mathcal{Y} consists of all (ordered) pairs (x,y) where x is an element of \\mathcal{X} and y is an element of \\mathcal{Y}.\nAs a shorthand for set membership we can write x \\in \\mathcal{X} and y \\in \\mathcal{Y}. The Cartesian product of \\mathcal{X} and \\mathcal{Y} is denoted \\mathcal{X} \\times \\mathcal{Y}. For example, \\mathbb{R} \\times \\mathbb{R} is the two-dimensional Euclidean plane; we often abbreviate this to \\mathbb{R}^2.\nMore generally we could consider d-fold Cartesian products such as \\mathbb{R}^d.\n\n\n\n\n1.1.1.0.0.2 Probability mass functions; Definition 7 in MAS2909\nLet P be a probability distribution on a countable set \\mathcal{X} = \\{x_1, x_2, \\dots \\}.\nThen P is characterised by its probability mass function \np : \\mathcal{X} \\rightarrow [0,\\infty).\n Indeed, P assigns an amount of probability P(S) = \\sum_{x \\in S} p(x) to each S \\subset \\mathcal{X}.\nFrom the definition of a probability measure it must hold that p(\\mathcal{X}) = \\sum_{x \\in \\mathcal{X}} p(x) = 1.\n\n\n\n\n\n\n\n\n\nExample 1.1 (Binomial Distribution) The Binomial Distribution 1.2, with n trials and success parameter \\rho \\in [0,1], is a probability distribution on \\mathcal{X} = \\{0,1,2, \\dots , n \\} with probability mass function \np(x) = \\binom{n}{x} \\rho^x (1-\\rho)^{n-x}.\n In shorthand this is denoted \\mathrm{Binom}(n,\\rho).\n\n\nShow Visualisation\n\n{\n  const n = binom_n, p = binom_p;\n  const data = Array.from({ length: n + 1 }, (_, k) =&gt; ({ x: k, y: binomPMF(n, p, k) }));\n  const xDomain = Array.from({ length: n + 1 }, (_, k) =&gt; k);  // &lt;-- 0..n categories\n\n  const stats = md`**Mean** ${tex`= n\\rho`} = ${(n * p).toFixed(2)}; \n  **Variance** ${tex`= n\\rho(1-\\rho)`} = ${(n * p * (1 - p)).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n    y: { label: \"PMF\" },\n    x: { label: \"x\", type: \"band\", domain: xDomain, padding: 0.05 },  // &lt;-- band scale\n    marks: [\n      Plot.barY(data, { x: \"x\", y: \"y\", fill: ACCENT }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof binom_n = Inputs.range([1, 200], { value: 20, step: 1,  label: md`${tex`n`}` })\nviewof binom_p = Inputs.range([0.01, 0.99], { value: 0.3, step: 0.01, label: md`${tex`\\rho`}` })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.2 (Poisson Distribution) The Poisson Distribution 1.4, with rate parameter \\lambda &gt;0, is a probability distribution on \\mathcal{X} = \\{0,1,2, \\dots  \\} with probability mass function \np(x) = \\frac{ e^{-\\lambda} \\lambda^x }{ x! } .\n In shorthand this is denoted \\mathrm{Pois}(\\lambda).\n\n\nShow Visualisation\n\n{\n  // compute locally (no exported names)\n  const L     = pois_lambda;\n  const kmax  = Math.max(15, Math.ceil(L + 6*Math.sqrt(L)));\n  const pois_data = Array.from({length: kmax + 1}, (_, k) =&gt; ({ x: k, y: poisPMF(L, k) }));\n\n  // build the UI bits\n  const stats = md`**Mean** ${tex`= \\lambda`} = ${L.toFixed(2)}; \n  **Variance** ${tex`= \\lambda`} = ${L.toFixed(2)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n\n    y: { label: \"PMF\" },\n    x: { label: \"x\" },\n    marks: [\n      Plot.barY(pois_data, { x: \"x\", y: \"y\", fill: \"var(--brand-teal)\" }),\n      Plot.ruleY([0], { stroke: \"var(--border)\", strokeOpacity: 0.6 })\n    ]\n  });\n\n  // return both in a single wrapper\n  return html`&lt;div class=\"dist-panel\"&gt;\n    &lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;\n    ${plot}\n  &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof pois_lambda = Inputs.range([0.2, 30], {\n  value: 6, step: 0.2, label: md`${tex`\\lambda`}`\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.1.0.0.3 Set Notation II\nIf a set \\mathcal{X} is contained in another set \\mathcal{Y} we write \\mathcal{X} \\subset \\mathcal{Y}.\nIn this case, the indicator function of the set \\mathcal{X} is the function 1_{\\mathcal{X}} : \\mathcal{Y} \\rightarrow \\{0,1\\} for which f_{\\mathcal{X}}(y) = 1 if and only if y \\in \\mathcal{X}.\nFor example, 1_{[0,1]}(x) is equal to 1 when 0 \\leq x \\leq 1 and equal to 0 if x lies outside this interval.\n\n\n\n\n1.1.1.0.0.4 Probability Density Function\nLet P be a sufficiently regular1 probability distribution on \\mathbb{R}^d.\nThen P is characterised by its probability density function \np : \\mathbb{R}^d \\rightarrow [0,\\infty).\n Indeed, P assigns an amount of probability P(S) = \\int 1_S(\\mathbf{x}) p(\\mathbf{x}) \\; \\mathrm{d}\\mathbf{x} to each set S \\subset \\mathbb{R}^d.\nFrom the definition of a probability measure it must hold that \\int p(\\mathbf{x}) \\; \\mathrm{d}\\mathbf{x} = 1.\n\n\n\n\n\n\n\n\n\nExample 1.3 (Uniform Distribution; Section 1.4 in MAS2909) The Uniform Distribution 2.1 on an interval [a,b] with a &lt; b has probability density function \np(x) = \\frac{1}{b-a} 1_{[a,b]}(x).\n In shorthand this is denoted \\mathcal{U}(a,b).\n\n\nShow Visualisation\n\n{\n  const a = unif_a, b = unif_b;\n  const data = linspace(a - 1, b + 1, 401).map(x =&gt; ({ x, y: unifPDF(x, a, b) }));\n\n  const stats = md`**Mean** ${tex`= (a+b)/2`} = ${(((a+b)/2)).toFixed(2)}; \n  **Variance** ${tex`= (b-a)^2/12`} = ${(((b-a)**2)/12).toFixed(3)}.`;\n\n  const plot = Plot.plot({\n        width, height: 260,\n    style: {\n    background: \"var(--plot-panel-bg)\",\n    color: \"var(--brand-fg)\"           // drives 'currentColor'\n    },\n y: { label: \"PDF\" }, x: { label: \"x\" },\n    marks: [\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof unif_a = Inputs.range([-5, 5], {value: -2, step: 0.1, label: md`${tex`a`}`})\nviewof unif_b = Inputs.range([unif_a + 0.2, unif_a + 10], {value: 3, step: 0.1, label: md`${tex`b`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1.4 (Normal Distribution on \\mathbb{R}; Section 1.4 in MAS2909) The Normal Distribution 2.5, with mean parameter \\mu \\in \\mathbb{R} and variance parameter \\sigma^2 &gt; 0, has probability density function \np(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left( - \\frac{1}{2 \\sigma^2} (x-\\mu)^2 \\right).\n In shorthand this is denoted \\mathcal{N}(\\mu,\\sigma^2).\n\n\nShow Visualisation\n\n{\n  const μ = norm_mu, σ = norm_sig;\n  const [lo, hi] = domainNormal(μ, σ);\n  const data = linspace(lo, hi).map(x =&gt; ({ x, y: normPDF(x, μ, σ) }));\n\n  const stats = md`**Mean** ${tex`= \\mu`} = ${μ.toFixed(2)}; \n  **Variance** ${tex`= \\sigma^2`} = ${(σ**2).toFixed(2)}.`;\n\n  const plot = Plot.plot({\n    width, height: 260,\n    style: { background: \"var(--plot-panel-bg)\", color: \"var(--brand-fg)\" },\n    x: { label: \"x\" }, y: { label: \"PDF\" },\n    marks: [\n      // shaded area under the PDF:\n      Plot.areaY(data, { x: \"x\", y: \"y\", fill: ACCENT, fillOpacity: 0.18 }),\n\n      // PDF outline:\n      Plot.lineY(data, { x: \"x\", y: \"y\", stroke: ACCENT, strokeWidth: 2 }),\n\n      Plot.ruleY([0], { stroke: GRID, strokeOpacity: 0.6 })\n    ]\n  });\n\n  return html`&lt;div class=\"dist-panel\"&gt;&lt;div class=\"stats\"&gt;${stats}&lt;/div&gt;${plot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\nviewof norm_mu  = Inputs.range([-3, 3], {value: 0, step: 0.05, label: md`${tex`\\mu`}`})\nviewof norm_sig = Inputs.range([0.05, 3], {value: 1, step: 0.05, label: md`${tex`\\sigma`}`})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom variables were formally defined in MAS2909. Following standard convention, we will use upper-case Roman letters (e.g. X) for random variables and lower-case Roman letters (e.g. x) for specific values that could be taken by X.\n\n\n1.1.1.0.0.5 Distribution of a Random Variable\nLet X be a random variable taking values in a set \\mathcal{X}.\nThe distribution of X is the probability distribution P for which P(S) = \\mathrm{Prob}(X \\in S) for each S \\subset \\mathcal{X}.\n\n\nIt is common to write X \\sim P as shorthand for “X has distribution P”. Another reasonably common notation, which will be used in this module, is \\mathcal{P}(\\mathcal{X}) to denote the set of probability distributions on a set \\mathcal{X}.\n\n\n\n\n\n\n\nExercise 1.1 (Coin Tossing) A biased coin, which with probability 0.6 lands on heads, is tossed 10 times in total.\nWhat is the probability of observing at least 8 heads?\n\nSolution\nLet X denote the number of heads.\nThen X is a random variable with distribution P = \\mathrm{Binom}(10,0.6). We have P(\\{8,9,10\\}) = p(8) + p(9) + p(10) = \\binom{10}{8} 0.6^8 (1-0.6)^{2} + \\binom{10}{9} 0.6^9 (1-0.6)^1 + \\binom{10}{10} 0.6^{10} (1-0.6)^0 = 0.1673 (4 s.f.)\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 1.2 (Sums of random variables) Let X_1 \\sim \\mathcal{U}(0,1) and X_2 \\sim \\mathcal{U}(0,1) be independent.\nLet Z = X_1 + X_2.\nFind a probability density function for Z.\n(Hint: Recall Proposition 1 in MAS2909.)\n\nSolution\nFrom Proposition 1 in MAS2909 we have \np(z) = \\int 1_{[0,1]}(x) 1_{[0,1]}(z-x) \\; \\mathrm{d}x\n and we can evaluate this integral: \\begin{align*}\np(z)   &= \\int 1_{[\\max\\{0 , z-1 \\},\\min\\{1,z\\}]}(x) \\; \\mathrm{d}x \\\\\n    &= \\max\\{ \\min\\{1,z\\} - \\max\\{0 , z-1 \\} , 0 \\} \\\\\n    &= \\left\\{ \\begin{array}{ll} z & 0 &lt; z \\leq 1 \\\\ 2 - z & 1 &lt; z &lt; 2 \\\\ 0 & \\text{otherwise} \\end{array} \\right.\n\\end{align*} This is called the triangular distribution.\n\n\n\n\n\n\n\n1.1.1.0.0.6 Probabilistic calculus\nWhich of the following equivalent statements do you think is most natural?\n\nZ = X_1 + X_2 where X_1 \\sim \\mathcal{U}(a,b) and X_2 \\sim \\mathcal{N}(\\mu,\\sigma^2) are independent\nZ has probability density function \n\\frac{1}{b-a} \\int 1_{[a,b]}(x) \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (z - x - \\mu)^2 \\right) \\; \\mathrm{d}x\n\n\nIt of course depends on what we are trying to do - a good rule of thumb is to “use random variables for intuition, and use densities for computation”.\n\n\n\n\n1.1.1.0.0.7 Joint Distribution\nGiven random variables X_1 and X_2, we can define a new random variable as \\mathbf{X} = (X_1,X_2).\nThe distribution of \\mathbf{X} is called the joint distribution of X_1 and X_2.\nThe concept naturally extends to more than two random variables as well.\n\n\n\n\n1.1.1.0.0.8 Marginal Distribution; Section 2.3 of MAS2909\nGiven a random variable \\mathbf{X} = (X_1,X_2) with probability (mass or) density function p.\nThe distribution of X_1 is called the marginal distribution of X_1; i.e. the probability distribution whose probability (mass or) density function is \np_1(x_1) = \\int p(\\mathbf{x}) \\; \\mathrm{d}x_2,\n where \\mathbf{x} = (x_1,x_2).\n(For probability mass functions this integral should be replaced by a sum.)\nIntuitively, the marginal distribution of X_1 is just the distribution of X_1 if we have not observed X_2.\n\n\n\n\n1.1.1.0.0.9 Conditional Distribution; Section 2.4 of MAS2909\nGiven a random variable \\mathbf{X} = (X_1,X_2) with probability (mass or) density function p, let p_1 and p_2 denote probability (mass or) density functions for the marginal distributions of X_1 and X_2.\nThe conditional distribution of X_1 given X_2 = x_2 is the probability distribution whose probability (mass or) density function is \np(\\mathbf{x}) / p_2(x_2),\n where \\mathbf{x} = (x_1,x_2). The associated random variable is usually denoted X_1 | X_2 = x_2.\nIntuitively, the conditional distribution of X_1 given X_2 represents our understanding of X_1 if we had observed the value of X_2 (e.g. our understanding of the weather given we had observed someone putting on a coat).\n\n\n\n\n1.1.1.0.0.10 Independence; Section 2.5 of MAS2909\nTwo random variables X_1 and X_2 are independent if their joint distribution admits a probability (mass or) density function of the form p(\\mathbf{x}) = p_1(x_1) p_2(x_2) where p_i is a probability density function for X_i and \\mathbf{x} = (x_1,x_2).\nIntuitively, if X_1 and X_2 are independent, then observing X_2 tells us nothing about X_1 (and vice versa).\nThe concept naturally extends to multiple random variables; we say X_1,\\dots,X_n are independent if \np(\\mathbf{x}) = p_1(x_1) p_2(x_2) \\cdots p_n(x_n)\n where \\mathbf{x} = (x_1,\\dots,x_n).\n\n\n\n\n\n\n\n\n\nExercise 1.3 (Normal distribution on \\mathbb{R}^d) Let X_1 , \\dots X_d be independent with X_i \\sim \\mathcal{N}(\\mu_i , \\sigma_i^2) for each i \\in \\{1,\\dots,d\\}. Let \\mathbf{X} = (X_1, \\dots , X_d).\nShow that \\mathbf{X} \\sim \\mathcal{N}(\\bm{\\mu},\\bm{\\Sigma}) where \\bm{\\mu} = (\\mu_1,\\dots,\\mu_d)^\\top and \\bm{\\Sigma} = \\mathrm{diag}(\\sigma_1^2 , \\dots , \\sigma_d^2).\n\nSolution\nFrom independence we know that \\mathbf{X} has distribution p(\\mathbf{x}) = p_1(x_1) \\cdots p_d(x_d) where p_i(x_i) = \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp( - \\frac{1}{2 \\sigma_i^2} (x_i-\\mu_i)^2 ).\nAlgebra gives the result.\n\n\n\n\n\n\n\n1.1.1.0.0.11 Notation for Expectations\nLet P be a probability distribution on a set \\mathcal{X} and let f : \\mathcal{X} \\rightarrow \\mathbb{R} be a function of interest.\nThe following notations are all equivalent and widely-used:\n\n\\mathbb{E}_{X \\sim P}[f(X)]\n\\mathbb{E}[f(X)] where X \\sim P\nP(f)\n\\int f \\; \\mathrm{d}P\n\\int f(x) p(x) \\; \\mathrm{d}x (if P has a probability density function p)\n\\sum_{x \\in \\mathcal{X}} f(x) p(x) (if P has a probability mass function p)\n\n\n\n\n\n\n\n\n\nTipRemark (Disclaimer: MAS3716 Prequisite)\n\n\n\n\n\n\nRemark 1.2 (Disclaimer: MAS3716 Prequisite). This course does not require MAS3716 and so we will not work rigorously with measure theory; any expectations that we write down will always be assumed to exist.\n\n\n\n\n\n\n\n\n\n\n\nExample 1.5 (Expected Loss 1)  \n\n\n\n\n\n\n\n\n\n\n\nExample 1.6 (Expected Loss 2)  \n\n\n\n\n\n\n\n\n\n\n\nExample 1.7 (Expected Loss 3)  \n\n\n\n\nNow we are ready to unpack Definition 1.1. The easiest way is to see some examples of supervised learning tasks:\n\n\n\n\n\n\n\nExample 1.8 (Regression) Regression models are powerful statistical tools used to understand the relationship between variables and make predictions. At their core, these models aim to identify how one or more independent variables (also often called covariates or predictors), influence a dependent variable (also often called a response variable) of interest.\nFor example, suppose we are interested in the (statistical) relationship between the frequency of pedestrians walking up the Queen Victoria Road next to campus and the time of day.\n\n\n\n\n\n\nFigure 1.1: Map of the main university campus, with the location of the measurements on the Queen Victoria Road highlighted.\n\n\n\nThe independent variable here is the time of day, which we denote X, and the dependent variable is the frequency of pedestrians (i.e. the number of pedestrians per unit time), which we denote Y. It is reasonable to suppose X \\in \\mathbb{R} and Y \\in [0,\\infty).\nOne can freely access such data via the university’s Urban Observatory; the data shown below are from September 2025:\n\n\n\n\n\n\nFigure 1.2: Footfall data for the Queen Victoria Road in September 2025. The vertical axis represents the frequency of pedestrians.\n\n\n\nPredicting pedestrian footfall has important applications in transport, retail, and public safety; other independent variables that could be of interest in this context include the weather and whether or not large public events (e.g. the freshers’ fair) are being held. The goal in regression is to directly predict the dependent variable, so that \\mathcal{Z} = \\mathcal{Y} in the notation of Definition 1.1.\nSimple examples of loss functions, which measure the loss incurred when a true response y is predicted as y', include L(y,y') = |y-y'| and L(y,y') = (y-y')^2.\nRegression models are widely used in various fields, including economics for forecasting financial trends, in medicine for assessing treatment effects, and in social sciences for understanding behavioral patterns. They provide insights that are crucial for making informed decisions and formulating strategies.\n\n\n\n\n\n\n\n\n\n\n\nExample 1.9 (Classification) Continuing on from Example 1.8, how do you think these footfall data on the Queen Victoria Road were collected?\nIt will not be a surprise to you that CCTV cameras are abundant in large cities such as Newcastle; take a look at the latest feeds for yourself:\nhttps://api.newcastle.urbanobservatory.ac.uk/camera/\nCounting the number of people in an image obtained from CCTV is an example of a classification task. Classification is a fundamental concept in machine learning that involves categorising data into predefined groups or classes.\nHere \\mathbf{X} is the CCTV image, which we can consider as an element of \\mathbb{R}^{w \\times h \\times 3}, where the image is w pixels wide, h pixels high, and contains information for each of the red, green and blue colour channels, and Y is the number of pedestrians in the image, which is an element of \\mathbb{N}_0 (here the “classes”).\nThe goal in classification is to directly predict the class, so that \\mathcal{Z} = \\mathcal{Y} in the notation of Definition 1.1.\nThe most common loss function used in classification applications is L(y,y') = 1 if y = y', and otherwise L(y,y') = 0; in fact, this is sometimes called the classification loss, or the 0-1 loss.\nFor this footfall application it might also be reasonable to use a loss function such as L(y,y') = |y-y'|, which is more tolerant to small counting errors than the 0-1 loss.\n(Note that the scale of the loss is irrelevant; the supervised learning task is invariant to whether we use the loss function L(y,y') of the loss function cL(y,y') for any constant c &gt; 0, since we only care about the function f for which the expected loss is minimised; cf. Definition 1.1.)\n\n\n\n\n\n\nFigure 1.3: Several companies have emerged to sell “people counters” as a product. This image is taken from one such company.}.\n\n\n\nThe independent variable here is the time of day, which we denote X, and the dependent variable is the frequency of pedestrians (i.e. the number of pedestrians per unit time), which we denote Y. It is reasonable to suppose X \\in \\mathbb{R} and Y \\in [0,\\infty).\nOne can freely access such data via the university’s Urban Observatory; the data shown below are from September 2025:\n\n\n\n\n\n\nFigure 1.4: Footfall data for the Queen Victoria Road in September 2025. The vertical axis represents the frequency of pedestrians.\n\n\n\nClassification is widely used in various fields, from spam detection in emails to diagnosing diseases in the medical field.\nClassifiers are trained on a dataset where the categories, or labels, are already known; training helps the system learn the patterns and characteristics that differentiate one class from another (cf. Section 1.2).\n\n\n\n\n\n\n\n\n\n\n\nExample 1.10 (Probabilistic Forecasting) Probabilistic forecasting refers to predicting future events or outcomes along with an associated probability distribution.\nUnlike regression, which provides a single outcome prediction, probabilistic forecasting provides a range of potential outcomes and the likelihood of each occurring, offering a more comprehensive view of future uncertainties.\nOne of the key advantages of probabilistic forecasting is its ability to provide decision-makers with a range of possible scenarios, along with their associated probabilities. This allows organisations to plan for various contingencies and make informed decisions based on the level of risk they are willing to accept.\nSuppose, at time t, we want to predict footfall on the Queen Victoria Road at a future time t + 1. Our input X represents all data available to us at time t, and our task is to select a probability distribution that represents a probabilistic prediction of the actual footfall Y. In the setting of Definition 1.1, we have \\mathcal{Y} = \\mathbb{N}_0 and \\mathcal{Z} = \\mathcal{P}(\\mathbb{N}_0).\n\n\n\n\n\n\n\n\n\n\n\nExample 1.11 (Text-to-Video) Text-to-video technology represents a groundbreaking development in the field of artificial intelligence and multimedia content generation.\nBy employing advanced algorithms, this technology can transform textual descriptions X into dynamic video content f(X), offering a novel way to create visual media without the traditional constraints of video production.\nIn the setting of Definition 1.1, \\mathcal{X} is the set of text strings and \\mathcal{Z} is the set of all possible video content.\nFor coherence we can define Y equal to X, so that the loss function L(Y,f(X)) can be interpreted as a critical assessment of whether the video content f(X) is an accurate instantiation of the text string X.\n\n\n\n\n\n\n1.1.2 Models\nNow that we have seen several examples of supervised learning tasks, a natural question is how to solve them? That is, in the notation of Definition 1.1, how do we find a suitable function f : \\mathcal{X} \\rightarrow \\mathcal{Z}?\nThe answer to this question will be broken down into two parts:\n\nFirst we will talk about how to identify a set \\mathcal{F} whose elements are candidates for the function f in a given learning task; this set \\mathcal{F} is called the machine learning model.\nThen we will see how to identify a suitable element f \\in \\mathcal{F}; this second step is called training the machine learning model, and we will defer this discussion to Section 1.2.\n\n\n\n\n\n\n\n\nDefinition 1.2 (Machine Learning Model) A machine learning model (or simply model) for a supervised learning task as in Definition 1.1 is a collection \\mathcal{F} of maps \nf : \\mathcal{X} \\rightarrow \\mathcal{Y}.\n\n\n\n\n\nIn practice the elements of \\mathcal{F} are usually parametrised, denoted f_\\theta : \\mathcal{X} \\rightarrow \\mathcal{Y} for some parameters \\theta from a suitable index set \\Theta. It is then equivalent to specify either the set \\mathcal{F} or the form of the parametric function f_\\theta together with the set of allowed parameters \\Theta.\n\n\n\n\n\n\n\nExample 1.12 (Linear Regression) Linear models are one of the simplest examples of a machine learning model for a regression task (cf. Example 1.8).\nRecall that linear regression refers to using a linear function \nf_{\\bm{\\theta}}(\\mathbf{x}) = \\theta_1 x_1 + \\dots + \\theta_d x_d\n\\tag{1.1}\nto predict the value of the dependent variable Y \\in \\mathbb{R} based on the values of the independent variables \\mathbf{X} \\in \\mathbb{R}^d.\nDespite their simplicity, linear models are widely used in applications where scientific interpretation of the parameters \\bm{\\theta} is required.\nIndeed, \\theta_i carries the interpretation of how the prediction for the dependent variable Y changes per unit change in the associated independent variable X_i in Equation 1.1.\nIn fact, linear regression models can be quite sophisticated, e.g. \nf_{\\bm{\\theta}}(\\mathbf{x}) = \\theta_1 \\phi_1(\\mathbf{x}) + \\dots + \\theta_p \\phi_p(\\mathbf{x})\n\\tag{1.2}\nfor a fixed collection of \\bm{\\theta}-independent functions \\phi_i, i = 1 , \\dots , p, called features (cf. ?sec-featurisation) which could include an intercept (\\phi_i(\\mathbf{x}) = 1), nonlinearities (e.g. \\phi_i(\\mathbf{x}) = x_1^2), and interactions (e.g. \\phi_i(\\mathbf{x}) = x_1 x_2).\nIn this module a linear regression model refers to a machine learning model f_{\\bm{\\theta}} that is linear in the parameters \\bm{\\theta}; the map f_{\\bm{\\theta}}(\\mathbf{x}) need not be linear in \\mathbf{x}, as Equation 1.2 demonstrated.\nNote also that no concepts from probability appear in our definition of a linear regression model (though sometimes concepts from probability are used to train such a model; see Section 1.2).\n\n\n\n\n\n\n\n\n\n\n\nExample 1.13 (Logistic Classifier) A logistic classifier is a machine learning model used for binary classification tasks, i.e. where the classes can be represented using the binary labels \\mathcal{Y} = \\{0,1\\}. The model has the form \\begin{align*}\n    f_{\\bm{\\theta}}(\\mathbf{x}) = \\left\\{ \\begin{array}{ll} 1 & \\text{if} \\quad \\sigma( g_{\\bm{\\theta}}(\\textbf{x}) ) &gt; \\tau \\\\ 0 & \\text{if} \\quad \\sigma( g_{\\bm{\\theta}}(\\mathbf{x}) ) \\leq \\tau \\end{array} \\right.\n\\end{align*} where g_{\\bm{\\theta}} : \\mathcal{X} \\rightarrow \\mathbb{R} is a linear regression model of the form Equation 1.1 parametrised by \\bm{\\theta}, \\sigma(\\cdot) is the logistic function \n\\sigma(z) = \\frac{1}{1 + e^{-z}} ,\n\\tag{1.3}\nalso known as the sigmoid function, which converts the output g_{\\bm{\\theta}}(\\mathbf{x}) from the linear regression model into a score that ranges from 0 to 1, and \\tau \\in (0,1) is a fixed threshold, which is commonly \\tau = \\frac{1}{2}.\nAs with the linear regression model, no concepts from probability are required to define a logistic classifier (though sometimes concepts from probability are used to train such a model; see Section 1.2).\nLogistic classifiers are widely used in various fields, including finance for credit scoring, healthcare for disease prediction, and marketing for customer segmentation.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/1-overview-of-machine-learning.html#sec-training",
    "href": "content/main/1-overview-of-machine-learning.html#sec-training",
    "title": "1  Overview of Machine Learning",
    "section": "1.2 Training",
    "text": "1.2 Training",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/3-stochastic-optimisation.html",
    "href": "content/main/3-stochastic-optimisation.html",
    "title": "3  Stochastic Optimisation",
    "section": "",
    "text": "3.1 Gradient Descent",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochastic Optimisation</span>"
    ]
  },
  {
    "objectID": "content/main/3-stochastic-optimisation.html#stochastic-gradient-descent",
    "href": "content/main/3-stochastic-optimisation.html#stochastic-gradient-descent",
    "title": "3  Stochastic Optimisation",
    "section": "3.2 Stochastic Gradient Descent",
    "text": "3.2 Stochastic Gradient Descent",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Stochastic Optimisation</span>"
    ]
  },
  {
    "objectID": "content/main/6-beyond-supervised-learning.html",
    "href": "content/main/6-beyond-supervised-learning.html",
    "title": "6  Beyond Supervised Learning",
    "section": "",
    "text": "6.1 Unsupervised Learning",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Beyond Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/6-beyond-supervised-learning.html#semi-supervised-learning",
    "href": "content/main/6-beyond-supervised-learning.html#semi-supervised-learning",
    "title": "6  Beyond Supervised Learning",
    "section": "6.2 Semi-supervised Learning",
    "text": "6.2 Semi-supervised Learning",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Beyond Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/6-beyond-supervised-learning.html#generative-modelling-star",
    "href": "content/main/6-beyond-supervised-learning.html#generative-modelling-star",
    "title": "6  Beyond Supervised Learning",
    "section": "6.3 Generative Modelling (\\star)",
    "text": "6.3 Generative Modelling (\\star)\n\n6.3.1 Generative Models (\\star)\n\n\n6.3.2 Training Generative Models (\\star)",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Beyond Supervised Learning</span>"
    ]
  },
  {
    "objectID": "content/main/4-generalisation-error.html",
    "href": "content/main/4-generalisation-error.html",
    "title": "4  Generalisation Error",
    "section": "",
    "text": "4.1 Generalisation Error Bounds (\\star)",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Generalisation Error</span>"
    ]
  },
  {
    "objectID": "content/main/4-generalisation-error.html#domain-shift",
    "href": "content/main/4-generalisation-error.html#domain-shift",
    "title": "4  Generalisation Error",
    "section": "4.2 Domain Shift",
    "text": "4.2 Domain Shift",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Generalisation Error</span>"
    ]
  },
  {
    "objectID": "content/main/7-ethics-of-ml.html",
    "href": "content/main/7-ethics-of-ml.html",
    "title": "7  Ethics of Machine Learning",
    "section": "",
    "text": "Definition 7.1 (Adversarial Attacks) Adversarial attacks in machine learning refer to techniques used to deceive models by introducing small, intentional perturbations to the input data. This area of study has gained significant attention due to the vulnerabilities it exposes in machine learning systems, particularly in computer vision, natural language processing, and other applications where AI models are deployed.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics of Machine Learning</span>"
    ]
  },
  {
    "objectID": "content/main/2-machine-learning-models.html",
    "href": "content/main/2-machine-learning-models.html",
    "title": "2  Machine Learning Models",
    "section": "",
    "text": "2.1 Linear Model\nThis section takes a deep dive into the two main classes of machine learning model, the linear model 2.1 and neural networks 2.2\nAlong the way we will learn about the key (related) concepts of regularisation 2.1.1, featurisation 2.1.2, and dimensionality reduction 2.1.2.2.\nAlthough we already encountered examples of linear models in the regression context (cf. Example 1.12), here we precisely define it:\nIt is worth re-emphasising that this definition does not require the relationship between \\mathbf{x} and f_{\\bm{\\theta}}(\\mathbf{x}) to be linear as in Equation 1.1. The “linearity” refers to linearity of f_{\\bm{\\theta}}(\\mathbf{x}) with respect to the parameters \\bm{\\theta} \\in \\mathbb{R}^p.\nFor the moment we will suppose we are provided with appropriate feature functions \\phi_i : \\mathcal{X} \\rightarrow \\mathbb{R}; the issue of selecting an appropriate featurisation is discussed in detail in Section 2.1.2. The vector-valued function \\phi : \\mathcal{X} \\rightarrow \\mathbb{R}^p whose coordiate functions are the \\phi_i is called the feature map associated to the linear regression model.\nTo get started, let us see how to recover standard least squares from the empirical risk minimisation framework:\nIt is reassuring that least squares falls under the umbrella of empirical risk minimisation, but the value of having a general framework for supervised learning is that we can consider alternative loss functions as well.\nOne motivation for this is to consider the robustneess of a linear regression model against an ?def-adversarial-attack targetting one entry in the dataset.",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Machine Learning Models</span>"
    ]
  },
  {
    "objectID": "content/main/2-machine-learning-models.html#sec-linear-model",
    "href": "content/main/2-machine-learning-models.html#sec-linear-model",
    "title": "2  Machine Learning Models",
    "section": "",
    "text": "Definition 2.1 (Linear Model) Let \\mathcal{X} = \\mathbb{R}^d and \\mathcal{Z} = \\mathbb{R}. A linear model is a model of the form \nf_{\\bm{\\theta}}(\\mathbf{x}) = \\theta_1 \\phi_1(\\mathbf{x}) + \\dots + \\theta_p \\phi_p(\\mathbf{x})\n for some \\bm{\\theta} = (\\theta_1 , \\cdots , \\theta_p)^\\top \\in \\mathbb{R}^p and some feature functions \\phi_i : \\mathcal{X} \\rightarrow \\mathbb{R}, i \\in \\{1,\\dots,p\\}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.1 (Least squares as empirical risk minimisation) Consider training a linear regression model using empirical risk minimisation with squared error loss L(y,z) = (y - z)^2. Let \\bm{\\Phi} be the n \\times p whose (i,j)th entry is \\phi_j(\\mathbf{x}_i), and assume that \\bm{\\Phi} has full column rank. Then, \\begin{align*}\n\\mathcal{R}_n(f_{\\bm{\\theta}}) & = \\frac{1}{n} \\sum_{i=1}^n L(y_i , f_{\\bm{\\theta}}(\\mathbf{x}_i)) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\phi(\\mathbf{x}_i)^\\top \\bm{\\theta} )^2 \\\\\n& = \\frac{1}{n} \\| \\mathbf{y} - \\bm{\\Phi} \\bm{\\theta} \\|^2\n\\end{align*} so that \\begin{align*}\n\\nabla_{\\bm{\\theta}} \\mathcal{R}_n(f_{\\bm{\\theta}}) & = \\frac{2}{n} [ - 2 \\bm{\\Phi}^\\top \\mathbf{y} + 2 \\bm{\\Phi}^\\top \\bm{\\Phi} \\bm{\\theta} ] .\n\\end{align*} Since \\bm{\\Phi} has full column rank it follows that \\bm{\\Phi}^\\top \\bm{\\Phi} is a positive definite (and thus invertible) matrix. Thus the stationarity equation \\nabla_{\\bm{\\theta}} \\mathcal{R}_n(f_{\\bm{\\theta}}) = \\mathbf{0} has a unique solution \n\\hat{\\bm{\\theta}} = (\\bm{\\Phi}^\\top \\bm{\\Phi})^{-1} \\bm{\\Phi}^\\top \\mathbf{y}\n\\tag{2.1}\nwhich we recognise as the usual least-squares formula for regression coefficients that you learned in school.\nNote that the Hessian matrix \\nabla_{\\bm{\\theta}}^2 \\mathcal{R}_n(f_{\\bm{\\theta}}) = \\frac{4}{n} \\bm{\\Phi}^\\top \\bm{\\Phi} is positive definite, so although \\hat{\\bm{\\theta}} was obtained as a solution of the stationary point equation it is indeed a global minimiser of the empirical risk.\n\n\n\n\n\n\n\n2.1.1 Regularisation\n\n2.1.1.1 Ridge Regression\n\n\n2.1.1.2 Other Convex Regularisers\n\n\n\n2.1.2 Featurisation\n\n2.1.2.1 Variable Selection\n\n\n2.1.2.2 Dimensionality Reduction\n\n\n2.1.2.3 Kernel Methods (\\star)",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Machine Learning Models</span>"
    ]
  },
  {
    "objectID": "content/main/2-machine-learning-models.html#sec-nn",
    "href": "content/main/2-machine-learning-models.html#sec-nn",
    "title": "2  Machine Learning Models",
    "section": "2.2 Neural Networks",
    "text": "2.2 Neural Networks\n\n2.2.1 Activation Functions",
    "crumbs": [
      "Lecture Notes",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Machine Learning Models</span>"
    ]
  }
]